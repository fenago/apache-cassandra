{
  "paragraphs": [
    {
      "text": "%sh\nSTATUS=\"$(service cassandra status)\"\n\nif [[ $STATUS == *\"is running\"* ]]; then\n    echo \"Cassandra is running\"\nelse \n    echo \" Cassandra not running .... Starting\"  \n    service cassandra restart > /dev/null 2>&1 &\n    echo \" Started\"  \nfi",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "sh",
          "editOnDblClick": false,
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/sh",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506763_2085558218",
      "id": "paragraph_1591536954486_1152598017",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "focus": true,
      "$$hashKey": "object:57"
    },
    {
      "text": "%md\n\nEffective CQL\n------------------------\n\nIn this lab, we will examine common approaches to data modeling and\ninteracting with data stored in Apache Cassandra. This will involve us\ntaking a close look at the Cassandra Query Language, otherwise known as\n**CQL**. Specifically, we will cover and discuss the following topics:\n\n-   The evolution of CQL and the role it plays in the Apache Cassandra\n    universe\n-   How data is structured and modeled effectively for Apache Cassandra\n-   How to build primary keys that facilitate high-performing data\n    models at scale\n-   How CQL differs from SQL\n-   CQL syntax and how to solve different types of problems using it\n\nOnce you have completed this lab, you should have an understanding\nof why data models need to be built in a certain way. You should also\nbegin to understand known Cassandra anti-patterns and be able to spot\ncertain types of bad queries. This should help you to build scalable,\nquery-based tables and write successful CQL to interact with them.\n\nIn the parts of this lab that cover data modeling, be sure to pay\nextra attention. The data model is the most important part of a\nsuccessful, high-performing Apache Cassandra cluster. It is also\nextremely difficult to change your data model later on, so test early,\noften, and with a significant amount of data. You do not want to realize\nthat you need to change your model after you have already stored\nmillions of rows. No amount of performance-tuning on the cluster side\ncan make up for a poorly-designed data model!\n",
      "user": "anonymous",
      "dateUpdated": "2020-06-30T13:46:17+0000",
      "config": {
        "colWidth": 12,
        "fontSize": 9,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false,
          "completionSupport": false
        },
        "editorMode": "ace/mode/text",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<h2>Effective CQL</h2>\n<p>In this lab, we will examine common approaches to data modeling and<br />\ninteracting with data stored in Apache Cassandra. This will involve us<br />\ntaking a close look at the Cassandra Query Language, otherwise known as<br />\n<strong>CQL</strong>. Specifically, we will cover and discuss the following topics:</p>\n<ul>\n<li>The evolution of CQL and the role it plays in the Apache Cassandra<br />\nuniverse</li>\n<li>How data is structured and modeled effectively for Apache Cassandra</li>\n<li>How to build primary keys that facilitate high-performing data<br />\nmodels at scale</li>\n<li>How CQL differs from SQL</li>\n<li>CQL syntax and how to solve different types of problems using it</li>\n</ul>\n<p>Once you have completed this lab, you should have an understanding<br />\nof why data models need to be built in a certain way. You should also<br />\nbegin to understand known Cassandra anti-patterns and be able to spot<br />\ncertain types of bad queries. This should help you to build scalable,<br />\nquery-based tables and write successful CQL to interact with them.</p>\n<p>In the parts of this lab that cover data modeling, be sure to pay<br />\nextra attention. The data model is the most important part of a<br />\nsuccessful, high-performing Apache Cassandra cluster. It is also<br />\nextremely difficult to change your data model later on, so test early,<br />\noften, and with a significant amount of data. You do not want to realize<br />\nthat you need to change your model after you have already stored<br />\nmillions of rows. No amount of performance-tuning on the cluster side<br />\ncan make up for a poorly-designed data model!</p>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1593524768695_411850479",
      "id": "paragraph_1593524768695_411850479",
      "dateCreated": "2020-06-30T13:46:08+0000",
      "dateStarted": "2020-06-30T13:46:17+0000",
      "dateFinished": "2020-06-30T13:46:17+0000",
      "status": "FINISHED",
      "$$hashKey": "object:58"
    },
    {
      "text": "%md\n\nAn overview of Cassandra data modeling\n--------------------------------------\n\n* * * * *\n\nUnderstanding how Apache Cassandra organizes data under the hood is\nessential to knowing how to use it properly. When examining Cassandra's\ndata organization, it is important to determine which version of Apache\nCassandra you are working with. Apache Cassandra 3.0 represents a\nsignificant shift in the way data is both stored and accessed, which\nwarrants a discussion on the evolution of CQL.\n\nBefore we get started, let's create a keyspace for this lab's work:\n\n```\nCREATE KEYSPACE fenago_ch3 WITH replication =\n {'class': 'NetworkTopologyStrategy', 'ClockworkAngels':'1'};\n```\n\nTo preface this discussion, let's create an example table. Let's assume\nthat we want to store data about a music playlist, including the band's\nname, albums, song titles, and some additional data about the songs. The\nCQL for creating that table could look like this:\n\n```\nCREATE TABLE playlist (\n band TEXT,\n album TEXT,\n song TEXT,\n running_time TEXT,\n year INT,\n PRIMARY KEY (band,album,song));\n```\n\nNow we'll add some data into that table:\n\n```\nINSERT INTO playlist (band,album,song,running_time,year)\n  VALUES ('Rush','Moving Pictures','Limelight','4:20',1981);\nINSERT INTO playlist (band,album,song,running_time,year)\n  VALUES ('Rush','Moving Pictures','Tom Sawyer','4:34',1981);\nINSERT INTO playlist (band,album,song,running_time,year)\n  VALUES ('Rush','Moving Pictures','Red Barchetta','6:10',1981);\nINSERT INTO playlist (band,album,song,running_time,year)\n  VALUES ('Rush','2112','2112','20:34',1976);\nINSERT INTO playlist (band,album,song,running_time,year)\n  VALUES ('Rush','Clockwork Angels','Seven Cities of Gold','6:32',2012);\nINSERT INTO playlist (band,album,song,running_time,year)\n  VALUES ('Coheed and Cambria','Burning Star IV','Welcome Home','6:15',2006);\n```\n\n### Cassandra storage model for early versions up to 2.2\n\nThe original underlying storage for Apache Cassandra was based on its\nuse of the Thrift interface layer. If we were to look at how the\nunderlying data was stored in older (pre-3.0) versions of Cassandra, we\nwould see something similar to the following:\n\n\nFigure 3.1: Demonstration of how data was stored in the older storage\nengine of Apache Cassandra. Notice that the data is partitioned\n(co-located) by its row key, and then each column is ordered by the\ncolumn keys.\n\n![](https://raw.githubusercontent.com/fenago/apache-cassandra/master/images/1.jpg)\n\nAs you can see in the preceding screenshot, data is simply stored by its\nrow key (also known as the **partitioning key**). Within each partition,\ndata is stored ordered by its column keys, and finally by its (non-key)\ncolumn names. This structure was sometimes referred to as a **map of a\nmap**. The innermost section of the map, where the column values were\nstored, was called a **cell**. Dealing with data like this proved to be\nproblematic and required some understanding of the Thrift API to\ncomplete basic operations.\n\nWhen CQL was introduced with Cassandra 1.2, it essentially abstracted\nthe Thrift model in favor of a SQL-like interface, which was more\nfamiliar to the database development community. This abstraction brought\nabout the concept known as the **CQL row**. While the storage layer\nstill viewed from the simple perspective of partitions and column\nvalues, CQL introduced the row construct to Cassandra, if only at a\nlogical level. This difference between the physical and logical models\nof the Apache Cassandra storage engine was prevalent in major versions:\n1.2, 2.0, 2.1, and 2.2.\n\n#### Cassandra storage model for versions 3.0 and beyond\n\nOn the other hand, the new storage engine changes in Apache Cassandra\n3.0 offer several improvements. With version 3.0 and up, stored data is\nnow organized like this:\n\n![](https://raw.githubusercontent.com/fenago/apache-cassandra/master/images/2.jpg)\n\nFigure 3.2: Demonstration of how data is stored in the new storage\nengine used by Apache Cassandra 3.0 and up. While data is still\npartitioned in a similar manner, rows are now first-class citizens.\n\n \n\nThe preceding figure shows that, while data is still partitioned\nsimilarly to how it always was, there is a new structure present. The\nrow is now part of the storage engine. This allows for the data model\nand the Cassandra language drivers to deal with the underlying data\nsimilar to how the storage engine does.\n\n### Note\n\nAn important aspect not pictured in the preceding screenshot is the fact\nthat each row and column value has its own timestamp.\n\nIn addition to rows becoming first-class citizens of the physical data\nmodel, another change to the storage engine brought about a drastic\nimprovement. As Apache Cassandra's original data model comes from more\nof a key/value approach, every row is not required to have a value for\nevery column in a table.\n\nThe original storage engine allowed for this by repeating the column\nnames and clustering keys with each column value. One way around\nrepeating the column data was to use the\n`WITH COMPACT STORAGE` directive at the time of table\ncreation. However, this presented limitations around schema flexibility,\nin that columns could no longer be added or removed.\n\n### Note\n\nDo not use the `WITH COMPACT STORAGE` directive with Apache\nCassandra version 3.0 or newer. It no longer provides any benefits, and\nexists so that legacy users have an upgrade path.\n\nWith Apache Cassandra 3.0, column names and clustering keys are no\nlonger repeated with each column value. Depending on the data model,\nthis can lead to a drastic difference in the disk footprint between\nCassandra 3.0 and its prior versions.\n\n### Note\n\nI have seen as much as a 90% reduction in disk footprint by upgrading\nfrom Cassandra 2.x to Cassandra 3.0 and as little as 10% to 15%. Your\nexperience may vary, depending on the number of columns in a table, size\nof their names, and primary key definition.\n\n \n\n#### Data cells\n\nSometimes structures for storing column values are referred to as\n**cells**. Queries to Cassandra essentially return collections of cells.\nAssume the following table definition for keeping track of weather\nstation readings:\n\n```\nCREATE TABLE weather_data_by_date (\n  month BIGINT,\n  day BIGINT,\n  station_id UUID,\n  time timestamp,\n  temperature DOUBLE,\n  wind_speed DOUBLE,\n  PRIMARY KEY ((month,day),station_id,time));\n```\n\nIn this model, the `month` and `day` keys are used\nto make up a composite partition key. The clustering keys are\n`station_id` and `time`. In this way, for each\npartition, the number of cells will be equal to the total unique\ncombinations of tuples:\n\n-   `station_id`, `time`, `temperature`\n-   `station_id`, `time`, `wind_speed`\n\nUnderstanding a cell comes into play when building data models. Apache\nCassandra can only support 2,000,000,000 cells per partition. When data\nmodelers fail to consider this, partitions can become large and\nungainly, with query times eventually getting slower. This is why data\nmodels that allow for unbound row growth are considered to be an\nanti-pattern.\n\n### Note\n\nThe maximum of 2,000,000,000 cells per partition is a hard limit. But,\npractically speaking, models that allow that many cells to be written to\na single partition will become slow long before that limit is reached.\n\n\nGetting started with CQL\n------------------------\n\n* * * * *\n\nWith some quick definitions of CQL data modeling and cqlsh completed,\nnow we'll take a look at CQL. The basic commands for creating data\nstructures (keyspaces, tables, and so on) will be covered right away,\nwith command complexity increasing as we build more useful structures.\n\n### Creating a keyspace\n\nKeyspaces are analogous to the logical databases of the relational\nworld. A keyspace contains tables, which are usually related to each\nother by application, use case, or development team. When defining a\nkeyspace, you also have the ability to control its replication behavior,\nspecifying pairs of data center names and a numeric **Replication\nFactor** (**RF**).\n\nCreating a keyspace is a simple operation and can be done like this:\n\n```\nCREATE KEYSPACE [IF NOT EXISTS] <keyspace_name>\n WITH replication =\n {'class': '<replication_strategy>',\n  '<data_center_name>':'<replication_factor>'}\n AND durable_writes = <true/false>;\n```\n\n \n\nHere is the detailed explanation of the preceding query:\n\n-   `keyspace_name`: Valid keyspace names must be composed of\n    alphanumeric characters and underscores.\n-   `replication_strategy`: Either `SimpleStrategy`\n    or `NetworkTopologyStrategy`.\n-   `data_center_name`: Valid only\n    for `NetworkTopologyStrategy`, must be the name of a valid\n    data center. If using `SimpleStrategy`, specify\n    `replication_factor`.\n-   `replication_factor`: A numeric value representing the\n    number of replicas to write for the key with which it is paired.\n-   `durable_writes`: A Boolean indicating whether writes\n    should be written to the commit log. If not specified, this defaults\n    to `true`.\n\n### Note\n\nNames for keyspaces, tables, columns, and custom structures in Apache\nCassandra must be alphanumeric. The only exception to that rule is that\nan underscore (`_`) is the only valid special character that\ncan be used.\n\n#### Single data center example\n\nThe following example will create the `fenago_ch3` keyspace.\nWhen a write occurs, one replica will be written to the cluster. Writes\nwill also be sent to the commit log for extra durability:\n\n```\nCREATE KEYSPACE IF NOT EXISTS fenago_ch3\n WITH replication =\n {'class': 'NetworkTopologyStrategy', 'ClockworkAngels':'1'}\n AND durable_writes = true;\n```\n\n### Note\n\n`SimpleStrategy` isn't very useful, so my advice is not to use\nit. It's a good idea to get into the habit of using\n`NetworkTopologyStrategy`, as that's the one that should be\nused in production. `SimpleStrategy` offers no advantages over\n`NetworkTopologyStrategy`, and using\n`SimpleStrategy` can complicate converting into a multi-data\ncenter environment later.\n\n \n\n \n\n#### Multi-data center example\n\nThe following example will create the `fenago_ch3b` keyspace,\nas long as it does not already exist. When a write occurs, two replicas\nwill be written to the `ClockworkAngels` data center, and\nthree will be written to the `PermanentWaves` and\n`MovingPictures` data centers. Writes will also be sent to\nthe commit log for extra durability:\n\n```\nCREATE KEYSPACE fenago_ch3_mdc\n WITH replication = {'class': 'NetworkTopologyStrategy',\n  'ClockworkAngels':'2', 'MovingPictures':'3', 'PermanentWaves':'3'}\n AND durable_writes = true;\n```\n\nOnce you have created your keyspace, you can use it to avoid having to\nkeep typing it later. Notice that this will also change your Command\nPrompt:\n\n```\ncassdba@cqlsh> use fenago_ch3 ;\ncassdba@cqlsh:fenago_ch3>\n```\n\n### Creating a table\n\nData in Cassandra is organized into storage structures known as tables.\nSome older documentation may refer to tables as column families. If\nsomeone refers to column families, it is safe to assume that they are\nreferring to structures in older versions of Apache Cassandra:\n\n```\nCREATE TABLE [IF NOT EXISTS] [keyspace_name.]<table_name>\n <column_name> <column_type>,\n [additional <column_name> <column_type>,]\n PRIMARY KEY ((<partition_key>[,additional <partition_key>])[,<clustering_keys]);\n[WITH <options>];\n```\n\n#### Simple table example\n\nFor a small table with simple query requirements, something like this\nmight be sufficient:\n\n```\nCREATE TABLE users (\n username TEXT,\n email TEXT,\n department TEXT,\n title TEXT,\n ad_groups TEXT,\n PRIMARY KEY (username));\n```\n\n \n\n#### Clustering key example\n\nLet's say that we wanted to be able to offer up the same data, but to\nsupport a query for users by department. The table definition would\nchange to something like this:\n\n```\nCREATE TABLE users_by_dept (\n  username TEXT,\n  email TEXT,\n  department TEXT,\n  title TEXT,\n  AD_groups TEXT,\n  PRIMARY KEY ((department),username))\nWITH CLUSTERING ORDER BY (username ASC)\n  AND COMPACTION = {'class':'LeveledCompactionStrategy',\n  'sstable_size_in_mb':'200'};\n```\n\nAs the preceding table will be read more than it will be written to\n(users queried more often than they are added), we also designate use\nof `LeveledCompactionStrategy`.\n\n### Note\n\nThe default compaction strategy is\n`SizeTieredCompactionStrategy`, which tends to favor read and\nwrite patterns that are either even (50% read, 50% write) or more\nwrite-heavy.\n\nFor a later example, let's write some data to that table:\n\n```\nINSERT INTO users_by_dept(department,username,title,email) VALUES ('Engineering','Dinesh','Dev Lead','dinesh@piedpiper.com');\nINSERT INTO users_by_dept(department,username,title,email) VALUES ('Engineering','Gilfoyle','Sys Admin/DBA','thedarkone@piedpiper.com');\nINSERT INTO users_by_dept(department,username,title,email) VALUES ('Engineering','Richard','CEO','richard@piedpiper.com');\nINSERT INTO users_by_dept(department,username,title,email) VALUES ('Marketing','Erlich','CMO','erlichb@aviato.com');\nINSERT INTO users_by_dept(department,username,title,email) VALUES ('Finance/HR','Jared','COO','donald@piedpiper.com');\n```\n\n \n\n#### Composite partition key example\n\nSolving data model problems attributed to unbound row growth can\nsometimes be done by adding another partition key. Let's assume that we\nwant to query security entrance logs for employees. If we were to use a\nclustering key on a new column named time to one of the preceding\nexamples, we would be continually adding cells to each partition. So\nwe'll build this `PRIMARY KEY` to partition our data by\n`entrance` and `day`, as well as cluster it on\n`checkpoint_time` and `username`:\n\n```\nCREATE TABLE security_log (\n entrance TEXT,\n day BIGINT,\n checkpoint_time TIMESTAMP,\n username TEXT,\n email TEXT,\n department TEXT,\n title TEXT,\n PRIMARY KEY ((entrance,day),checkpoint_time,username))\nWITH CLUSTERING ORDER BY (checkpoint_time DESC, username ASC)\nAND default_time_to_live=2592000;\n```\n\nThe preceding table will store data sorted within each partition by both\n`checkpoint_time` and `username`. Note that, since\nwe care more about the most recent data, we have designated the\nclustering on `checkpoint_time` to be in descending order.\nAdditionally, we'll assume we have a requirement to only keep security\nlog data for the last 30 days, so we'll set\n`default_time_to_live` to 30 days (`2592000`\nseconds).\n\n",
      "user": "anonymous",
      "dateUpdated": "2020-06-30T13:46:02+0000",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<h2>An overview of Cassandra data modeling</h2>\n<hr />\n<p>Understanding how Apache Cassandra organizes data under the hood is<br />\nessential to knowing how to use it properly. When examining Cassandra&rsquo;s<br />\ndata organization, it is important to determine which version of Apache<br />\nCassandra you are working with. Apache Cassandra 3.0 represents a<br />\nsignificant shift in the way data is both stored and accessed, which<br />\nwarrants a discussion on the evolution of CQL.</p>\n<p>Before we get started, let&rsquo;s create a keyspace for this lab&rsquo;s work:</p>\n<pre><code>CREATE KEYSPACE fenago_ch3 WITH replication =\n {'class': 'NetworkTopologyStrategy', 'ClockworkAngels':'1'};\n</code></pre>\n<p>To preface this discussion, let&rsquo;s create an example table. Let&rsquo;s assume<br />\nthat we want to store data about a music playlist, including the band&rsquo;s<br />\nname, albums, song titles, and some additional data about the songs. The<br />\nCQL for creating that table could look like this:</p>\n<pre><code>CREATE TABLE playlist (\n band TEXT,\n album TEXT,\n song TEXT,\n running_time TEXT,\n year INT,\n PRIMARY KEY (band,album,song));\n</code></pre>\n<p>Now we&rsquo;ll add some data into that table:</p>\n<pre><code>INSERT INTO playlist (band,album,song,running_time,year)\n  VALUES ('Rush','Moving Pictures','Limelight','4:20',1981);\nINSERT INTO playlist (band,album,song,running_time,year)\n  VALUES ('Rush','Moving Pictures','Tom Sawyer','4:34',1981);\nINSERT INTO playlist (band,album,song,running_time,year)\n  VALUES ('Rush','Moving Pictures','Red Barchetta','6:10',1981);\nINSERT INTO playlist (band,album,song,running_time,year)\n  VALUES ('Rush','2112','2112','20:34',1976);\nINSERT INTO playlist (band,album,song,running_time,year)\n  VALUES ('Rush','Clockwork Angels','Seven Cities of Gold','6:32',2012);\nINSERT INTO playlist (band,album,song,running_time,year)\n  VALUES ('Coheed and Cambria','Burning Star IV','Welcome Home','6:15',2006);\n</code></pre>\n<h3>Cassandra storage model for early versions up to 2.2</h3>\n<p>The original underlying storage for Apache Cassandra was based on its<br />\nuse of the Thrift interface layer. If we were to look at how the<br />\nunderlying data was stored in older (pre-3.0) versions of Cassandra, we<br />\nwould see something similar to the following:</p>\n<p>Figure 3.1: Demonstration of how data was stored in the older storage<br />\nengine of Apache Cassandra. Notice that the data is partitioned<br />\n(co-located) by its row key, and then each column is ordered by the<br />\ncolumn keys.</p>\n<p><img src=\"https://raw.githubusercontent.com/fenago/apache-cassandra/master/images/1.jpg\" alt=\"\" /></p>\n<p>As you can see in the preceding screenshot, data is simply stored by its<br />\nrow key (also known as the <strong>partitioning key</strong>). Within each partition,<br />\ndata is stored ordered by its column keys, and finally by its (non-key)<br />\ncolumn names. This structure was sometimes referred to as a <strong>map of a<br />\nmap</strong>. The innermost section of the map, where the column values were<br />\nstored, was called a <strong>cell</strong>. Dealing with data like this proved to be<br />\nproblematic and required some understanding of the Thrift API to<br />\ncomplete basic operations.</p>\n<p>When CQL was introduced with Cassandra 1.2, it essentially abstracted<br />\nthe Thrift model in favor of a SQL-like interface, which was more<br />\nfamiliar to the database development community. This abstraction brought<br />\nabout the concept known as the <strong>CQL row</strong>. While the storage layer<br />\nstill viewed from the simple perspective of partitions and column<br />\nvalues, CQL introduced the row construct to Cassandra, if only at a<br />\nlogical level. This difference between the physical and logical models<br />\nof the Apache Cassandra storage engine was prevalent in major versions:<br />\n1.2, 2.0, 2.1, and 2.2.</p>\n<h4>Cassandra storage model for versions 3.0 and beyond</h4>\n<p>On the other hand, the new storage engine changes in Apache Cassandra<br />\n3.0 offer several improvements. With version 3.0 and up, stored data is<br />\nnow organized like this:</p>\n<p><img src=\"https://raw.githubusercontent.com/fenago/apache-cassandra/master/images/2.jpg\" alt=\"\" /></p>\n<p>Figure 3.2: Demonstration of how data is stored in the new storage<br />\nengine used by Apache Cassandra 3.0 and up. While data is still<br />\npartitioned in a similar manner, rows are now first-class citizens.</p>\n<p>The preceding figure shows that, while data is still partitioned<br />\nsimilarly to how it always was, there is a new structure present. The<br />\nrow is now part of the storage engine. This allows for the data model<br />\nand the Cassandra language drivers to deal with the underlying data<br />\nsimilar to how the storage engine does.</p>\n<h3>Note</h3>\n<p>An important aspect not pictured in the preceding screenshot is the fact<br />\nthat each row and column value has its own timestamp.</p>\n<p>In addition to rows becoming first-class citizens of the physical data<br />\nmodel, another change to the storage engine brought about a drastic<br />\nimprovement. As Apache Cassandra&rsquo;s original data model comes from more<br />\nof a key/value approach, every row is not required to have a value for<br />\nevery column in a table.</p>\n<p>The original storage engine allowed for this by repeating the column<br />\nnames and clustering keys with each column value. One way around<br />\nrepeating the column data was to use the<br />\n<code>WITH COMPACT STORAGE</code> directive at the time of table<br />\ncreation. However, this presented limitations around schema flexibility,<br />\nin that columns could no longer be added or removed.</p>\n<h3>Note</h3>\n<p>Do not use the <code>WITH COMPACT STORAGE</code> directive with Apache<br />\nCassandra version 3.0 or newer. It no longer provides any benefits, and<br />\nexists so that legacy users have an upgrade path.</p>\n<p>With Apache Cassandra 3.0, column names and clustering keys are no<br />\nlonger repeated with each column value. Depending on the data model,<br />\nthis can lead to a drastic difference in the disk footprint between<br />\nCassandra 3.0 and its prior versions.</p>\n<h3>Note</h3>\n<p>I have seen as much as a 90% reduction in disk footprint by upgrading<br />\nfrom Cassandra 2.x to Cassandra 3.0 and as little as 10% to 15%. Your<br />\nexperience may vary, depending on the number of columns in a table, size<br />\nof their names, and primary key definition.</p>\n<h4>Data cells</h4>\n<p>Sometimes structures for storing column values are referred to as<br />\n<strong>cells</strong>. Queries to Cassandra essentially return collections of cells.<br />\nAssume the following table definition for keeping track of weather<br />\nstation readings:</p>\n<pre><code>CREATE TABLE weather_data_by_date (\n  month BIGINT,\n  day BIGINT,\n  station_id UUID,\n  time timestamp,\n  temperature DOUBLE,\n  wind_speed DOUBLE,\n  PRIMARY KEY ((month,day),station_id,time));\n</code></pre>\n<p>In this model, the <code>month</code> and <code>day</code> keys are used<br />\nto make up a composite partition key. The clustering keys are<br />\n<code>station_id</code> and <code>time</code>. In this way, for each<br />\npartition, the number of cells will be equal to the total unique<br />\ncombinations of tuples:</p>\n<ul>\n<li><code>station_id</code>, <code>time</code>, <code>temperature</code></li>\n<li><code>station_id</code>, <code>time</code>, <code>wind_speed</code></li>\n</ul>\n<p>Understanding a cell comes into play when building data models. Apache<br />\nCassandra can only support 2,000,000,000 cells per partition. When data<br />\nmodelers fail to consider this, partitions can become large and<br />\nungainly, with query times eventually getting slower. This is why data<br />\nmodels that allow for unbound row growth are considered to be an<br />\nanti-pattern.</p>\n<h3>Note</h3>\n<p>The maximum of 2,000,000,000 cells per partition is a hard limit. But,<br />\npractically speaking, models that allow that many cells to be written to<br />\na single partition will become slow long before that limit is reached.</p>\n<h2>Getting started with CQL</h2>\n<hr />\n<p>With some quick definitions of CQL data modeling and cqlsh completed,<br />\nnow we&rsquo;ll take a look at CQL. The basic commands for creating data<br />\nstructures (keyspaces, tables, and so on) will be covered right away,<br />\nwith command complexity increasing as we build more useful structures.</p>\n<h3>Creating a keyspace</h3>\n<p>Keyspaces are analogous to the logical databases of the relational<br />\nworld. A keyspace contains tables, which are usually related to each<br />\nother by application, use case, or development team. When defining a<br />\nkeyspace, you also have the ability to control its replication behavior,<br />\nspecifying pairs of data center names and a numeric <strong>Replication<br />\nFactor</strong> (<strong>RF</strong>).</p>\n<p>Creating a keyspace is a simple operation and can be done like this:</p>\n<pre><code>CREATE KEYSPACE [IF NOT EXISTS] &lt;keyspace_name&gt;\n WITH replication =\n {'class': '&lt;replication_strategy&gt;',\n  '&lt;data_center_name&gt;':'&lt;replication_factor&gt;'}\n AND durable_writes = &lt;true/false&gt;;\n</code></pre>\n<p>Here is the detailed explanation of the preceding query:</p>\n<ul>\n<li><code>keyspace_name</code>: Valid keyspace names must be composed of<br />\nalphanumeric characters and underscores.</li>\n<li><code>replication_strategy</code>: Either <code>SimpleStrategy</code><br />\nor <code>NetworkTopologyStrategy</code>.</li>\n<li><code>data_center_name</code>: Valid only<br />\nfor <code>NetworkTopologyStrategy</code>, must be the name of a valid<br />\ndata center. If using <code>SimpleStrategy</code>, specify<br />\n<code>replication_factor</code>.</li>\n<li><code>replication_factor</code>: A numeric value representing the<br />\nnumber of replicas to write for the key with which it is paired.</li>\n<li><code>durable_writes</code>: A Boolean indicating whether writes<br />\nshould be written to the commit log. If not specified, this defaults<br />\nto <code>true</code>.</li>\n</ul>\n<h3>Note</h3>\n<p>Names for keyspaces, tables, columns, and custom structures in Apache<br />\nCassandra must be alphanumeric. The only exception to that rule is that<br />\nan underscore (<code>_</code>) is the only valid special character that<br />\ncan be used.</p>\n<h4>Single data center example</h4>\n<p>The following example will create the <code>fenago_ch3</code> keyspace.<br />\nWhen a write occurs, one replica will be written to the cluster. Writes<br />\nwill also be sent to the commit log for extra durability:</p>\n<pre><code>CREATE KEYSPACE IF NOT EXISTS fenago_ch3\n WITH replication =\n {'class': 'NetworkTopologyStrategy', 'ClockworkAngels':'1'}\n AND durable_writes = true;\n</code></pre>\n<h3>Note</h3>\n<p><code>SimpleStrategy</code> isn&rsquo;t very useful, so my advice is not to use<br />\nit. It&rsquo;s a good idea to get into the habit of using<br />\n<code>NetworkTopologyStrategy</code>, as that&rsquo;s the one that should be<br />\nused in production. <code>SimpleStrategy</code> offers no advantages over<br />\n<code>NetworkTopologyStrategy</code>, and using<br />\n<code>SimpleStrategy</code> can complicate converting into a multi-data<br />\ncenter environment later.</p>\n<h4>Multi-data center example</h4>\n<p>The following example will create the <code>fenago_ch3b</code> keyspace,<br />\nas long as it does not already exist. When a write occurs, two replicas<br />\nwill be written to the <code>ClockworkAngels</code> data center, and<br />\nthree will be written to the <code>PermanentWaves</code> and<br />\n<code>MovingPictures</code> data centers. Writes will also be sent to<br />\nthe commit log for extra durability:</p>\n<pre><code>CREATE KEYSPACE fenago_ch3_mdc\n WITH replication = {'class': 'NetworkTopologyStrategy',\n  'ClockworkAngels':'2', 'MovingPictures':'3', 'PermanentWaves':'3'}\n AND durable_writes = true;\n</code></pre>\n<p>Once you have created your keyspace, you can use it to avoid having to<br />\nkeep typing it later. Notice that this will also change your Command<br />\nPrompt:</p>\n<pre><code>cassdba@cqlsh&gt; use fenago_ch3 ;\ncassdba@cqlsh:fenago_ch3&gt;\n</code></pre>\n<h3>Creating a table</h3>\n<p>Data in Cassandra is organized into storage structures known as tables.<br />\nSome older documentation may refer to tables as column families. If<br />\nsomeone refers to column families, it is safe to assume that they are<br />\nreferring to structures in older versions of Apache Cassandra:</p>\n<pre><code>CREATE TABLE [IF NOT EXISTS] [keyspace_name.]&lt;table_name&gt;\n &lt;column_name&gt; &lt;column_type&gt;,\n [additional &lt;column_name&gt; &lt;column_type&gt;,]\n PRIMARY KEY ((&lt;partition_key&gt;[,additional &lt;partition_key&gt;])[,&lt;clustering_keys]);\n[WITH &lt;options&gt;];\n</code></pre>\n<h4>Simple table example</h4>\n<p>For a small table with simple query requirements, something like this<br />\nmight be sufficient:</p>\n<pre><code>CREATE TABLE users (\n username TEXT,\n email TEXT,\n department TEXT,\n title TEXT,\n ad_groups TEXT,\n PRIMARY KEY (username));\n</code></pre>\n<h4>Clustering key example</h4>\n<p>Let&rsquo;s say that we wanted to be able to offer up the same data, but to<br />\nsupport a query for users by department. The table definition would<br />\nchange to something like this:</p>\n<pre><code>CREATE TABLE users_by_dept (\n  username TEXT,\n  email TEXT,\n  department TEXT,\n  title TEXT,\n  AD_groups TEXT,\n  PRIMARY KEY ((department),username))\nWITH CLUSTERING ORDER BY (username ASC)\n  AND COMPACTION = {'class':'LeveledCompactionStrategy',\n  'sstable_size_in_mb':'200'};\n</code></pre>\n<p>As the preceding table will be read more than it will be written to<br />\n(users queried more often than they are added), we also designate use<br />\nof <code>LeveledCompactionStrategy</code>.</p>\n<h3>Note</h3>\n<p>The default compaction strategy is<br />\n<code>SizeTieredCompactionStrategy</code>, which tends to favor read and<br />\nwrite patterns that are either even (50% read, 50% write) or more<br />\nwrite-heavy.</p>\n<p>For a later example, let&rsquo;s write some data to that table:</p>\n<pre><code>INSERT INTO users_by_dept(department,username,title,email) VALUES ('Engineering','Dinesh','Dev Lead','dinesh@piedpiper.com');\nINSERT INTO users_by_dept(department,username,title,email) VALUES ('Engineering','Gilfoyle','Sys Admin/DBA','thedarkone@piedpiper.com');\nINSERT INTO users_by_dept(department,username,title,email) VALUES ('Engineering','Richard','CEO','richard@piedpiper.com');\nINSERT INTO users_by_dept(department,username,title,email) VALUES ('Marketing','Erlich','CMO','erlichb@aviato.com');\nINSERT INTO users_by_dept(department,username,title,email) VALUES ('Finance/HR','Jared','COO','donald@piedpiper.com');\n</code></pre>\n<h4>Composite partition key example</h4>\n<p>Solving data model problems attributed to unbound row growth can<br />\nsometimes be done by adding another partition key. Let&rsquo;s assume that we<br />\nwant to query security entrance logs for employees. If we were to use a<br />\nclustering key on a new column named time to one of the preceding<br />\nexamples, we would be continually adding cells to each partition. So<br />\nwe&rsquo;ll build this <code>PRIMARY KEY</code> to partition our data by<br />\n<code>entrance</code> and <code>day</code>, as well as cluster it on<br />\n<code>checkpoint_time</code> and <code>username</code>:</p>\n<pre><code>CREATE TABLE security_log (\n entrance TEXT,\n day BIGINT,\n checkpoint_time TIMESTAMP,\n username TEXT,\n email TEXT,\n department TEXT,\n title TEXT,\n PRIMARY KEY ((entrance,day),checkpoint_time,username))\nWITH CLUSTERING ORDER BY (checkpoint_time DESC, username ASC)\nAND default_time_to_live=2592000;\n</code></pre>\n<p>The preceding table will store data sorted within each partition by both<br />\n<code>checkpoint_time</code> and <code>username</code>. Note that, since<br />\nwe care more about the most recent data, we have designated the<br />\nclustering on <code>checkpoint_time</code> to be in descending order.<br />\nAdditionally, we&rsquo;ll assume we have a requirement to only keep security<br />\nlog data for the last 30 days, so we&rsquo;ll set<br />\n<code>default_time_to_live</code> to 30 days (<code>2592000</code><br />\nseconds).</p>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506765_750850516",
      "id": "paragraph_1591532800089_41274937",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "dateStarted": "2020-06-30T13:46:02+0000",
      "dateFinished": "2020-06-30T13:46:02+0000",
      "status": "FINISHED",
      "$$hashKey": "object:59"
    },
    {
      "text": "%cassandra\r\nCREATE KEYSPACE fenago_ch3 WITH replication =\r\n  {'class':'SimpleStrategy', 'replication_factor':1};",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:59:49+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/undefined",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506770_16913538",
      "id": "paragraph_1591536998472_1500850746",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:60"
    },
    {
      "text": "use fenago_ch3;\r\n\r\nCREATE TABLE playlist (\r\n band TEXT,\r\n album TEXT,\r\n song TEXT,\r\n running_time TEXT,\r\n year INT,\r\n PRIMARY KEY (band,album,song));",
      "user": "anonymous",
      "dateUpdated": "2020-06-30T13:33:16+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506770_2069477290",
      "id": "paragraph_1591536998467_-59616501",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:61"
    },
    {
      "text": "INSERT INTO playlist (band,album,song,running_time,year)\r\n  VALUES ('Rush','Moving Pictures','Limelight','4:20',1981);\r\nINSERT INTO playlist (band,album,song,running_time,year)\r\n  VALUES ('Rush','Moving Pictures','Tom Sawyer','4:34',1981);\r\nINSERT INTO playlist (band,album,song,running_time,year)\r\n  VALUES ('Rush','Moving Pictures','Red Barchetta','6:10',1981);\r\nINSERT INTO playlist (band,album,song,running_time,year)\r\n  VALUES ('Rush','2112','2112','20:34',1976);\r\nINSERT INTO playlist (band,album,song,running_time,year)\r\n  VALUES ('Rush','Clockwork Angels','Seven Cities of Gold','6:32',2012);\r\nINSERT INTO playlist (band,album,song,running_time,year)\r\n  VALUES ('Coheed and Cambria','Burning Star IV','Welcome Home','6:15',2006);",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506770_90691620",
      "id": "paragraph_1591536998647_-1404297703",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:62"
    },
    {
      "text": "CREATE TABLE weather_data_by_date (\r\n  month BIGINT,\r\n  day BIGINT,\r\n  station_id UUID,\r\n  time timestamp,\r\n  temperature DOUBLE,\r\n  wind_speed DOUBLE,\r\n  PRIMARY KEY ((month,day),station_id,time));",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506770_-1299105291",
      "id": "paragraph_1591536997928_-86545866",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:63"
    },
    {
      "text": "CREATE KEYSPACE IF NOT EXISTS fenago_ch3\r\n WITH replication =\r\n {'class':'SimpleStrategy', 'replication_factor':1}\r\n AND durable_writes = true;",
      "user": "anonymous",
      "dateUpdated": "2020-06-30T13:39:23+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506771_-438589695",
      "id": "paragraph_1591536997546_512276914",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:64"
    },
    {
      "text": "CREATE KEYSPACE fenago_ch3_mdc\r\n WITH replication =\r\n {'class':'SimpleStrategy', 'replication_factor':1}\r\n AND durable_writes = true;",
      "user": "anonymous",
      "dateUpdated": "2020-06-30T13:40:53+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506771_-14774108",
      "id": "paragraph_1591536998228_-1673860348",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:65"
    },
    {
      "text": "USE fenago_ch3 ;\r\n \r\nCREATE TABLE users (\r\n username TEXT,\r\n email TEXT,\r\n department TEXT,\r\n title TEXT,\r\n ad_groups TEXT,\r\n PRIMARY KEY (username));",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506771_-393022063",
      "id": "paragraph_1591536998071_-231882523",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:66"
    },
    {
      "text": "",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506772_-395260212",
      "id": "paragraph_1591536997366_-883758887",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:67"
    },
    {
      "text": "CREATE TABLE users_by_dept (\r\n  username TEXT,\r\n  email TEXT,\r\n  department TEXT,\r\n  title TEXT,\r\n  AD_groups TEXT,\r\n  PRIMARY KEY ((department),username))\r\nWITH CLUSTERING ORDER BY (username ASC)\r\n  AND COMPACTION = {'class':'LeveledCompactionStrategy',\r\n  'sstable_size_in_mb':'200'};",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506772_-1320883432",
      "id": "paragraph_1591536997858_-1654887668",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:68"
    },
    {
      "text": "INSERT INTO users_by_dept(department,username,title,email) VALUES ('Engineering','Dinesh','Dev Lead','dinesh@piedpiper.com');\r\nINSERT INTO users_by_dept(department,username,title,email) VALUES ('Engineering','Gilfoyle','Sys Admin/DBA','thedarkone@piedpiper.com');\r\nINSERT INTO users_by_dept(department,username,title,email) VALUES ('Engineering','Richard','CEO','richard@piedpiper.com');\r\nINSERT INTO users_by_dept(department,username,title,email) VALUES ('Marketing','Erlich','CMO','erlichb@aviato.com');\r\nINSERT INTO users_by_dept(department,username,title,email) VALUES ('Finance/HR','Jared','COO','donald@piedpiper.com');",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506773_-1031017756",
      "id": "paragraph_1591536997208_566503760",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:69"
    },
    {
      "text": "CREATE TABLE security_log (\r\n entrance TEXT,\r\n day BIGINT,\r\n checkpoint_time TIMESTAMP,\r\n username TEXT,\r\n email TEXT,\r\n department TEXT,\r\n title TEXT,\r\n PRIMARY KEY ((entrance,day),checkpoint_time,username))\r\nWITH CLUSTERING ORDER BY (checkpoint_time DESC, username ASC)\r\nAND default_time_to_live=2592000;",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506773_-1578364630",
      "id": "paragraph_1591536996908_2072041633",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:70"
    },
    {
      "text": "%md\n#### Table options\n\nThere are several options that can be adjusted at table-creation time.\nMost of these options are present on all tables. If they are omitted\nfrom table creation, their default values are assumed. The following are\na few of the table options: \n\n-   Clustering order specifies the column(s) and direction by which the\n    table data (within a partition) should be stored on disk. As\n    Cassandra stores data written sequentially, it's also faster when it\n    can read sequentially, so learning how to utilize clustering keys in\n    your models can help with performance:\n\n```\nCLUSTERING ORDER BY (<clustering_key_name <ASC|DESC>)\n```\n\n-   This setting represents the false positive probability for the\n    table's bloom filter. The value can range between `0.0`\n    and `1.0`, with a recommended setting of `0.1`\n    (10%):\n\n```\nbloom_filter_fp_chance = 0.1\n```\n\n-   The `caching` property dictates which caching features are\n    used by this table. There are two types of caching that can be used\n    by a table: **key caching** and **row caching**. Key caching is\n    enabled by default. Row caching can take up larger amounts of\n    resources, so it defaults to disabled or `NONE`:\n\n```\ncaching = {'keys': 'ALL', 'rows_per_partition': 'NONE'}\n```\n\n-   This property allows for the addition of `comment` or\n    description for the table, assuming that it is not clear from its\n    name:\n\n```\ncomment = ''\n```\n\n-   This enables the table for **Change Data Capture** (**CDC**) logging\n    and `cdc` defaults to `FALSE`:\n\n```\ncdc = FALSE\n```\n\n-   A map structure that allows for the configuration of the compaction\n    strategy, and the properties that govern it:\n\n```\ncompaction = {'class': 'org.apache.cassandra.db.compaction.LeveledCompactionStrategy'}\n```\n\nApache Cassandra 3.0 ships with three compaction strategies:\n\n-   `SizeTieredCompactionStrategy`: This is the default\n    strategy, and works well in most scenarios, specifically write-heavy\n    throughput patterns. It works by finding similarly-sized SSTable\n    files and combining them once they reach a certain size. If you\n    create a table without configuring compaction, it will be set to the\n    following options:\n\n```\ncompaction = {'class': 'org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy',\n 'max_threshold': '32', 'min_threshold': '4'}\n```\n\nUnder these settings, a minor compaction will trigger for the table when\nat least `4` (and no more than `32`) SSTables are\nfound to be within a calculated threshold of the average SSTable file\nsize.\n\n \n\n-   `LeveledCompactionStrategy`: The leveled compaction\n    strategy builds out SSTable files as levels, where each level is 10\n    times the size of the previous level. In this way, a row can be\n    guaranteed to be contained within a single SSTable file 90% of the\n    time. A typical leveled `compaction` config looks like\n    this:\n\n```\ncompaction = {'class': 'org.apache.cassandra.db.compaction.LeveledCompactionStrategy',\n 'sstable_size_in_mb': '160'}\n```\n\nLeveled `compaction` is a good idea for operational patterns\nwhere reads are twice (or more) as frequent as writes.\n\n-   `TimeWindowCompactionStrategy`: Time-window compaction\n    builds SSTable files according to time-based buckets. Rows are then\n    stored according to these (configurable) buckets. Configuration for\n    time window `compaction` looks like this:\n\n```\ncompaction = {'class': 'org.apache.cassandra.db.compaction.TimeWindowCompactionStrategy',\n 'compaction_window_unit': 'hours', 'compaction_window_size': '24'}\n```\n\nThis is especially useful for time-series data, as it allows data within\nthe same time period to be stored together.\n\n### Note\n\nTime-window compaction can greatly improve query performance (over other\nstrategies) for time-series data that uses **time to live** (**TTL**).\nThis ensures that data within a bucket is tombstoned together, and\ntherefore the TTL tombstones should not interfere with queries for newer\ndata.\n\n### Note\n\n`TimeWindowCompactionStrategy` is new as of Apache Cassandra\n3.0, and replaces `DateTieredCompactionStrategy`, which was\nshipped with Apache Cassandra 2.1 and 2.2.\n\n```\ncompression = {'chunk_length_in_kb': '64', 'class': 'org.apache.cassandra.io.compress.LZ4Compressor'}\n```\n\n \n\nThis property is another map structure that allows the compression\nsettings for a table to be configured. Apache Cassandra ships with three\ncompressor classes: `LZ4Compressor` (default),\n`SnappyCompressor`, and `DeflateCompressor`. Once\nthe class has been specified, `chunk_length` can also be\nspecified. By default, a table will use `LZ4Compressor`, and\nwill be configured as shown here:\n\n```\ncompression = {'class': 'org.apache.cassandra.io.compress.LZ4Compressor',\n 'chunk_length_in_kb': '64'}\n```\n\n### Note\n\nTo disable compression,\nspecify `compression = {'sstable_compression': ''}`.\n\nIt should be noted that the default `chunk_length_in_kb` of\n`64` is intended for write-heavy workloads.  Access patterns\nthat are more evenly read and write, or read-heavy may see a performance\nbenefit from bringing that value down to as low as four. As always, be\nsure to test significant changes, like this:\n\n```\ncrc_check_chance = 1.0\n```\n\nWith compression enabled, this property defines the probability that the\nCRC compression checksums will be verified on a read operation. The\ndefault value is `1.0`, or 100%:\n\n```\ndclocal_read_repair_chance = 0.1\n```\n\nThis property specifies the probability that a read repair will be\ninvoked on a read. The read repair will only be enforced within the same\n(local) data center:\n\n```\ndefault_time_to_live = 0\n```\n\nThis allows all data entered into a table to be automatically deleted\nafter a specified number of seconds. The default value is `0`,\nwhich disables TTL by default. TTLs can also be set from the application\nside, which will override this setting. The maximum value is\n`630720000`, or 20 years.\n\n### Note\n\nDon't forget that TTLs also create tombstones. So, if your table employs\na TTL, be sure to account for that in your overall data modeling\napproach.\n\n```\ngc_grace_seconds = 864000\n```\n\n \n\n \n\nThis property specifies the amount of time (in seconds) that tombstones\nin the table will persist before they are eligible for collection via\ncompaction. By default, this is set to `864000` seconds, or 10\ndays.\n\n### Note\n\nRemember that the 10 day default exists to give your cluster a chance to\nrun a repair. This is important, as all tombstones must be successfully\npropagated to avoid data ghosting its way back into a result set. If you\nplan to lower this value, make sure that you also increase the frequency\nby which the repair is run.\n\n```\nmin_index_interval & max_index_interval\n```\n\nThese properties work together to determine how many entries end up in\nthe table's index summary (in RAM). The more entries in the partition\nindex, the quicker a partition can be located during an operation. The\ntrade-off, is that more entries equal more RAM consumed. The actual\nvalue used is determined by how often the table is accessed. Default\nvalues for these properties are set as follows:\n\n```\nmax_index_interval = 2048\nmin_index_interval = 128\nmemtable_flush_period_in_ms = 0\n```\n\nThe number of milliseconds before the table's memtables are flushed from\nRAM to disk. The default is zero, effectively leaving the triggering of\nmemtable flushes up to the commit log and the defined value of\n`memtable_cleanup_threshold`:\n\n```\nread_repair_chance = 0.0\n```\n\nSimilar to `dclocal_read_repair_chance`, this setting\nspecifies the probability that a cross-data center read repair will be\ninvoked. This defaults to zero (0.0), to ensure that read repairs are\nlimited to a single data center at a time (and therefore less\nexpensive):\n\n```\nspeculative_retry = '99PERCENTILE';\n```\n\nThis property configures rapid read protection, in that read requests\nare sent to other replicas despite their consistency requirements having\nbeen met. This property has four possible values:\n\n-   `ALWAYS`: Every ready sends additional read requests to\n    other replicas.\n-   `XPERCENTILE`: Sends additional read requests only for\n    requests that are determined to be in the slowest X percentile. The\n    default value for this property is `99PERCENTILE`, which\n    will trigger additional replica reads for request latencies in the\n    99^th^ percentile, based on past performance of reads for that\n    table.\n-   `XMS`: Sends additional replica reads for requests that do\n    not complete within X milliseconds.\n-   `NONE`: Disables this functionality.\n\n### Data types\n\nApache Cassandra comes with many common types that can help you with\nefficient data storage and representation. As Cassandra is written in\nJava, the Cassandra data types correlate directly to Java data types:\n\n![](https://raw.githubusercontent.com/fenago/apache-cassandra/master/images/8_1_1.png)\n\n![](https://raw.githubusercontent.com/fenago/apache-cassandra/master/images/8_1_2.png)\n\n#### Type conversion\n\nOne common point of consternation for many folks new to Cassandra is\nconverting between types. This can be done either by altering the\nexisting table, or coercing the results at query-time with\n`CAST`. While some of the types may seem interchangeable,\nissues can arise when converting between types where the target type\ncannot support the amount of precision required. The following type\nconversions can be done without issue:\n\n![](https://raw.githubusercontent.com/fenago/apache-cassandra/master/images/8_2.png)\n\nSome notes about CQL data type conversion:\n\n![](https://raw.githubusercontent.com/fenago/apache-cassandra/master/images/8_3.png)\n\n### The primary key\n\nThe most important part of designing your data model is how you define\nthe primary key of your tables. As mentioned previously in this lab,\nprimary keys are built at table-creation time, and have the following\noptions:\n\n```\nPRIMARY KEY ((<partition_key>[,additional <partition_key>])[,<clustering_keys])\n```\n\nTables in Apache Cassandra may have (both) multiple partition and\nclustering keys. As previously mentioned, the partition keys determine\nwhich nodes are responsible for a row and its replicas. The clustering\nkeys determine the on-disk sort order within a partition.\n\n \n\n#### Designing a primary key\n\nWhen designing a primary key, Cassandra modelers should have two main\nconsiderations:\n\n-   Does this primary key allow for even distribution, at scale?\n-   Does this primary key match the required query pattern(s), at scale?\n\nNote that on the end of each statement is the phrase at scale. A model\nthat writes all of its table's data into a single partition distributes\nevenly when you have a 3-node cluster. But it doesn't evenly distribute\nwhen you scale up to a 30-node cluster. Plus, that type of model puts\nyour table in danger of approaching the limit of 2,000,000,000 cells per\npartition. Likewise, almost any model will support high-performing\nunbound queries (queries without a `WHERE` clause) when they\nhave 10 rows across the (aforementioned) 3-node cluster. But increase\nthat to 10,000,000,000 rows across 30 nodes, and watch the bad queries\nstart to time out.\n\nApache Cassandra is a great tool for supporting large amounts of data at\nlarge scale. But simply using Cassandra for that task is not enough.\nYour tables must be designed to take advantage of Cassandra’s storage\nand distribution model, or trouble will quickly ensue.\n\n##### Selecting a good partition key\n\nSo, how do we pick a partition key that distributes well at scale? \nMinding your model’s potential cardinality is the key. The cardinality\nof a partition key represents the number of possible values of the key,\nranging from one to infinity.\n\n### Note\n\nAvoid extreme ends of cardinality. Boolean columns should not be used as\na single partition key (results in only two partitions). Likewise, you\nmay want to avoid UUIDs or any kind of unique identifier as a single\npartition key, as its high cardinality will limit potential query\npatterns.\n\nA bad partition key is easy to spot, with proper knowledge of the\nbusiness or use case.  For instance, if I wanted to be able to query all\nproducts found in a particular store, store would seem like a good\npartition key.  However, if a retailer has 1,000,000 products, all of\nwhich are sold in all 3 of their stores, that's obviously not going to\ndistribute well.\n\n \n\nLet's think about a time-series model. If I'm going to keep track of\nsecurity logs for a company's employees (with multiple locations), I may\nthink about building a model like this:\n\n```\nCREATE TABLE security_logs_by_location (\n  employee_id TEXT,\n  time_in TIMESTAMP,\n  location_id TEXT,\n  mailstop TEXT,\n  PRIMARY KEY (location_id, time_in, employee_id));\n```\n\nThis will store the times that each employee enters by location. And if\nI want to query by a specific location, this may work for query\nrequirements. The problem is that, with each write, the\n`location_id` partition will get bigger and bigger.\nEventually, too many employees will check in at a certain location, and\nthe partition will get too big and become unable to be queried.  This is\na common Cassandra modeling anti-pattern, known as **unbound row\ngrowth**.\n\n### Note\n\nCardinality may also be an issue with `location_id`. If the\ncompany in question has 20-50 locations, this might not be so bad. But\nif it only has two, this model won’t distribute well at all. That's\nwhere knowing and understanding the business requirements comes into\nplay.\n\nTo fix unbound row growth, we can apply a technique called\n**bucketing**. Let's assume that we know that each building location\nwill only have 300 employees enter each day. That means if we could\npartition our table by day, we would never have much more than 300 rows\nin each partition. We can do that by introducing a day bucket into the\nmodel, resulting in a composite partition key:\n\n```\nDROP TABLE security_logs_by_location;\n\nCREATE TABLE security_logs_by_location (\n employee_id TEXT,\n time_in TIMESTAMP,\n location_id TEXT,\n day INT,\n mailstop TEXT,\n PRIMARY KEY ((location_id, day), time_in, employee_id));\n```\n\n### Note\n\nCreating a compound partition key is as simple as specifying the\ncomma-delimited partition keys inside parentheses.\n\nNow when I insert into this table and query it, it looks something like\nthis:\n\n```\nINSERT INTO security_logs_by_location (location_id,day,time_in,employee_id,mailstop)\nVALUES ('MPLS2',20180723,'2018-07-23 11:04:22.432','aaronp','M266');\n\nSELECT * FROM security_logs_by_location ;\n\n location_id | day      | time_in                         | employee_id | mailstop\n-------------+----------+---------------------------------+-------------+----------\n       MPLS2 | 20180723 | 2018-07-23 12:04:22.432000+0000 |      aaronp |     M266\n\n(1 rows)\n```\n\nNow my application can write as many rows as it needs to, without\nworrying about running into too many cells per partition. The trade-off\nis that when I query this table, I'll need to specify the location and\nday. But business-reporting requirements typically (in this hypothetical\nuse case) require querying data only for a specific day, so that will\nwork.\n\n##### Selecting a good clustering key\n\nAs mentioned previously, clustering determine the on-disk sort order for\nrows within a partition. But a good clustering key can also help to\nensure uniqueness among the rows. Consider the table used in the\npreceding examples. This section will make more sense with more data, so\nlet’s start by adding a few more rows:\n\n```\nINSERT INTO security_logs_by_location (location_id,day,time_in,employee_id,mailstop)\n VALUES ('MPLS2',20180723,'2018-07-23 9:04:59.377','tejam','M266');\nINSERT INTO security_logs_by_location (location_id,day,time_in,employee_id,mailstop)\n VALUES ('MPLS2',20180723,'2018-07-23 7:17:38.268','jeffb','M266');\nINSERT INTO security_logs_by_location (location_id,day,time_in,employee_id,mailstop)\n VALUES ('MPLS2',20180723,'2018-07-23 7:01:18.163','sandrak','M266');\nINSERT INTO security_logs_by_location (location_id,day,time_in,employee_id,mailstop)\n VALUES ('MPLS2',20180723,'2018-07-23 6:49:11.754','samb','M266');\nINSERT INTO security_logs_by_location (location_id,day,time_in,employee_id,mailstop)\n VALUES ('MPLS2',20180723,'2018-07-23 7:08:24.682','johno','M261');\nINSERT INTO security_logs_by_location (location_id,day,time_in,employee_id,mailstop)\n VALUES ('MPLS2',20180723,'2018-07-23 7:55:45.911','tedk','M266');\n```\n\nNow, I'll query the table for all employees entering\nthe `MPLS2` building between 6 AM and 10 AM, on July 23, 2018:\n\n```\nSELECT * FROM security_logs_by_location\nWHERE location_id='MPLS2'\nAND day=20180723 AND time_in > '2018-07-23 6:00'\nAND time_in < '2018-07-23 10:00';\n\n location_id | day      | time_in                         | employee_id | mailstop\n-------------+----------+---------------------------------+-------------+----------\n       MPLS2 | 20180723 | 2018-07-23 11:49:11.754000+0000 |        samb | M266\n       MPLS2 | 20180723 | 2018-07-23 12:01:18.163000+0000 |     sandrak | M266\n       MPLS2 | 20180723 | 2018-07-23 12:04:22.432000+0000 |      aaronp | M266\n       MPLS2 | 20180723 | 2018-07-23 12:08:24.682000+0000 |       johno | M261\n       MPLS2 | 20180723 | 2018-07-23 12:17:38.268000+0000 |       jeffb | M266\n       MPLS2 | 20180723 | 2018-07-23 12:55:45.911000+0000 |        tedk | M266\n       MPLS2 | 20180723 | 2018-07-23 14:04:59.377000+0000 |       tejam | M266\n\n(7 rows)\n```\n\nHere are some things to note about the preceding result set:\n\n-   As required by the table's `PRIMARY KEY`, I have filtered\n    my `WHERE` clause on the complete partition key\n    (`location_id` and `day`)\n-   I did not specify the complete PRIMARY KEY, choosing to omit\n    `employee_id`\n-   The results are sorted by `time_in`, in ascending order; I\n    did not specify `ORDER BY`\n-   I specified a range on `time_in`, mentioning it twice in\n    the `WHERE` clause, instructing Cassandra to return a\n    range of data\n-   While Cassandra is aware of my system's time zone, the\n    `time_in` timestamp is shown in UTC time\n\nAs per my clustering key definition, my result set was sorted by the\n`time_in` column, with the oldest value at the top.  This is\nbecause, while I did clearly specify my clustering keys, I did not\nspecify the sort order.  Therefore, it defaulted to ascending order.\n\nAdditionally, I omitted the `employee_id` key. I can do that\nbecause I specified the keys that preceded it.  If I opted to skip\n`time_in` and specify `employee_id`, this query\nwould fail. There's more on that later.\n\nSo why make `employee_id` part of PRIMARY KEY? It helps to\nensure uniqueness. After all, if two employees came through security at\nthe exact same time, their writes to the table would conflict. Although\nunlikely, designating `employee_id` as the last clustering key\nhelps to ensure that a last-write-wins scenario does not occur.\n\nAnother good question to ask would be, if Cassandra requires specific\nkeys, how can range query be made to work. Recall that Apache Cassandra\nis built on a log-based storage engine (LSM tree). This means that\nbuilding a table to return data in the order in which it is written\nactually coincides with how Cassandra was designed to work. Cassandra\nhas problems when it is made to serve random reads but sequential reads\nactually work quite well.\n\nNow assume that the requirements change slightly, in that the result set\nneeds to be in descending order. How can we solve for that? Well, we\ncould specify an `ORDER BY` clause at query time, but flipping\nthe sort direction of a large result set can be costly for performance.\nWhat is the best way to solve that? By creating a table designed to\nserve that query naturally, of course:\n\n```\nCREATE TABLE security_logs_by_location_desc (\n  employee_id TEXT,\n  time_in TIMESTAMP,\n  location_id TEXT,\n  day INT,\n  mailstop TEXT,\n  PRIMARY KEY ((location_id, day), time_in, employee_id))\nWITH CLUSTERING ORDER BY (time_in DESC, employee_id ASC);\n```\n\n \n\n \n\nIf I duplicate my data into this table as well, I can run that same\nquery and get my result set in descending order:\n\n```\nINSERT INTO security_logs_by_location_desc (location_id,day,time_in,employee_id,mailstop)\n VALUES ('MPLS2',20180723,'2018-07-23 9:04:59.377','tejam','M266');\nINSERT INTO security_logs_by_location_desc (location_id,day,time_in,employee_id,mailstop)\n VALUES ('MPLS2',20180723,'2018-07-23 7:17:38.268','jeffb','M266');\nINSERT INTO security_logs_by_location_desc (location_id,day,time_in,employee_id,mailstop)\n VALUES ('MPLS2',20180723,'2018-07-23 7:01:18.163','sandrak','M266');\nINSERT INTO security_logs_by_location_desc (location_id,day,time_in,employee_id,mailstop)\n VALUES ('MPLS2',20180723,'2018-07-23 6:49:11.754','samb','M266');\nINSERT INTO security_logs_by_location_desc (location_id,day,time_in,employee_id,mailstop)\n VALUES ('MPLS2',20180723,'2018-07-23 7:08:24.682','johno','M261');\nINSERT INTO security_logs_by_location_desc (location_id,day,time_in,employee_id,mailstop)\n VALUES ('MPLS2',20180723,'2018-07-23 7:55:45.911','tedk','M266');\n\nSELECT * FROM security_logs_by_location_desc\nWHERE location_id='MPLS2'\nAND day=20180723\nAND time_in > '2018-07-23 6:00' AND time_in < '2018-07-23 10:00';\n\n location_id | day      | time_in                         | employee_id | mailstop\n-------------+----------+---------------------------------+-------------+----------\n       MPLS2 | 20180723 | 2018-07-23 14:04:59.377000+0000 |       tejam | M266\n       MPLS2 | 20180723 | 2018-07-23 12:55:45.911000+0000 |        tedk | M266\n       MPLS2 | 20180723 | 2018-07-23 12:17:38.268000+0000 |       jeffb | M266\n       MPLS2 | 20180723 | 2018-07-23 12:08:24.682000+0000 |       johno | M261\n       MPLS2 | 20180723 | 2018-07-23 12:04:22.432000+0000 |      aaronp | M266\n       MPLS2 | 20180723 | 2018-07-23 12:01:18.163000+0000 |     sandrak | M266\n       MPLS2 | 20180723 | 2018-07-23 11:49:11.754000+0000 |        samb | M266\n\n(7 rows)\n```\n\n \n\nIn this way, it is clear how picking the right clustering keys (and sort\ndirection) also plays a part in designing tables that will perform well\nat scale.\n",
      "user": "anonymous",
      "dateUpdated": "2020-06-30T13:29:31+0000",
      "config": {
        "colWidth": 12,
        "fontSize": 9,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false
        },
        "editorMode": "ace/mode/text",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<h4>Table options</h4>\n<p>There are several options that can be adjusted at table-creation time.<br />\nMost of these options are present on all tables. If they are omitted<br />\nfrom table creation, their default values are assumed. The following are<br />\na few of the table options:</p>\n<ul>\n<li>Clustering order specifies the column(s) and direction by which the<br />\ntable data (within a partition) should be stored on disk. As<br />\nCassandra stores data written sequentially, it&rsquo;s also faster when it<br />\ncan read sequentially, so learning how to utilize clustering keys in<br />\nyour models can help with performance:</li>\n</ul>\n<pre><code>CLUSTERING ORDER BY (&lt;clustering_key_name &lt;ASC|DESC&gt;)\n</code></pre>\n<ul>\n<li>This setting represents the false positive probability for the<br />\ntable&rsquo;s bloom filter. The value can range between <code>0.0</code><br />\nand <code>1.0</code>, with a recommended setting of <code>0.1</code><br />\n(10%):</li>\n</ul>\n<pre><code>bloom_filter_fp_chance = 0.1\n</code></pre>\n<ul>\n<li>The <code>caching</code> property dictates which caching features are<br />\nused by this table. There are two types of caching that can be used<br />\nby a table: <strong>key caching</strong> and <strong>row caching</strong>. Key caching is<br />\nenabled by default. Row caching can take up larger amounts of<br />\nresources, so it defaults to disabled or <code>NONE</code>:</li>\n</ul>\n<pre><code>caching = {'keys': 'ALL', 'rows_per_partition': 'NONE'}\n</code></pre>\n<ul>\n<li>This property allows for the addition of <code>comment</code> or<br />\ndescription for the table, assuming that it is not clear from its<br />\nname:</li>\n</ul>\n<pre><code>comment = ''\n</code></pre>\n<ul>\n<li>This enables the table for <strong>Change Data Capture</strong> (<strong>CDC</strong>) logging<br />\nand <code>cdc</code> defaults to <code>FALSE</code>:</li>\n</ul>\n<pre><code>cdc = FALSE\n</code></pre>\n<ul>\n<li>A map structure that allows for the configuration of the compaction<br />\nstrategy, and the properties that govern it:</li>\n</ul>\n<pre><code>compaction = {'class': 'org.apache.cassandra.db.compaction.LeveledCompactionStrategy'}\n</code></pre>\n<p>Apache Cassandra 3.0 ships with three compaction strategies:</p>\n<ul>\n<li><code>SizeTieredCompactionStrategy</code>: This is the default<br />\nstrategy, and works well in most scenarios, specifically write-heavy<br />\nthroughput patterns. It works by finding similarly-sized SSTable<br />\nfiles and combining them once they reach a certain size. If you<br />\ncreate a table without configuring compaction, it will be set to the<br />\nfollowing options:</li>\n</ul>\n<pre><code>compaction = {'class': 'org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy',\n 'max_threshold': '32', 'min_threshold': '4'}\n</code></pre>\n<p>Under these settings, a minor compaction will trigger for the table when<br />\nat least <code>4</code> (and no more than <code>32</code>) SSTables are<br />\nfound to be within a calculated threshold of the average SSTable file<br />\nsize.</p>\n<ul>\n<li><code>LeveledCompactionStrategy</code>: The leveled compaction<br />\nstrategy builds out SSTable files as levels, where each level is 10<br />\ntimes the size of the previous level. In this way, a row can be<br />\nguaranteed to be contained within a single SSTable file 90% of the<br />\ntime. A typical leveled <code>compaction</code> config looks like<br />\nthis:</li>\n</ul>\n<pre><code>compaction = {'class': 'org.apache.cassandra.db.compaction.LeveledCompactionStrategy',\n 'sstable_size_in_mb': '160'}\n</code></pre>\n<p>Leveled <code>compaction</code> is a good idea for operational patterns<br />\nwhere reads are twice (or more) as frequent as writes.</p>\n<ul>\n<li><code>TimeWindowCompactionStrategy</code>: Time-window compaction<br />\nbuilds SSTable files according to time-based buckets. Rows are then<br />\nstored according to these (configurable) buckets. Configuration for<br />\ntime window <code>compaction</code> looks like this:</li>\n</ul>\n<pre><code>compaction = {'class': 'org.apache.cassandra.db.compaction.TimeWindowCompactionStrategy',\n 'compaction_window_unit': 'hours', 'compaction_window_size': '24'}\n</code></pre>\n<p>This is especially useful for time-series data, as it allows data within<br />\nthe same time period to be stored together.</p>\n<h3>Note</h3>\n<p>Time-window compaction can greatly improve query performance (over other<br />\nstrategies) for time-series data that uses <strong>time to live</strong> (<strong>TTL</strong>).<br />\nThis ensures that data within a bucket is tombstoned together, and<br />\ntherefore the TTL tombstones should not interfere with queries for newer<br />\ndata.</p>\n<h3>Note</h3>\n<p><code>TimeWindowCompactionStrategy</code> is new as of Apache Cassandra<br />\n3.0, and replaces <code>DateTieredCompactionStrategy</code>, which was<br />\nshipped with Apache Cassandra 2.1 and 2.2.</p>\n<pre><code>compression = {'chunk_length_in_kb': '64', 'class': 'org.apache.cassandra.io.compress.LZ4Compressor'}\n</code></pre>\n<p>This property is another map structure that allows the compression<br />\nsettings for a table to be configured. Apache Cassandra ships with three<br />\ncompressor classes: <code>LZ4Compressor</code> (default),<br />\n<code>SnappyCompressor</code>, and <code>DeflateCompressor</code>. Once<br />\nthe class has been specified, <code>chunk_length</code> can also be<br />\nspecified. By default, a table will use <code>LZ4Compressor</code>, and<br />\nwill be configured as shown here:</p>\n<pre><code>compression = {'class': 'org.apache.cassandra.io.compress.LZ4Compressor',\n 'chunk_length_in_kb': '64'}\n</code></pre>\n<h3>Note</h3>\n<p>To disable compression,<br />\nspecify <code>compression = {'sstable_compression': ''}</code>.</p>\n<p>It should be noted that the default <code>chunk_length_in_kb</code> of<br />\n<code>64</code> is intended for write-heavy workloads.  Access patterns<br />\nthat are more evenly read and write, or read-heavy may see a performance<br />\nbenefit from bringing that value down to as low as four. As always, be<br />\nsure to test significant changes, like this:</p>\n<pre><code>crc_check_chance = 1.0\n</code></pre>\n<p>With compression enabled, this property defines the probability that the<br />\nCRC compression checksums will be verified on a read operation. The<br />\ndefault value is <code>1.0</code>, or 100%:</p>\n<pre><code>dclocal_read_repair_chance = 0.1\n</code></pre>\n<p>This property specifies the probability that a read repair will be<br />\ninvoked on a read. The read repair will only be enforced within the same<br />\n(local) data center:</p>\n<pre><code>default_time_to_live = 0\n</code></pre>\n<p>This allows all data entered into a table to be automatically deleted<br />\nafter a specified number of seconds. The default value is <code>0</code>,<br />\nwhich disables TTL by default. TTLs can also be set from the application<br />\nside, which will override this setting. The maximum value is<br />\n<code>630720000</code>, or 20 years.</p>\n<h3>Note</h3>\n<p>Don&rsquo;t forget that TTLs also create tombstones. So, if your table employs<br />\na TTL, be sure to account for that in your overall data modeling<br />\napproach.</p>\n<pre><code>gc_grace_seconds = 864000\n</code></pre>\n<p>This property specifies the amount of time (in seconds) that tombstones<br />\nin the table will persist before they are eligible for collection via<br />\ncompaction. By default, this is set to <code>864000</code> seconds, or 10<br />\ndays.</p>\n<h3>Note</h3>\n<p>Remember that the 10 day default exists to give your cluster a chance to<br />\nrun a repair. This is important, as all tombstones must be successfully<br />\npropagated to avoid data ghosting its way back into a result set. If you<br />\nplan to lower this value, make sure that you also increase the frequency<br />\nby which the repair is run.</p>\n<pre><code>min_index_interval &amp; max_index_interval\n</code></pre>\n<p>These properties work together to determine how many entries end up in<br />\nthe table&rsquo;s index summary (in RAM). The more entries in the partition<br />\nindex, the quicker a partition can be located during an operation. The<br />\ntrade-off, is that more entries equal more RAM consumed. The actual<br />\nvalue used is determined by how often the table is accessed. Default<br />\nvalues for these properties are set as follows:</p>\n<pre><code>max_index_interval = 2048\nmin_index_interval = 128\nmemtable_flush_period_in_ms = 0\n</code></pre>\n<p>The number of milliseconds before the table&rsquo;s memtables are flushed from<br />\nRAM to disk. The default is zero, effectively leaving the triggering of<br />\nmemtable flushes up to the commit log and the defined value of<br />\n<code>memtable_cleanup_threshold</code>:</p>\n<pre><code>read_repair_chance = 0.0\n</code></pre>\n<p>Similar to <code>dclocal_read_repair_chance</code>, this setting<br />\nspecifies the probability that a cross-data center read repair will be<br />\ninvoked. This defaults to zero (0.0), to ensure that read repairs are<br />\nlimited to a single data center at a time (and therefore less<br />\nexpensive):</p>\n<pre><code>speculative_retry = '99PERCENTILE';\n</code></pre>\n<p>This property configures rapid read protection, in that read requests<br />\nare sent to other replicas despite their consistency requirements having<br />\nbeen met. This property has four possible values:</p>\n<ul>\n<li><code>ALWAYS</code>: Every ready sends additional read requests to<br />\nother replicas.</li>\n<li><code>XPERCENTILE</code>: Sends additional read requests only for<br />\nrequests that are determined to be in the slowest X percentile. The<br />\ndefault value for this property is <code>99PERCENTILE</code>, which<br />\nwill trigger additional replica reads for request latencies in the<br />\n99^th^ percentile, based on past performance of reads for that<br />\ntable.</li>\n<li><code>XMS</code>: Sends additional replica reads for requests that do<br />\nnot complete within X milliseconds.</li>\n<li><code>NONE</code>: Disables this functionality.</li>\n</ul>\n<h3>Data types</h3>\n<p>Apache Cassandra comes with many common types that can help you with<br />\nefficient data storage and representation. As Cassandra is written in<br />\nJava, the Cassandra data types correlate directly to Java data types:</p>\n<p><img src=\"https://raw.githubusercontent.com/fenago/apache-cassandra/master/images/8_1_1.png\" alt=\"\" /></p>\n<p><img src=\"https://raw.githubusercontent.com/fenago/apache-cassandra/master/images/8_1_2.png\" alt=\"\" /></p>\n<h4>Type conversion</h4>\n<p>One common point of consternation for many folks new to Cassandra is<br />\nconverting between types. This can be done either by altering the<br />\nexisting table, or coercing the results at query-time with<br />\n<code>CAST</code>. While some of the types may seem interchangeable,<br />\nissues can arise when converting between types where the target type<br />\ncannot support the amount of precision required. The following type<br />\nconversions can be done without issue:</p>\n<p><img src=\"https://raw.githubusercontent.com/fenago/apache-cassandra/master/images/8_2.png\" alt=\"\" /></p>\n<p>Some notes about CQL data type conversion:</p>\n<p><img src=\"https://raw.githubusercontent.com/fenago/apache-cassandra/master/images/8_3.png\" alt=\"\" /></p>\n<h3>The primary key</h3>\n<p>The most important part of designing your data model is how you define<br />\nthe primary key of your tables. As mentioned previously in this lab,<br />\nprimary keys are built at table-creation time, and have the following<br />\noptions:</p>\n<pre><code>PRIMARY KEY ((&lt;partition_key&gt;[,additional &lt;partition_key&gt;])[,&lt;clustering_keys])\n</code></pre>\n<p>Tables in Apache Cassandra may have (both) multiple partition and<br />\nclustering keys. As previously mentioned, the partition keys determine<br />\nwhich nodes are responsible for a row and its replicas. The clustering<br />\nkeys determine the on-disk sort order within a partition.</p>\n<h4>Designing a primary key</h4>\n<p>When designing a primary key, Cassandra modelers should have two main<br />\nconsiderations:</p>\n<ul>\n<li>Does this primary key allow for even distribution, at scale?</li>\n<li>Does this primary key match the required query pattern(s), at scale?</li>\n</ul>\n<p>Note that on the end of each statement is the phrase at scale. A model<br />\nthat writes all of its table&rsquo;s data into a single partition distributes<br />\nevenly when you have a 3-node cluster. But it doesn&rsquo;t evenly distribute<br />\nwhen you scale up to a 30-node cluster. Plus, that type of model puts<br />\nyour table in danger of approaching the limit of 2,000,000,000 cells per<br />\npartition. Likewise, almost any model will support high-performing<br />\nunbound queries (queries without a <code>WHERE</code> clause) when they<br />\nhave 10 rows across the (aforementioned) 3-node cluster. But increase<br />\nthat to 10,000,000,000 rows across 30 nodes, and watch the bad queries<br />\nstart to time out.</p>\n<p>Apache Cassandra is a great tool for supporting large amounts of data at<br />\nlarge scale. But simply using Cassandra for that task is not enough.<br />\nYour tables must be designed to take advantage of Cassandra’s storage<br />\nand distribution model, or trouble will quickly ensue.</p>\n<h5>Selecting a good partition key</h5>\n<p>So, how do we pick a partition key that distributes well at scale?<br />\nMinding your model’s potential cardinality is the key. The cardinality<br />\nof a partition key represents the number of possible values of the key,<br />\nranging from one to infinity.</p>\n<h3>Note</h3>\n<p>Avoid extreme ends of cardinality. Boolean columns should not be used as<br />\na single partition key (results in only two partitions). Likewise, you<br />\nmay want to avoid UUIDs or any kind of unique identifier as a single<br />\npartition key, as its high cardinality will limit potential query<br />\npatterns.</p>\n<p>A bad partition key is easy to spot, with proper knowledge of the<br />\nbusiness or use case.  For instance, if I wanted to be able to query all<br />\nproducts found in a particular store, store would seem like a good<br />\npartition key.  However, if a retailer has 1,000,000 products, all of<br />\nwhich are sold in all 3 of their stores, that&rsquo;s obviously not going to<br />\ndistribute well.</p>\n<p>Let&rsquo;s think about a time-series model. If I&rsquo;m going to keep track of<br />\nsecurity logs for a company&rsquo;s employees (with multiple locations), I may<br />\nthink about building a model like this:</p>\n<pre><code>CREATE TABLE security_logs_by_location (\n  employee_id TEXT,\n  time_in TIMESTAMP,\n  location_id TEXT,\n  mailstop TEXT,\n  PRIMARY KEY (location_id, time_in, employee_id));\n</code></pre>\n<p>This will store the times that each employee enters by location. And if<br />\nI want to query by a specific location, this may work for query<br />\nrequirements. The problem is that, with each write, the<br />\n<code>location_id</code> partition will get bigger and bigger.<br />\nEventually, too many employees will check in at a certain location, and<br />\nthe partition will get too big and become unable to be queried.  This is<br />\na common Cassandra modeling anti-pattern, known as <strong>unbound row<br />\ngrowth</strong>.</p>\n<h3>Note</h3>\n<p>Cardinality may also be an issue with <code>location_id</code>. If the<br />\ncompany in question has 20-50 locations, this might not be so bad. But<br />\nif it only has two, this model won’t distribute well at all. That&rsquo;s<br />\nwhere knowing and understanding the business requirements comes into<br />\nplay.</p>\n<p>To fix unbound row growth, we can apply a technique called<br />\n<strong>bucketing</strong>. Let&rsquo;s assume that we know that each building location<br />\nwill only have 300 employees enter each day. That means if we could<br />\npartition our table by day, we would never have much more than 300 rows<br />\nin each partition. We can do that by introducing a day bucket into the<br />\nmodel, resulting in a composite partition key:</p>\n<pre><code>DROP TABLE security_logs_by_location;\n\nCREATE TABLE security_logs_by_location (\n employee_id TEXT,\n time_in TIMESTAMP,\n location_id TEXT,\n day INT,\n mailstop TEXT,\n PRIMARY KEY ((location_id, day), time_in, employee_id));\n</code></pre>\n<h3>Note</h3>\n<p>Creating a compound partition key is as simple as specifying the<br />\ncomma-delimited partition keys inside parentheses.</p>\n<p>Now when I insert into this table and query it, it looks something like<br />\nthis:</p>\n<pre><code>INSERT INTO security_logs_by_location (location_id,day,time_in,employee_id,mailstop)\nVALUES ('MPLS2',20180723,'2018-07-23 11:04:22.432','aaronp','M266');\n\nSELECT * FROM security_logs_by_location ;\n\n location_id | day      | time_in                         | employee_id | mailstop\n-------------+----------+---------------------------------+-------------+----------\n       MPLS2 | 20180723 | 2018-07-23 12:04:22.432000+0000 |      aaronp |     M266\n\n(1 rows)\n</code></pre>\n<p>Now my application can write as many rows as it needs to, without<br />\nworrying about running into too many cells per partition. The trade-off<br />\nis that when I query this table, I&rsquo;ll need to specify the location and<br />\nday. But business-reporting requirements typically (in this hypothetical<br />\nuse case) require querying data only for a specific day, so that will<br />\nwork.</p>\n<h5>Selecting a good clustering key</h5>\n<p>As mentioned previously, clustering determine the on-disk sort order for<br />\nrows within a partition. But a good clustering key can also help to<br />\nensure uniqueness among the rows. Consider the table used in the<br />\npreceding examples. This section will make more sense with more data, so<br />\nlet’s start by adding a few more rows:</p>\n<pre><code>INSERT INTO security_logs_by_location (location_id,day,time_in,employee_id,mailstop)\n VALUES ('MPLS2',20180723,'2018-07-23 9:04:59.377','tejam','M266');\nINSERT INTO security_logs_by_location (location_id,day,time_in,employee_id,mailstop)\n VALUES ('MPLS2',20180723,'2018-07-23 7:17:38.268','jeffb','M266');\nINSERT INTO security_logs_by_location (location_id,day,time_in,employee_id,mailstop)\n VALUES ('MPLS2',20180723,'2018-07-23 7:01:18.163','sandrak','M266');\nINSERT INTO security_logs_by_location (location_id,day,time_in,employee_id,mailstop)\n VALUES ('MPLS2',20180723,'2018-07-23 6:49:11.754','samb','M266');\nINSERT INTO security_logs_by_location (location_id,day,time_in,employee_id,mailstop)\n VALUES ('MPLS2',20180723,'2018-07-23 7:08:24.682','johno','M261');\nINSERT INTO security_logs_by_location (location_id,day,time_in,employee_id,mailstop)\n VALUES ('MPLS2',20180723,'2018-07-23 7:55:45.911','tedk','M266');\n</code></pre>\n<p>Now, I&rsquo;ll query the table for all employees entering<br />\nthe <code>MPLS2</code> building between 6 AM and 10 AM, on July 23, 2018:</p>\n<pre><code>SELECT * FROM security_logs_by_location\nWHERE location_id='MPLS2'\nAND day=20180723 AND time_in &gt; '2018-07-23 6:00'\nAND time_in &lt; '2018-07-23 10:00';\n\n location_id | day      | time_in                         | employee_id | mailstop\n-------------+----------+---------------------------------+-------------+----------\n       MPLS2 | 20180723 | 2018-07-23 11:49:11.754000+0000 |        samb | M266\n       MPLS2 | 20180723 | 2018-07-23 12:01:18.163000+0000 |     sandrak | M266\n       MPLS2 | 20180723 | 2018-07-23 12:04:22.432000+0000 |      aaronp | M266\n       MPLS2 | 20180723 | 2018-07-23 12:08:24.682000+0000 |       johno | M261\n       MPLS2 | 20180723 | 2018-07-23 12:17:38.268000+0000 |       jeffb | M266\n       MPLS2 | 20180723 | 2018-07-23 12:55:45.911000+0000 |        tedk | M266\n       MPLS2 | 20180723 | 2018-07-23 14:04:59.377000+0000 |       tejam | M266\n\n(7 rows)\n</code></pre>\n<p>Here are some things to note about the preceding result set:</p>\n<ul>\n<li>As required by the table&rsquo;s <code>PRIMARY KEY</code>, I have filtered<br />\nmy <code>WHERE</code> clause on the complete partition key<br />\n(<code>location_id</code> and <code>day</code>)</li>\n<li>I did not specify the complete PRIMARY KEY, choosing to omit<br />\n<code>employee_id</code></li>\n<li>The results are sorted by <code>time_in</code>, in ascending order; I<br />\ndid not specify <code>ORDER BY</code></li>\n<li>I specified a range on <code>time_in</code>, mentioning it twice in<br />\nthe <code>WHERE</code> clause, instructing Cassandra to return a<br />\nrange of data</li>\n<li>While Cassandra is aware of my system&rsquo;s time zone, the<br />\n<code>time_in</code> timestamp is shown in UTC time</li>\n</ul>\n<p>As per my clustering key definition, my result set was sorted by the<br />\n<code>time_in</code> column, with the oldest value at the top.  This is<br />\nbecause, while I did clearly specify my clustering keys, I did not<br />\nspecify the sort order.  Therefore, it defaulted to ascending order.</p>\n<p>Additionally, I omitted the <code>employee_id</code> key. I can do that<br />\nbecause I specified the keys that preceded it.  If I opted to skip<br />\n<code>time_in</code> and specify <code>employee_id</code>, this query<br />\nwould fail. There&rsquo;s more on that later.</p>\n<p>So why make <code>employee_id</code> part of PRIMARY KEY? It helps to<br />\nensure uniqueness. After all, if two employees came through security at<br />\nthe exact same time, their writes to the table would conflict. Although<br />\nunlikely, designating <code>employee_id</code> as the last clustering key<br />\nhelps to ensure that a last-write-wins scenario does not occur.</p>\n<p>Another good question to ask would be, if Cassandra requires specific<br />\nkeys, how can range query be made to work. Recall that Apache Cassandra<br />\nis built on a log-based storage engine (LSM tree). This means that<br />\nbuilding a table to return data in the order in which it is written<br />\nactually coincides with how Cassandra was designed to work. Cassandra<br />\nhas problems when it is made to serve random reads but sequential reads<br />\nactually work quite well.</p>\n<p>Now assume that the requirements change slightly, in that the result set<br />\nneeds to be in descending order. How can we solve for that? Well, we<br />\ncould specify an <code>ORDER BY</code> clause at query time, but flipping<br />\nthe sort direction of a large result set can be costly for performance.<br />\nWhat is the best way to solve that? By creating a table designed to<br />\nserve that query naturally, of course:</p>\n<pre><code>CREATE TABLE security_logs_by_location_desc (\n  employee_id TEXT,\n  time_in TIMESTAMP,\n  location_id TEXT,\n  day INT,\n  mailstop TEXT,\n  PRIMARY KEY ((location_id, day), time_in, employee_id))\nWITH CLUSTERING ORDER BY (time_in DESC, employee_id ASC);\n</code></pre>\n<p>If I duplicate my data into this table as well, I can run that same<br />\nquery and get my result set in descending order:</p>\n<pre><code>INSERT INTO security_logs_by_location_desc (location_id,day,time_in,employee_id,mailstop)\n VALUES ('MPLS2',20180723,'2018-07-23 9:04:59.377','tejam','M266');\nINSERT INTO security_logs_by_location_desc (location_id,day,time_in,employee_id,mailstop)\n VALUES ('MPLS2',20180723,'2018-07-23 7:17:38.268','jeffb','M266');\nINSERT INTO security_logs_by_location_desc (location_id,day,time_in,employee_id,mailstop)\n VALUES ('MPLS2',20180723,'2018-07-23 7:01:18.163','sandrak','M266');\nINSERT INTO security_logs_by_location_desc (location_id,day,time_in,employee_id,mailstop)\n VALUES ('MPLS2',20180723,'2018-07-23 6:49:11.754','samb','M266');\nINSERT INTO security_logs_by_location_desc (location_id,day,time_in,employee_id,mailstop)\n VALUES ('MPLS2',20180723,'2018-07-23 7:08:24.682','johno','M261');\nINSERT INTO security_logs_by_location_desc (location_id,day,time_in,employee_id,mailstop)\n VALUES ('MPLS2',20180723,'2018-07-23 7:55:45.911','tedk','M266');\n\nSELECT * FROM security_logs_by_location_desc\nWHERE location_id='MPLS2'\nAND day=20180723\nAND time_in &gt; '2018-07-23 6:00' AND time_in &lt; '2018-07-23 10:00';\n\n location_id | day      | time_in                         | employee_id | mailstop\n-------------+----------+---------------------------------+-------------+----------\n       MPLS2 | 20180723 | 2018-07-23 14:04:59.377000+0000 |       tejam | M266\n       MPLS2 | 20180723 | 2018-07-23 12:55:45.911000+0000 |        tedk | M266\n       MPLS2 | 20180723 | 2018-07-23 12:17:38.268000+0000 |       jeffb | M266\n       MPLS2 | 20180723 | 2018-07-23 12:08:24.682000+0000 |       johno | M261\n       MPLS2 | 20180723 | 2018-07-23 12:04:22.432000+0000 |      aaronp | M266\n       MPLS2 | 20180723 | 2018-07-23 12:01:18.163000+0000 |     sandrak | M266\n       MPLS2 | 20180723 | 2018-07-23 11:49:11.754000+0000 |        samb | M266\n\n(7 rows)\n</code></pre>\n<p>In this way, it is clear how picking the right clustering keys (and sort<br />\ndirection) also plays a part in designing tables that will perform well<br />\nat scale.</p>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1593523751259_590062590",
      "id": "paragraph_1593523751259_590062590",
      "dateCreated": "2020-06-30T13:29:11+0000",
      "dateStarted": "2020-06-30T13:29:31+0000",
      "dateFinished": "2020-06-30T13:29:32+0000",
      "status": "FINISHED",
      "$$hashKey": "object:71"
    },
    {
      "text": "CREATE TABLE security_logs_by_location (\r\n  employee_id TEXT,\r\n  time_in TIMESTAMP,\r\n  location_id TEXT,\r\n  mailstop TEXT,\r\n  PRIMARY KEY (location_id, time_in, employee_id));",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506774_773130568",
      "id": "paragraph_1591536996729_-1074423646",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:72"
    },
    {
      "user": "anonymous",
      "config": {
        "colWidth": 12,
        "fontSize": 9,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false
        },
        "editorMode": "ace/mode/text"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1593523743960_1771003490",
      "id": "paragraph_1593523743960_1771003490",
      "dateCreated": "2020-06-30T13:29:03+0000",
      "status": "READY",
      "$$hashKey": "object:73"
    },
    {
      "text": "DROP TABLE security_logs_by_location;\r\n\r\nCREATE TABLE security_logs_by_location (\r\n employee_id TEXT,\r\n time_in TIMESTAMP,\r\n location_id TEXT,\r\n day INT,\r\n mailstop TEXT,\r\n PRIMARY KEY ((location_id, day), time_in, employee_id));",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506774_1372232076",
      "id": "paragraph_1591537170886_-658534",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:74"
    },
    {
      "text": "INSERT INTO security_logs_by_location (location_id,day,time_in,employee_id,mailstop)\r\nVALUES ('MPLS2',20180723,'2018-07-23 11:04:22.432','aaronp','M266');\r\n\r\nSELECT * FROM security_logs_by_location ;",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506774_-966518944",
      "id": "paragraph_1591537189507_-331155342",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:75"
    },
    {
      "text": "CREATE TABLE security_logs_by_location_desc (\r\n  employee_id TEXT,\r\n  time_in TIMESTAMP,\r\n  location_id TEXT,\r\n  day INT,\r\n  mailstop TEXT,\r\n  PRIMARY KEY ((location_id, day), time_in, employee_id))\r\nWITH CLUSTERING ORDER BY (time_in DESC, employee_id ASC);",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506774_466735730",
      "id": "paragraph_1591971081089_-1652693213",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:76"
    },
    {
      "text": "INSERT INTO security_logs_by_location (location_id,day,time_in,employee_id,mailstop)\r\n VALUES ('MPLS2',20180723,'2018-07-23 9:04:59.377','tejam','M266');\r\nINSERT INTO security_logs_by_location (location_id,day,time_in,employee_id,mailstop)\r\n VALUES ('MPLS2',20180723,'2018-07-23 7:17:38.268','jeffb','M266');\r\nINSERT INTO security_logs_by_location (location_id,day,time_in,employee_id,mailstop)\r\n VALUES ('MPLS2',20180723,'2018-07-23 7:01:18.163','sandrak','M266');\r\nINSERT INTO security_logs_by_location (location_id,day,time_in,employee_id,mailstop)\r\n VALUES ('MPLS2',20180723,'2018-07-23 6:49:11.754','samb','M266');\r\nINSERT INTO security_logs_by_location (location_id,day,time_in,employee_id,mailstop)\r\n VALUES ('MPLS2',20180723,'2018-07-23 7:08:24.682','johno','M261');\r\nINSERT INTO security_logs_by_location (location_id,day,time_in,employee_id,mailstop)\r\n VALUES ('MPLS2',20180723,'2018-07-23 7:55:45.911','tedk','M266');",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506775_-1943129582",
      "id": "paragraph_1591537189392_-1997956480",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:77"
    },
    {
      "text": "SELECT * FROM security_logs_by_location\r\nWHERE location_id='MPLS2'\r\nAND day=20180723 AND time_in > '2018-07-23 6:00'\r\nAND time_in < '2018-07-23 10:00';",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506775_259900060",
      "id": "paragraph_1591537189386_679342958",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:78"
    },
    {
      "text": "INSERT INTO security_logs_by_location_desc (location_id,day,time_in,employee_id,mailstop)\r\n VALUES ('MPLS2',20180723,'2018-07-23 9:04:59.377','tejam','M266');\r\nINSERT INTO security_logs_by_location_desc (location_id,day,time_in,employee_id,mailstop)\r\n VALUES ('MPLS2',20180723,'2018-07-23 7:17:38.268','jeffb','M266');\r\nINSERT INTO security_logs_by_location_desc (location_id,day,time_in,employee_id,mailstop)\r\n VALUES ('MPLS2',20180723,'2018-07-23 7:01:18.163','sandrak','M266');\r\nINSERT INTO security_logs_by_location_desc (location_id,day,time_in,employee_id,mailstop)\r\n VALUES ('MPLS2',20180723,'2018-07-23 6:49:11.754','samb','M266');\r\nINSERT INTO security_logs_by_location_desc (location_id,day,time_in,employee_id,mailstop)\r\n VALUES ('MPLS2',20180723,'2018-07-23 7:08:24.682','johno','M261');\r\nINSERT INTO security_logs_by_location_desc (location_id,day,time_in,employee_id,mailstop)\r\n VALUES ('MPLS2',20180723,'2018-07-23 7:55:45.911','tedk','M266');\r\n\r\nSELECT * FROM security_logs_by_location_desc\r\nWHERE location_id='MPLS2'\r\nAND day=20180723\r\nAND time_in > '2018-07-23 6:00' AND time_in < '2018-07-23 10:00';",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506775_-365267935",
      "id": "paragraph_1591537189227_-1921055988",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:79"
    },
    {
      "text": "%md\n\n\n### Querying data\n\nWhile Apache Cassandra is known for its restrictive query model (design\nyour tables to suit your queries), the previous content has shown that\nCQL can still be quite powerful. Consider the following table:\n\n```\nCREATE TABLE query_test (\n pk1 TEXT,\n pk2 TEXT,\n ck3 TEXT,\n ck4 TEXT,\n c5 TEXT,\n PRIMARY KEY ((pk1,pk2), ck3, ck4))\nWITH CLUSTERING ORDER BY (ck3 DESC, ck4 ASC);\n\nINSERT INTO query_test (pk1,pk2,ck3,ck4,c5) VALUES ('a','b','c1','d1','e1');\nINSERT INTO query_test (pk1,pk2,ck3,ck4,c5) VALUES ('a','b','c2','d2','e2');\nINSERT INTO query_test (pk1,pk2,ck3,ck4,c5) VALUES ('a','b','c2','d3','e3');\nINSERT INTO query_test (pk1,pk2,ck3,ck4,c5) VALUES ('a','b','c2','d4','e4');\nINSERT INTO query_test (pk1,pk2,ck3,ck4,c5) VALUES ('a','b','c3','d5','e5');\nINSERT INTO query_test (pk1,pk2,ck3,ck4,c5) VALUES ('f','b','c3','d5','e5');\n```\n\nLet's start by querying everything for `pk1`:\n\n```\nSELECT * FROM query_test WHERE pk1='a';\n\nInvalidRequest: Error from server: code=2200 [Invalid query] message=\"Cannot execute this query as it might involve data filtering and thus may have unpredictable performance. If you want to execute this query despite the performance unpredictability, use ALLOW FILTERING\"\n```\n\n \n\nSo what happened here? Cassandra is essentially informing us that it\ncannot ensure that this query will be served by a single node. This is\nbecause we have defined `pk1` and `pk2` as a\ncomposite partition key. Without both `pk1` and\n`pk2` specified, a single node containing the requested data\ncannot be ascertained. However, it does say the following:\n\n```\nIf you want to execute this query despite the performance unpredictability, use ALLOW FILTERING\n```\n\nSo let's give that a try:\n\n```\nSELECT * FROM query_test\nWHERE pk1='a' ALLOW FILTERING;\n\n pk1 | pk2 | ck3 | ck4 | c5\n-----+-----+-----+-----+----\n   a |   b |  c3 |  d5 | e5\n   a |   b |  c2 |  d2 | e2\n   a |   b |  c2 |  d3 | e3\n   a |   b |  c2 |  d4 | e4\n   a |   b |  c1 |  d1 | e1\n\n(5 rows)\n```\n\nThat worked. But the bigger question is why? The\n`ALLOW FILTERING` directive tells Cassandra that it should\nperform an exhaustive seek of all partitions, looking for data that\nmight match. With a total of six rows in the table, served by a single\nnode cluster, that will still run fast. But in a multi-node cluster,\nwith millions of other rows, that query will likely time out.\n\nSo, let's try that query again, and this time we'll specify the complete\npartition key, as well as the first clustering key:\n\n```\nSELECT * FROM query_test\nWHERE pk1='a' AND pk2='b' AND ck3='c2';\n\n pk1 | pk2 | ck3 | ck4 | c5\n-----+-----+-----+-----+----\n   a |   b |  c2 |  d2 | e2\n   a |   b |  c2 |  d3 | e3\n   a |   b |  c2 |  d4 | e4\n\n(3 rows)\n```\n\n \n\nThat works. So what if we just want to query for a specific\n`ck4`, but we don't know which `ck3` it's under?\nLet's try skipping `ck3`:\n\n```\nSELECT * FROM query_test\nWHERE pk1='a' AND pk2='b' AND ck4='d2';\n\nInvalidRequest: Error from server: code=2200 [Invalid query] message=\"PRIMARY KEY column \"ck4\" cannot be restricted as preceding column \"ck3\" is not restricted\"\n```\n\nRemember, components of the `PRIMARY KEY` definition can be\nomitted, as long as (some of) the preceding keys are specified. But they\ncan only be omitted in order. You can't pick and choose which ones to\nleave out.\n\nSo how do we solve this issue? Let's use `ALLOW FILTERING`:\n\n```\nSELECT * FROM query_test\nWHERE pk1='a' AND pk2='b' AND ck4='d2' ALLOW FILTERING;\n\n pk1 | pk2 | ck3 | ck4 | c5\n-----+-----+-----+-----+----\n   a |   b |  c2 |  d2 | e2\n\n(1 rows)\n```\n\nThat works. But given what we know about the `ALLOW FILTERING`\ndirective, is this OK to do? The answer to this question lies in the\nfact that we have indeed specified the complete partition key. By doing\nthat, Cassandra knows which node can serve the query. While this may not\nfollow the advice of *build your tables to support your queries*, it may\nactually perform well (depending on the size of the result set).\n\n### Note\n\nAvoid using `ALLOW FILTERING`. It might make certain ad-hoc\nqueries work, but improper use of it may cause your nodes to work too\nhard, and whichever is chosen as the coordinator may crash. Definitely\ndo not deploy any production code that regularly uses CQL queries\ncontaining the `ALLOW FILTERING` directive.\n\nFor a quick detour, what if I wanted to know what time it was on my\nApache Cassandra cluster? I could query my table using the\n`now()` function:\n\n```\nSELECT now() FROM query_test;\n\n system.now()\n--------------------------------------\nf83015b0-8fba-11e8-91d4-a7c67cc60e89\nf83015b1-8fba-11e8-91d4-a7c67cc60e89\nf83015b2-8fba-11e8-91d4-a7c67cc60e89\nf83015b3-8fba-11e8-91d4-a7c67cc60e89\nf83015b4-8fba-11e8-91d4-a7c67cc60e89\nf83015b5-8fba-11e8-91d4-a7c67cc60e89\n\n(6 rows)\n```\n\nWhat happened here? The `now()` function was invoked for each\nrow in the table. First of all, this is an unbound query and will hit\nmultiple nodes for data that it's not even using. Secondly, we just need\none result. And third, returning the current time\nas `TIMEUUID` isn't very easy to read.\n\nLet's solve problems one and two by changing the table we're querying.\nLet's try that on the `system.local` table:\n\n```\nSELECT now() FROM system.local ;\n\n system.now()\n--------------------------------------\n 94a88ad0-8fbb-11e8-91d4-a7c67cc60e89\n\n(1 rows)\n```\n\nThe `system.local` table is unique to each node in a Cassandra\ncluster. Also, it only ever has one row in it. So, this query will be\nserved by one node, and there will only be one row returned. But how can\nwe make that more easier to read? We can use the `dateof()`\nfunction for this:\n\n```\nSELECT dateof(now()) FROM system.local;\n\n system.dateof(system.now())\n---------------------------------\n 2018-07-25 03:37:08.045000+0000\n\n(1 rows)\n```\n\n \n\nCassandra has other built-in functions that can help to solve other\nproblems. We will cover those later.\n\n### Note\n\nYou can execute\n`SELECT CAST(now() as TIMESTAMP) FROM system.local;` to\nachieve the same result.\n\n#### The IN operator\n\nSo we've seen that CQL has an `AND` keyword for specifying\nmultiple filters in the `WHERE` clause. Does it also have an\n`OR` keyword, like SQL?\n\nNo, it does not. This is because Apache Cassandra is designed to serve\nsequential reads, not random reads. It works best when its queries give\nit a clear, precise path to the requested data. Allowing filters in the\n`WHERE` clause to be specified on an `OR` basis\nwould force Cassandra to perform random reads, which really works\nagainst how it was built.\n\nHowever, queries can be made to perform similarly to `OR`, via\nthe `IN` operator:\n\n```\nSELECT * FROM query_test WHERE pk1='a' AND pk2 IN ('b','c');\n```\n\nWhile this query technically will work, its use is considered to be an\nanti-pattern in Cassandra. This is because it is a multi-key query,\nmeaning the primary key filters are filtering on more than one key\nvalue. In this case, Cassandra cannot figure out which node the\nrequested data is on. We are only giving it one part of the partition\nkey. This means that it will have to designate one node as a coordinator\nnode, and then scan each node to build the result set:\n\n```\nSELECT * FROM query_test WHERE pk1='a' AND  pk2='b' AND ck3 IN ('c1','c3');\n```\n\nThis query is also a multi-key query. But, this query will perform\nbetter, because we are at least specifying a complete partition key.\nThis way, a token-aware application will not require a coordinator node,\nand will be able to go directly to the one node that can serve this\nrequest.\n\nDo note that, if you use `IN`, the same restrictions apply as\nfor other operators. You cannot skip primary keys, and if you use\n`IN` on a key, you must do the following:\n\n-   Specify all of the keys prior to it\n-   Use `IN` only on the last key specified in the query\n\n \n\n### Note\n\nLike its `ALLOW FILTERING` counterpart, `IN` queries\ncan still be served by one node if the complete partition key is\nspecified. However, it’s a good idea to limit the number of values\nspecified with the `IN` operator to less than 10.\n\n### Writing data\n\nGiven the ways in which Apache Cassandra has been shown to handle things\nsuch as `INSERT`, `UPDATE`, and `DELETE`,\nit is important to discuss what they have in common. They all result in\nwrites to the database. Let's take a look at how each one behaves in\ncertain scenarios. Assume that we need to keep track of statuses for\norders from an e-commerce website. Consider the following table:\n\n```\nCREATE TABLE order_status (\n status TEXT,\n order_id UUID,\n shipping_weight_kg DECIMAL,\n total DECIMAL,\n PRIMARY KEY (status,order_id))\nWITH CLUSTERING ORDER BY (order_id DESC);\n```\n\n### Note\n\nThe `order_status` table is for example purposes only, and is\nintended to be used to show how writes work in Apache Cassandra. I do\nnot recommend building an order-status-tracking system this way.\n\n#### Inserting data\n\nLet's write some data to that table.  To do this, we'll use the\n`INSERT` statement.  With an `INSERT` statement, all\n`PRIMARY KEY` components must be specified; we will\nspecify`status` and `order_id`.  Additionally, every\ncolumn that you wish to provide a value for must be specified in a\nparenthesis list, followed by the`VALUES`in their own\nparenthesis list:\n\n```\nINSERT INTO order_status (status,order_id,total) VALUES ('PENDING',UUID(),114.22);\nINSERT INTO order_status (status,order_id,total) VALUES ('PENDING',UUID(),33.12);\nINSERT INTO order_status (status,order_id,total) VALUES ('PENDING',UUID(),86.63);\nINSERT INTO order_status (status,order_id,total,shipping_weight_kg)\n  VALUES ('PICKED',UUID(),303.11,2);\nINSERT INTO order_status (status,order_id,total,shipping_weight_kg)\n  VALUES ('SHIPPED',UUID(),218.99,1.05);\nINSERT INTO order_status (status,order_id,total,shipping_weight_kg)\n  VALUES ('SHIPPED',UUID(),177.08,1.2);\n```\n\n### Note\n\nIf you're going to need a unique identifier for things such as IDs,\nthe `UUID()` and `TIMEUUID()` functions can be\ninvoked in-line as a part of `INSERT`.\n\nAs you can see, not all columns need to be specified. In our business\ncase, assume that we do not know the shipping weight until the order has\nbeen `PICKED`. If I query for all orders currently in a\n`PENDING` status, it shows `shipping_weight_kg` as\n`null`:\n\n```\nSELECT * FROM order_status WHERE status='PENDING';\n\n status  | order_id                             | shipping_weight_kg | total\n---------+--------------------------------------+--------------------+--------\n PENDING | fcb15fc2-feaa-4ba9-a3c6-899d1107cce9 |               null | 114.22\n PENDING | ede8af04-cc66-4b3a-a672-ab1abed64c21 |               null | 86.63\n PENDING | 1da6aef1-bd1e-4222-af01-19d2ab0d8151 |               null | 33.12\n\n(3 rows)\n```\n\nRemember, Apache Cassandra does not use `null` in the same way\nthat other databases may. In the case of Cassandra,\n`null` simply means that the currently-requested column does\nnot contain a value.\n\n### Note\n\nDo not literally `INSERT` a null value into a table. Cassandra\ntreats this as a `DELETE`, and writes a tombstone. It's also\nimportant to make sure that your application code is also not writing\nnulls for column values that are not set.\n\n \n\n \n\n#### Updating data\n\nSo now let's update one of our `PENDING` orders to a status of\n`PICKED`, and give it a value for shipping weight. We can\nstart by updating our `shipping_weight_kg` for order\n`fcb15fc2-feaa-4ba9-a3c6-899d1107cce9`, and we'll assume that\nit is `1.4` kilograms. This can be done in two different\nways. Updates and inserts are treated the same in Cassandra, so we could\nactually update our row with the `INSERT` statement:\n\n```\nINSERT INTO order_status (status,order_id,shipping_weight_kg)\n  VALUES ('PENDING',fcb15fc2-feaa-4ba9-a3c6-899d1107cce9,1.4);\n```\n\nOr, we can also use the `UPDATE` statement that we know from\nSQL:\n\n```\nUPDATE order_status SET shipping_weight_kg=1.4\nWHERE status='PENDING'\nAND order_id=fcb15fc2-feaa-4ba9-a3c6-899d1107cce9;\n```\n\nEither way, we can then query our row and see this result:\n\n```\nSELECT * FROM order_status\nWHERE status='PENDING'\nAND order_id=fcb15fc2-feaa-4ba9-a3c6-899d1107cce9;\n\n status  | order_id                             | shipping_weight_kg | total\n---------+--------------------------------------+--------------------+--------\n PENDING | fcb15fc2-feaa-4ba9-a3c6-899d1107cce9 |                1.4 | 114.22\n\n(1 rows)\n```\n\nOk, so now how do we set the `PENDING` status to\n`PICKED`? Let's start by trying to `UPDATE` it, as\nwe would in SQL:\n\n```\nUPDATE order_status SET status='PICKED'\nWHERE order_id='fcb15fc2-feaa-4ba9-a3c6-899d1107cce9';\n\nInvalidRequest: Error from server: code=2200 [Invalid query] message=\"PRIMARY KEY part status found in SET part\"\n```\n\n \n\nWith the `UPDATE` statement in CQL, all\nthe `PRIMARY KEY` components are required to be specified in\nthe `WHERE` clause. So how about we try specifying both\n`PRIMARY KEY` components in `WHERE`, and both\ncolumns with values in `SET`:\n\n```\nUPDATE order_status SET shipping_weight_kg=1.4,total=114.22\nWHERE status='PICKED'\nAND order_id=fcb15fc2-feaa-4ba9-a3c6-899d1107cce9;\n```\n\nSo that doesn't error out, but did it work? To figure that out, let's\nrun a (bad) query using `ALLOW FILTERING`:\n\n```\nSELECT * FROM order_status WHERE order_id=fcb15fc2-feaa-4ba9-a3c6-899d1107cce9 ALLOW FILTERING;\n\n status  | order_id                             | shipping_weight_kg | total\n---------+--------------------------------------+--------------------+--------\n PENDING | fcb15fc2-feaa-4ba9-a3c6-899d1107cce9 |                1.4 | 114.22\n  PICKED | fcb15fc2-feaa-4ba9-a3c6-899d1107cce9 |                1.4 | 114.22\n\n(2 rows)\n```\n\nSo for this order ID, there are now two rows present in our table; not\nat all what we really wanted to do. Sure, we now have our order in a\n`PICKED` state, but our `PENDING` row is still out\nthere. Why did this happen?\n\nFirst of all, with both `INSERT` and `UPDATE` you\nmust specify all of the `PRIMARY KEY` components or the\noperation will fail. Secondly, primary keys are unique in Cassandra.\nWhen used together, they essentially point to the column values we want.\nBut that also means they cannot be updated. The only way to update a\n`PRIMARY KEY` component is to delete and then rewrite it.\n\n### Note\n\nTo Cassandra, `INSERT` and `UPDATE` are synonymous.\nThey behave the same, and can mostly be used interchangeably. They both\nwrite column values to a specific set of unique keys in the table. You\ncan insert new rows with `UPDATE` and you can update existing\nrows with `INSERT`.\n",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<h3>Querying data</h3>\n<p>While Apache Cassandra is known for its restrictive query model (design<br />\nyour tables to suit your queries), the previous content has shown that<br />\nCQL can still be quite powerful. Consider the following table:</p>\n<pre><code>CREATE TABLE query_test (\n pk1 TEXT,\n pk2 TEXT,\n ck3 TEXT,\n ck4 TEXT,\n c5 TEXT,\n PRIMARY KEY ((pk1,pk2), ck3, ck4))\nWITH CLUSTERING ORDER BY (ck3 DESC, ck4 ASC);\n\nINSERT INTO query_test (pk1,pk2,ck3,ck4,c5) VALUES ('a','b','c1','d1','e1');\nINSERT INTO query_test (pk1,pk2,ck3,ck4,c5) VALUES ('a','b','c2','d2','e2');\nINSERT INTO query_test (pk1,pk2,ck3,ck4,c5) VALUES ('a','b','c2','d3','e3');\nINSERT INTO query_test (pk1,pk2,ck3,ck4,c5) VALUES ('a','b','c2','d4','e4');\nINSERT INTO query_test (pk1,pk2,ck3,ck4,c5) VALUES ('a','b','c3','d5','e5');\nINSERT INTO query_test (pk1,pk2,ck3,ck4,c5) VALUES ('f','b','c3','d5','e5');\n</code></pre>\n<p>Let&rsquo;s start by querying everything for <code>pk1</code>:</p>\n<pre><code>SELECT * FROM query_test WHERE pk1='a';\n\nInvalidRequest: Error from server: code=2200 [Invalid query] message=&quot;Cannot execute this query as it might involve data filtering and thus may have unpredictable performance. If you want to execute this query despite the performance unpredictability, use ALLOW FILTERING&quot;\n</code></pre>\n<p>So what happened here? Cassandra is essentially informing us that it<br />\ncannot ensure that this query will be served by a single node. This is<br />\nbecause we have defined <code>pk1</code> and <code>pk2</code> as a<br />\ncomposite partition key. Without both <code>pk1</code> and<br />\n<code>pk2</code> specified, a single node containing the requested data<br />\ncannot be ascertained. However, it does say the following:</p>\n<pre><code>If you want to execute this query despite the performance unpredictability, use ALLOW FILTERING\n</code></pre>\n<p>So let&rsquo;s give that a try:</p>\n<pre><code>SELECT * FROM query_test\nWHERE pk1='a' ALLOW FILTERING;\n\n pk1 | pk2 | ck3 | ck4 | c5\n-----+-----+-----+-----+----\n   a |   b |  c3 |  d5 | e5\n   a |   b |  c2 |  d2 | e2\n   a |   b |  c2 |  d3 | e3\n   a |   b |  c2 |  d4 | e4\n   a |   b |  c1 |  d1 | e1\n\n(5 rows)\n</code></pre>\n<p>That worked. But the bigger question is why? The<br />\n<code>ALLOW FILTERING</code> directive tells Cassandra that it should<br />\nperform an exhaustive seek of all partitions, looking for data that<br />\nmight match. With a total of six rows in the table, served by a single<br />\nnode cluster, that will still run fast. But in a multi-node cluster,<br />\nwith millions of other rows, that query will likely time out.</p>\n<p>So, let&rsquo;s try that query again, and this time we&rsquo;ll specify the complete<br />\npartition key, as well as the first clustering key:</p>\n<pre><code>SELECT * FROM query_test\nWHERE pk1='a' AND pk2='b' AND ck3='c2';\n\n pk1 | pk2 | ck3 | ck4 | c5\n-----+-----+-----+-----+----\n   a |   b |  c2 |  d2 | e2\n   a |   b |  c2 |  d3 | e3\n   a |   b |  c2 |  d4 | e4\n\n(3 rows)\n</code></pre>\n<p>That works. So what if we just want to query for a specific<br />\n<code>ck4</code>, but we don&rsquo;t know which <code>ck3</code> it&rsquo;s under?<br />\nLet&rsquo;s try skipping <code>ck3</code>:</p>\n<pre><code>SELECT * FROM query_test\nWHERE pk1='a' AND pk2='b' AND ck4='d2';\n\nInvalidRequest: Error from server: code=2200 [Invalid query] message=&quot;PRIMARY KEY column &quot;ck4&quot; cannot be restricted as preceding column &quot;ck3&quot; is not restricted&quot;\n</code></pre>\n<p>Remember, components of the <code>PRIMARY KEY</code> definition can be<br />\nomitted, as long as (some of) the preceding keys are specified. But they<br />\ncan only be omitted in order. You can&rsquo;t pick and choose which ones to<br />\nleave out.</p>\n<p>So how do we solve this issue? Let&rsquo;s use <code>ALLOW FILTERING</code>:</p>\n<pre><code>SELECT * FROM query_test\nWHERE pk1='a' AND pk2='b' AND ck4='d2' ALLOW FILTERING;\n\n pk1 | pk2 | ck3 | ck4 | c5\n-----+-----+-----+-----+----\n   a |   b |  c2 |  d2 | e2\n\n(1 rows)\n</code></pre>\n<p>That works. But given what we know about the <code>ALLOW FILTERING</code><br />\ndirective, is this OK to do? The answer to this question lies in the<br />\nfact that we have indeed specified the complete partition key. By doing<br />\nthat, Cassandra knows which node can serve the query. While this may not<br />\nfollow the advice of <em>build your tables to support your queries</em>, it may<br />\nactually perform well (depending on the size of the result set).</p>\n<h3>Note</h3>\n<p>Avoid using <code>ALLOW FILTERING</code>. It might make certain ad-hoc<br />\nqueries work, but improper use of it may cause your nodes to work too<br />\nhard, and whichever is chosen as the coordinator may crash. Definitely<br />\ndo not deploy any production code that regularly uses CQL queries<br />\ncontaining the <code>ALLOW FILTERING</code> directive.</p>\n<p>For a quick detour, what if I wanted to know what time it was on my<br />\nApache Cassandra cluster? I could query my table using the<br />\n<code>now()</code> function:</p>\n<pre><code>SELECT now() FROM query_test;\n\n system.now()\n--------------------------------------\nf83015b0-8fba-11e8-91d4-a7c67cc60e89\nf83015b1-8fba-11e8-91d4-a7c67cc60e89\nf83015b2-8fba-11e8-91d4-a7c67cc60e89\nf83015b3-8fba-11e8-91d4-a7c67cc60e89\nf83015b4-8fba-11e8-91d4-a7c67cc60e89\nf83015b5-8fba-11e8-91d4-a7c67cc60e89\n\n(6 rows)\n</code></pre>\n<p>What happened here? The <code>now()</code> function was invoked for each<br />\nrow in the table. First of all, this is an unbound query and will hit<br />\nmultiple nodes for data that it&rsquo;s not even using. Secondly, we just need<br />\none result. And third, returning the current time<br />\nas <code>TIMEUUID</code> isn&rsquo;t very easy to read.</p>\n<p>Let&rsquo;s solve problems one and two by changing the table we&rsquo;re querying.<br />\nLet&rsquo;s try that on the <code>system.local</code> table:</p>\n<pre><code>SELECT now() FROM system.local ;\n\n system.now()\n--------------------------------------\n 94a88ad0-8fbb-11e8-91d4-a7c67cc60e89\n\n(1 rows)\n</code></pre>\n<p>The <code>system.local</code> table is unique to each node in a Cassandra<br />\ncluster. Also, it only ever has one row in it. So, this query will be<br />\nserved by one node, and there will only be one row returned. But how can<br />\nwe make that more easier to read? We can use the <code>dateof()</code><br />\nfunction for this:</p>\n<pre><code>SELECT dateof(now()) FROM system.local;\n\n system.dateof(system.now())\n---------------------------------\n 2018-07-25 03:37:08.045000+0000\n\n(1 rows)\n</code></pre>\n<p>Cassandra has other built-in functions that can help to solve other<br />\nproblems. We will cover those later.</p>\n<h3>Note</h3>\n<p>You can execute<br />\n<code>SELECT CAST(now() as TIMESTAMP) FROM system.local;</code> to<br />\nachieve the same result.</p>\n<h4>The IN operator</h4>\n<p>So we&rsquo;ve seen that CQL has an <code>AND</code> keyword for specifying<br />\nmultiple filters in the <code>WHERE</code> clause. Does it also have an<br />\n<code>OR</code> keyword, like SQL?</p>\n<p>No, it does not. This is because Apache Cassandra is designed to serve<br />\nsequential reads, not random reads. It works best when its queries give<br />\nit a clear, precise path to the requested data. Allowing filters in the<br />\n<code>WHERE</code> clause to be specified on an <code>OR</code> basis<br />\nwould force Cassandra to perform random reads, which really works<br />\nagainst how it was built.</p>\n<p>However, queries can be made to perform similarly to <code>OR</code>, via<br />\nthe <code>IN</code> operator:</p>\n<pre><code>SELECT * FROM query_test WHERE pk1='a' AND pk2 IN ('b','c');\n</code></pre>\n<p>While this query technically will work, its use is considered to be an<br />\nanti-pattern in Cassandra. This is because it is a multi-key query,<br />\nmeaning the primary key filters are filtering on more than one key<br />\nvalue. In this case, Cassandra cannot figure out which node the<br />\nrequested data is on. We are only giving it one part of the partition<br />\nkey. This means that it will have to designate one node as a coordinator<br />\nnode, and then scan each node to build the result set:</p>\n<pre><code>SELECT * FROM query_test WHERE pk1='a' AND  pk2='b' AND ck3 IN ('c1','c3');\n</code></pre>\n<p>This query is also a multi-key query. But, this query will perform<br />\nbetter, because we are at least specifying a complete partition key.<br />\nThis way, a token-aware application will not require a coordinator node,<br />\nand will be able to go directly to the one node that can serve this<br />\nrequest.</p>\n<p>Do note that, if you use <code>IN</code>, the same restrictions apply as<br />\nfor other operators. You cannot skip primary keys, and if you use<br />\n<code>IN</code> on a key, you must do the following:</p>\n<ul>\n<li>Specify all of the keys prior to it</li>\n<li>Use <code>IN</code> only on the last key specified in the query</li>\n</ul>\n<h3>Note</h3>\n<p>Like its <code>ALLOW FILTERING</code> counterpart, <code>IN</code> queries<br />\ncan still be served by one node if the complete partition key is<br />\nspecified. However, it’s a good idea to limit the number of values<br />\nspecified with the <code>IN</code> operator to less than 10.</p>\n<h3>Writing data</h3>\n<p>Given the ways in which Apache Cassandra has been shown to handle things<br />\nsuch as <code>INSERT</code>, <code>UPDATE</code>, and <code>DELETE</code>,<br />\nit is important to discuss what they have in common. They all result in<br />\nwrites to the database. Let&rsquo;s take a look at how each one behaves in<br />\ncertain scenarios. Assume that we need to keep track of statuses for<br />\norders from an e-commerce website. Consider the following table:</p>\n<pre><code>CREATE TABLE order_status (\n status TEXT,\n order_id UUID,\n shipping_weight_kg DECIMAL,\n total DECIMAL,\n PRIMARY KEY (status,order_id))\nWITH CLUSTERING ORDER BY (order_id DESC);\n</code></pre>\n<h3>Note</h3>\n<p>The <code>order_status</code> table is for example purposes only, and is<br />\nintended to be used to show how writes work in Apache Cassandra. I do<br />\nnot recommend building an order-status-tracking system this way.</p>\n<h4>Inserting data</h4>\n<p>Let&rsquo;s write some data to that table.  To do this, we&rsquo;ll use the<br />\n<code>INSERT</code> statement.  With an <code>INSERT</code> statement, all<br />\n<code>PRIMARY KEY</code> components must be specified; we will<br />\nspecify<code>status</code> and <code>order_id</code>.  Additionally, every<br />\ncolumn that you wish to provide a value for must be specified in a<br />\nparenthesis list, followed by the<code>VALUES</code>in their own<br />\nparenthesis list:</p>\n<pre><code>INSERT INTO order_status (status,order_id,total) VALUES ('PENDING',UUID(),114.22);\nINSERT INTO order_status (status,order_id,total) VALUES ('PENDING',UUID(),33.12);\nINSERT INTO order_status (status,order_id,total) VALUES ('PENDING',UUID(),86.63);\nINSERT INTO order_status (status,order_id,total,shipping_weight_kg)\n  VALUES ('PICKED',UUID(),303.11,2);\nINSERT INTO order_status (status,order_id,total,shipping_weight_kg)\n  VALUES ('SHIPPED',UUID(),218.99,1.05);\nINSERT INTO order_status (status,order_id,total,shipping_weight_kg)\n  VALUES ('SHIPPED',UUID(),177.08,1.2);\n</code></pre>\n<h3>Note</h3>\n<p>If you&rsquo;re going to need a unique identifier for things such as IDs,<br />\nthe <code>UUID()</code> and <code>TIMEUUID()</code> functions can be<br />\ninvoked in-line as a part of <code>INSERT</code>.</p>\n<p>As you can see, not all columns need to be specified. In our business<br />\ncase, assume that we do not know the shipping weight until the order has<br />\nbeen <code>PICKED</code>. If I query for all orders currently in a<br />\n<code>PENDING</code> status, it shows <code>shipping_weight_kg</code> as<br />\n<code>null</code>:</p>\n<pre><code>SELECT * FROM order_status WHERE status='PENDING';\n\n status  | order_id                             | shipping_weight_kg | total\n---------+--------------------------------------+--------------------+--------\n PENDING | fcb15fc2-feaa-4ba9-a3c6-899d1107cce9 |               null | 114.22\n PENDING | ede8af04-cc66-4b3a-a672-ab1abed64c21 |               null | 86.63\n PENDING | 1da6aef1-bd1e-4222-af01-19d2ab0d8151 |               null | 33.12\n\n(3 rows)\n</code></pre>\n<p>Remember, Apache Cassandra does not use <code>null</code> in the same way<br />\nthat other databases may. In the case of Cassandra,<br />\n<code>null</code> simply means that the currently-requested column does<br />\nnot contain a value.</p>\n<h3>Note</h3>\n<p>Do not literally <code>INSERT</code> a null value into a table. Cassandra<br />\ntreats this as a <code>DELETE</code>, and writes a tombstone. It&rsquo;s also<br />\nimportant to make sure that your application code is also not writing<br />\nnulls for column values that are not set.</p>\n<h4>Updating data</h4>\n<p>So now let&rsquo;s update one of our <code>PENDING</code> orders to a status of<br />\n<code>PICKED</code>, and give it a value for shipping weight. We can<br />\nstart by updating our <code>shipping_weight_kg</code> for order<br />\n<code>fcb15fc2-feaa-4ba9-a3c6-899d1107cce9</code>, and we&rsquo;ll assume that<br />\nit is <code>1.4</code> kilograms. This can be done in two different<br />\nways. Updates and inserts are treated the same in Cassandra, so we could<br />\nactually update our row with the <code>INSERT</code> statement:</p>\n<pre><code>INSERT INTO order_status (status,order_id,shipping_weight_kg)\n  VALUES ('PENDING',fcb15fc2-feaa-4ba9-a3c6-899d1107cce9,1.4);\n</code></pre>\n<p>Or, we can also use the <code>UPDATE</code> statement that we know from<br />\nSQL:</p>\n<pre><code>UPDATE order_status SET shipping_weight_kg=1.4\nWHERE status='PENDING'\nAND order_id=fcb15fc2-feaa-4ba9-a3c6-899d1107cce9;\n</code></pre>\n<p>Either way, we can then query our row and see this result:</p>\n<pre><code>SELECT * FROM order_status\nWHERE status='PENDING'\nAND order_id=fcb15fc2-feaa-4ba9-a3c6-899d1107cce9;\n\n status  | order_id                             | shipping_weight_kg | total\n---------+--------------------------------------+--------------------+--------\n PENDING | fcb15fc2-feaa-4ba9-a3c6-899d1107cce9 |                1.4 | 114.22\n\n(1 rows)\n</code></pre>\n<p>Ok, so now how do we set the <code>PENDING</code> status to<br />\n<code>PICKED</code>? Let&rsquo;s start by trying to <code>UPDATE</code> it, as<br />\nwe would in SQL:</p>\n<pre><code>UPDATE order_status SET status='PICKED'\nWHERE order_id='fcb15fc2-feaa-4ba9-a3c6-899d1107cce9';\n\nInvalidRequest: Error from server: code=2200 [Invalid query] message=&quot;PRIMARY KEY part status found in SET part&quot;\n</code></pre>\n<p>With the <code>UPDATE</code> statement in CQL, all<br />\nthe <code>PRIMARY KEY</code> components are required to be specified in<br />\nthe <code>WHERE</code> clause. So how about we try specifying both<br />\n<code>PRIMARY KEY</code> components in <code>WHERE</code>, and both<br />\ncolumns with values in <code>SET</code>:</p>\n<pre><code>UPDATE order_status SET shipping_weight_kg=1.4,total=114.22\nWHERE status='PICKED'\nAND order_id=fcb15fc2-feaa-4ba9-a3c6-899d1107cce9;\n</code></pre>\n<p>So that doesn&rsquo;t error out, but did it work? To figure that out, let&rsquo;s<br />\nrun a (bad) query using <code>ALLOW FILTERING</code>:</p>\n<pre><code>SELECT * FROM order_status WHERE order_id=fcb15fc2-feaa-4ba9-a3c6-899d1107cce9 ALLOW FILTERING;\n\n status  | order_id                             | shipping_weight_kg | total\n---------+--------------------------------------+--------------------+--------\n PENDING | fcb15fc2-feaa-4ba9-a3c6-899d1107cce9 |                1.4 | 114.22\n  PICKED | fcb15fc2-feaa-4ba9-a3c6-899d1107cce9 |                1.4 | 114.22\n\n(2 rows)\n</code></pre>\n<p>So for this order ID, there are now two rows present in our table; not<br />\nat all what we really wanted to do. Sure, we now have our order in a<br />\n<code>PICKED</code> state, but our <code>PENDING</code> row is still out<br />\nthere. Why did this happen?</p>\n<p>First of all, with both <code>INSERT</code> and <code>UPDATE</code> you<br />\nmust specify all of the <code>PRIMARY KEY</code> components or the<br />\noperation will fail. Secondly, primary keys are unique in Cassandra.<br />\nWhen used together, they essentially point to the column values we want.<br />\nBut that also means they cannot be updated. The only way to update a<br />\n<code>PRIMARY KEY</code> component is to delete and then rewrite it.</p>\n<h3>Note</h3>\n<p>To Cassandra, <code>INSERT</code> and <code>UPDATE</code> are synonymous.<br />\nThey behave the same, and can mostly be used interchangeably. They both<br />\nwrite column values to a specific set of unique keys in the table. You<br />\ncan insert new rows with <code>UPDATE</code> and you can update existing<br />\nrows with <code>INSERT</code>.</p>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506775_1990906816",
      "id": "paragraph_1591541634554_-811611830",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:80"
    },
    {
      "text": "CREATE TABLE query_test (\r\n pk1 TEXT,\r\n pk2 TEXT,\r\n ck3 TEXT,\r\n ck4 TEXT,\r\n c5 TEXT,\r\n PRIMARY KEY ((pk1,pk2), ck3, ck4))\r\nWITH CLUSTERING ORDER BY (ck3 DESC, ck4 ASC);\r\n\r\nINSERT INTO query_test (pk1,pk2,ck3,ck4,c5) VALUES ('a','b','c1','d1','e1');\r\nINSERT INTO query_test (pk1,pk2,ck3,ck4,c5) VALUES ('a','b','c2','d2','e2');\r\nINSERT INTO query_test (pk1,pk2,ck3,ck4,c5) VALUES ('a','b','c2','d3','e3');\r\nINSERT INTO query_test (pk1,pk2,ck3,ck4,c5) VALUES ('a','b','c2','d4','e4');\r\nINSERT INTO query_test (pk1,pk2,ck3,ck4,c5) VALUES ('a','b','c3','d5','e5');\r\nINSERT INTO query_test (pk1,pk2,ck3,ck4,c5) VALUES ('f','b','c3','d5','e5');",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506778_-316345844",
      "id": "paragraph_1591537188967_-1264428855",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:81"
    },
    {
      "text": "SELECT * FROM query_test WHERE pk1='a';\r\n",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506778_2015379172",
      "id": "paragraph_1591537188827_3655764",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:82"
    },
    {
      "text": "SELECT * FROM query_test\r\nWHERE pk1='a' ALLOW FILTERING;",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506778_-977154493",
      "id": "paragraph_1591537188629_-1137386199",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:83"
    },
    {
      "text": "SELECT * FROM query_test\r\nWHERE pk1='a' AND pk2='b' AND ck3='c2';",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506779_1254735985",
      "id": "paragraph_1591537250868_521606318",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:84"
    },
    {
      "text": "SELECT * FROM query_test\r\nWHERE pk1='a' AND pk2='b' AND ck4='d2';",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506779_-892298021",
      "id": "paragraph_1591537250287_-1644692718",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:85"
    },
    {
      "text": "SELECT * FROM query_test\r\nWHERE pk1='a' AND pk2='b' AND ck3='c2';",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506779_1714554439",
      "id": "paragraph_1591537252146_1268631291",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:86"
    },
    {
      "text": "SELECT now() FROM query_test;\n",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506780_-1421731895",
      "id": "paragraph_1591537252027_-1074513966",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:87"
    },
    {
      "text": "SELECT now() FROM system.local ;\r\n",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506780_-90676968",
      "id": "paragraph_1591537250108_1358482512",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:88"
    },
    {
      "text": "SELECT dateof(now()) FROM system.local;\r\n",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506780_-1924538674",
      "id": "paragraph_1591537250672_1105983602",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:89"
    },
    {
      "text": "SELECT * FROM query_test WHERE pk1='a' AND pk2 IN ('b','c');\r\n",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506781_1099806464",
      "id": "paragraph_1591537250408_148395097",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:90"
    },
    {
      "text": "SELECT * FROM query_test WHERE pk1='a' AND  pk2='b' AND ck3 IN ('c1','c3');\r\n",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506781_-91879488",
      "id": "paragraph_1591537249947_-903270254",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:91"
    },
    {
      "text": "CREATE TABLE order_status (\r\n status TEXT,\r\n order_id UUID,\r\n shipping_weight_kg DECIMAL,\r\n total DECIMAL,\r\n PRIMARY KEY (status,order_id))\r\nWITH CLUSTERING ORDER BY (order_id DESC);",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506782_-1083713064",
      "id": "paragraph_1591537249826_-1557828795",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:92"
    },
    {
      "text": "INSERT INTO order_status (status,order_id,total) VALUES ('PENDING',UUID(),114.22);\r\nINSERT INTO order_status (status,order_id,total) VALUES ('PENDING',UUID(),33.12);\r\nINSERT INTO order_status (status,order_id,total) VALUES ('PENDING',UUID(),86.63);\r\nINSERT INTO order_status (status,order_id,total,shipping_weight_kg)\r\n  VALUES ('PICKED',UUID(),303.11,2);\r\nINSERT INTO order_status (status,order_id,total,shipping_weight_kg)\r\n  VALUES ('SHIPPED',UUID(),218.99,1.05);\r\nINSERT INTO order_status (status,order_id,total,shipping_weight_kg)\r\n  VALUES ('SHIPPED',UUID(),177.08,1.2);",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506782_107133282",
      "id": "paragraph_1591537249735_-2112694839",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:93"
    },
    {
      "text": "SELECT * FROM order_status WHERE status='PENDING';\r\n",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506783_-1426039293",
      "id": "paragraph_1591537249407_901425809",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:94"
    },
    {
      "text": "INSERT INTO order_status (status,order_id,shipping_weight_kg)\r\n  VALUES ('PENDING',fcb15fc2-feaa-4ba9-a3c6-899d1107cce9,1.4);",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506783_33340186",
      "id": "paragraph_1591537249246_398815916",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:95"
    },
    {
      "text": "UPDATE order_status SET shipping_weight_kg=1.4\r\nWHERE status='PENDING'\r\nAND order_id=fcb15fc2-feaa-4ba9-a3c6-899d1107cce9;",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506783_1140529454",
      "id": "paragraph_1591537248147_-51068456",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:96"
    },
    {
      "text": "SELECT * FROM order_status\r\nWHERE status='PENDING'\r\nAND order_id=fcb15fc2-feaa-4ba9-a3c6-899d1107cce9;",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506784_-613870607",
      "id": "paragraph_1591537345706_1892861146",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:97"
    },
    {
      "text": "UPDATE order_status SET status='PICKED'\r\nWHERE order_id='fcb15fc2-feaa-4ba9-a3c6-899d1107cce9';",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506784_1504288814",
      "id": "paragraph_1591537346868_1919335520",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:98"
    },
    {
      "text": "UPDATE order_status SET shipping_weight_kg=1.4,total=114.22\r\nWHERE status='PICKED'\r\nAND order_id=fcb15fc2-feaa-4ba9-a3c6-899d1107cce9; ",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506784_164222923",
      "id": "paragraph_1591537346766_-1913476292",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:99"
    },
    {
      "text": "SELECT * FROM order_status WHERE order_id=fcb15fc2-feaa-4ba9-a3c6-899d1107cce9 ALLOW FILTERING;\r\n",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506785_-1368077541",
      "id": "paragraph_1591537346367_-225541325",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:100"
    },
    {
      "text": "%md\n\n\n### Deleting data\n\nWhile deleting data and its associated implications have been discussed,\nthere are times when rows or individual column values may need to be\ndeleted. In our use case, we discussed the difficulties of trying to\nwork with the primary key on something that needs to be dynamic, such\nas `status`. In our case, we have an extra row for our order\nthat we need to delete:\n\n```\nDELETE FROM order_status\nWHERE status='PENDING'\nAND order_id=fcb15fc2-feaa-4ba9-a3c6-899d1107cce9;\n```\n\nAs mentioned previously, `DELETE` can also enforce the removal\nof individual column values:\n\n```\nDELETE shipping_weight_kg FROM order_status\nWHERE status='PICKED'\nAND order_id=99886f63-f271-459d-b0b1-218c09cd05a2;\n```\n\n### Note\n\nAgain, take care when using `DELETE`. Deleting creates\ntombstones, which can be problematic to both data consistency and query\nperformance.\n\nSimilar to the previous write operations, `DELETE` requires a\ncomplete primary key. But unlike the other write operations, you do not\nneed to provide all of the clustering keys. In this way, multiple rows\nin a partition can be deleted with a single command.\n\n### Lightweight transactions\n\nOne difference between the CQL `INSERT` and `UPDATE`\nstatements is in how they handle lightweight transactions. Lightweight\ntransactions are essentially a way for Apache Cassandra to enforce a\nsequence of read-and-then-write operations to apply conditional writes.\n\nLightweight transactions are invokable at query time. Apache Cassandra\nimplements the paxos (consensus algorithm) to enforce concurrent\nlightweight transactions on the same sets of data.\n\n### Note\n\nA lightweight transaction in flight will block other lightweight\ntransactions, but will not stop normal reads and writes from querying or\nmutating the same data.\n\n \n\nIn any case, an `INSERT` statement can only check whether a\nrow does not already exist for the specified the `PRIMARY KEY`\ncomponents. If we consider our attempts to insert a new row to set our\norder status to `PENDING`, this could have been used:\n\n```\nINSERT INTO order_status (status,order_id,shipping_weight_kg)\nVALUES ('PENDING',fcb15fc2-feaa-4ba9-a3c6-899d1107cce9,1.4)\nIF NOT EXISTS;\n```\n\nEssentially what is happening here is that Cassandra is performing a\nread to verify the existence of a row with the specified keys. If that\nrow exists, the operation does not proceed, and a response consisting of\napplied with a value of `false` (along with the column values\nwhich failed to write) is returned. If it succeeds, an applied value of\n`true` is returned.\n\nOn the other hand, `UPDATE` allows for more granular control\nin terms of lightweight transactions. It allows for the use of both\n`IF EXISTS` and `IF NOT EXISTS`. Additionally, it\ncan determine whether a write should occur based on arbitrary column\nvalues. In our previous example, we could make our update\nto `shipping_weight_kg` and order total based on a threshold\nfor `shipping_weight_kg`:\n\n```\nUPDATE order_status SET shipping_weight_kg=1.4,total=114.22\nWHERE status='PICKED' AND order_id=fcb15fc2-feaa-4ba9-a3c6-899d1107cce9\nIF shipping_weight_kg > 1.0;\n```\n\nDeletes can also make use of lightweight transactions, much in the same\nway that updates do:\n\n```\nDELETE FROM order_status\nWHERE status='PENDING'\nAND order_id=fcb15fc2-feaa-4ba9-a3c6-899d1107cce9\nIF EXISTS;\n```\n\n### Note\n\nLightweight transactions do incur a performance penalty, so use them\nsparingly. However using them with `DELETE` is probably the\nbest use case, as the performance hit is preferable to generating many\nneedless tombstones.",
      "user": "anonymous",
      "dateUpdated": "2020-07-13T13:06:08+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<h3>Deleting data</h3>\n<p>While deleting data and its associated implications have been discussed,<br />\nthere are times when rows or individual column values may need to be<br />\ndeleted. In our use case, we discussed the difficulties of trying to<br />\nwork with the primary key on something that needs to be dynamic, such<br />\nas <code>status</code>. In our case, we have an extra row for our order<br />\nthat we need to delete:</p>\n<pre><code>DELETE FROM order_status\nWHERE status='PENDING'\nAND order_id=fcb15fc2-feaa-4ba9-a3c6-899d1107cce9;\n</code></pre>\n<p>As mentioned previously, <code>DELETE</code> can also enforce the removal<br />\nof individual column values:</p>\n<pre><code>DELETE shipping_weight_kg FROM order_status\nWHERE status='PICKED'\nAND order_id=99886f63-f271-459d-b0b1-218c09cd05a2;\n</code></pre>\n<h3>Note</h3>\n<p>Again, take care when using <code>DELETE</code>. Deleting creates<br />\ntombstones, which can be problematic to both data consistency and query<br />\nperformance.</p>\n<p>Similar to the previous write operations, <code>DELETE</code> requires a<br />\ncomplete primary key. But unlike the other write operations, you do not<br />\nneed to provide all of the clustering keys. In this way, multiple rows<br />\nin a partition can be deleted with a single command.</p>\n<h3>Lightweight transactions</h3>\n<p>One difference between the CQL <code>INSERT</code> and <code>UPDATE</code><br />\nstatements is in how they handle lightweight transactions. Lightweight<br />\ntransactions are essentially a way for Apache Cassandra to enforce a<br />\nsequence of read-and-then-write operations to apply conditional writes.</p>\n<p>Lightweight transactions are invokable at query time. Apache Cassandra<br />\nimplements the paxos (consensus algorithm) to enforce concurrent<br />\nlightweight transactions on the same sets of data.</p>\n<h3>Note</h3>\n<p>A lightweight transaction in flight will block other lightweight<br />\ntransactions, but will not stop normal reads and writes from querying or<br />\nmutating the same data.</p>\n<p>In any case, an <code>INSERT</code> statement can only check whether a<br />\nrow does not already exist for the specified the <code>PRIMARY KEY</code><br />\ncomponents. If we consider our attempts to insert a new row to set our<br />\norder status to <code>PENDING</code>, this could have been used:</p>\n<pre><code>INSERT INTO order_status (status,order_id,shipping_weight_kg)\nVALUES ('PENDING',fcb15fc2-feaa-4ba9-a3c6-899d1107cce9,1.4)\nIF NOT EXISTS;\n</code></pre>\n<p>Essentially what is happening here is that Cassandra is performing a<br />\nread to verify the existence of a row with the specified keys. If that<br />\nrow exists, the operation does not proceed, and a response consisting of<br />\napplied with a value of <code>false</code> (along with the column values<br />\nwhich failed to write) is returned. If it succeeds, an applied value of<br />\n<code>true</code> is returned.</p>\n<p>On the other hand, <code>UPDATE</code> allows for more granular control<br />\nin terms of lightweight transactions. It allows for the use of both<br />\n<code>IF EXISTS</code> and <code>IF NOT EXISTS</code>. Additionally, it<br />\ncan determine whether a write should occur based on arbitrary column<br />\nvalues. In our previous example, we could make our update<br />\nto <code>shipping_weight_kg</code> and order total based on a threshold<br />\nfor <code>shipping_weight_kg</code>:</p>\n<pre><code>UPDATE order_status SET shipping_weight_kg=1.4,total=114.22\nWHERE status='PICKED' AND order_id=fcb15fc2-feaa-4ba9-a3c6-899d1107cce9\nIF shipping_weight_kg &gt; 1.0;\n</code></pre>\n<p>Deletes can also make use of lightweight transactions, much in the same<br />\nway that updates do:</p>\n<pre><code>DELETE FROM order_status\nWHERE status='PENDING'\nAND order_id=fcb15fc2-feaa-4ba9-a3c6-899d1107cce9\nIF EXISTS;\n</code></pre>\n<h3>Note</h3>\n<p>Lightweight transactions do incur a performance penalty, so use them<br />\nsparingly. However using them with <code>DELETE</code> is probably the<br />\nbest use case, as the performance hit is preferable to generating many<br />\nneedless tombstones.</p>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506785_-619466373",
      "id": "paragraph_1591537346208_2126971232",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "dateStarted": "2020-07-13T13:06:09+0000",
      "dateFinished": "2020-07-13T13:06:10+0000",
      "status": "FINISHED",
      "$$hashKey": "object:101"
    },
    {
      "text": "DELETE FROM order_status\r\nWHERE status='PENDING'\r\nAND order_id=fcb15fc2-feaa-4ba9-a3c6-899d1107cce9;\r\n",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506786_979715424",
      "id": "paragraph_1591537346447_1614806421",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:102"
    },
    {
      "text": "DELETE shipping_weight_kg FROM order_status\r\nWHERE status='PICKED'\r\nAND order_id=99886f63-f271-459d-b0b1-218c09cd05a2;",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506786_2117353354",
      "id": "paragraph_1591537345991_-1524314197",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:103"
    },
    {
      "text": "INSERT INTO order_status (status,order_id,shipping_weight_kg)\r\nVALUES ('PENDING',fcb15fc2-feaa-4ba9-a3c6-899d1107cce9,1.4)\r\nIF NOT EXISTS;\r\n",
      "user": "anonymous",
      "dateUpdated": "2020-07-13T13:05:37+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506787_-129899137",
      "id": "paragraph_1591537344767_668607678",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:104"
    },
    {
      "text": "\r\nUPDATE order_status SET shipping_weight_kg=1.4,total=114.22\r\nWHERE status='PICKED' AND order_id=fcb15fc2-feaa-4ba9-a3c6-899d1107cce9\r\nIF shipping_weight_kg > 1.0;",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506787_-1050071137",
      "id": "paragraph_1591537345539_-1391915017",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:105"
    },
    {
      "text": "DELETE FROM order_status\r\nWHERE status='PENDING'\r\nAND order_id=fcb15fc2-feaa-4ba9-a3c6-899d1107cce9\r\nIF EXISTS;",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506787_-1510219874",
      "id": "paragraph_1591537345367_-1005230932",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:106"
    },
    {
      "text": "%md\n\n\n\n### Executing a BATCH statement\n\nOne of the more controversial features of CQL is the `BATCH`\nstatement. Essentially, this allows for write operations to be grouped\ntogether and applied at once, automatically. Therefore, if one of the\nstatements should fail, they are all rolled back. A common application\nof this is for developers to write the same data to multiple query\ntables, keeping them in sync. `BATCH` statements in CQL can be\napplied as such:\n\n```\nBEGIN BATCH\n INSERT INTO security_logs_by_location (location_id,day,time_in,employee_id,mailstop)\n VALUES ('MPLS2',20180726,'2018-07-26 11:45:22.004','robp','M266');\n INSERT INTO security_logs_by_location_desc (location_id,day,time_in,employee_id,mailstop)\n VALUES ('MPLS2',20180726,'2018-07-26 11:45:22.004','robp','M266');\nAPPLY BATCH;\n```\n\nNote that statements in `BATCH` are not guaranteed to be\nexecuted in any particular order. All statements within a batch are\nassumed to have been applied at the same time, and so will bear the same\nwrite timestamps.\n\nWhat makes this functionality controversial is that it bears a\nresemblance to a keyword in the RDBMS world, which behaves very\ndifferently. RDBMS developers are encouraged to apply several (sometimes\nthousands) of writes in a batch, to apply them all in one network trip,\nand gain some performance. With Cassandra, this approach is dangerous,\nbecause batching too many writes together can exacerbate a coordinator\nnode and potentially cause it to crash.\n\n### Note\n\n`BATCH` was just not designed to apply several updates to the\nsame table. It was designed to apply one update to several (such as five\nor six) tables. This fundamental misunderstanding of the purpose\nof `BATCH` can potentially affect cluster availability.\n\n### The expiring cell\n\nApache Cassandra allows for data in cells to be expired. This is called\nsetting a TTL. TTLs can be applied at write-time, or they can be\nenforced at the table level with a default value. To set a TTL on a row\nat write time, utilize the `USING TTL` clause:\n\n```\nINSERT INTO query_test (pk1,pk2,ck3,ck4,c5)\nVALUES ('f','g','c4','d6','e7')\nUSING TTL 86400;\n```\n\n \n\nLikewise, TTLs can also be applied with the `UPDATE`\nstatement:\n\n```\nUPDATE query_test\nUSING TTL 86400\nSET c5='e7'\nWHERE pk1='f' AND pk2='g' AND ck3='c4' AND ck4='d6';\n```\n\nTTLs represent the number of seconds elapsed since write-time.\n\n### Note\n\nOne day is 86,400 seconds.\n",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<h3>Executing a BATCH statement</h3>\n<p>One of the more controversial features of CQL is the <code>BATCH</code><br />\nstatement. Essentially, this allows for write operations to be grouped<br />\ntogether and applied at once, automatically. Therefore, if one of the<br />\nstatements should fail, they are all rolled back. A common application<br />\nof this is for developers to write the same data to multiple query<br />\ntables, keeping them in sync. <code>BATCH</code> statements in CQL can be<br />\napplied as such:</p>\n<pre><code>BEGIN BATCH\n INSERT INTO security_logs_by_location (location_id,day,time_in,employee_id,mailstop)\n VALUES ('MPLS2',20180726,'2018-07-26 11:45:22.004','robp','M266');\n INSERT INTO security_logs_by_location_desc (location_id,day,time_in,employee_id,mailstop)\n VALUES ('MPLS2',20180726,'2018-07-26 11:45:22.004','robp','M266');\nAPPLY BATCH;\n</code></pre>\n<p>Note that statements in <code>BATCH</code> are not guaranteed to be<br />\nexecuted in any particular order. All statements within a batch are<br />\nassumed to have been applied at the same time, and so will bear the same<br />\nwrite timestamps.</p>\n<p>What makes this functionality controversial is that it bears a<br />\nresemblance to a keyword in the RDBMS world, which behaves very<br />\ndifferently. RDBMS developers are encouraged to apply several (sometimes<br />\nthousands) of writes in a batch, to apply them all in one network trip,<br />\nand gain some performance. With Cassandra, this approach is dangerous,<br />\nbecause batching too many writes together can exacerbate a coordinator<br />\nnode and potentially cause it to crash.</p>\n<h3>Note</h3>\n<p><code>BATCH</code> was just not designed to apply several updates to the<br />\nsame table. It was designed to apply one update to several (such as five<br />\nor six) tables. This fundamental misunderstanding of the purpose<br />\nof <code>BATCH</code> can potentially affect cluster availability.</p>\n<h3>The expiring cell</h3>\n<p>Apache Cassandra allows for data in cells to be expired. This is called<br />\nsetting a TTL. TTLs can be applied at write-time, or they can be<br />\nenforced at the table level with a default value. To set a TTL on a row<br />\nat write time, utilize the <code>USING TTL</code> clause:</p>\n<pre><code>INSERT INTO query_test (pk1,pk2,ck3,ck4,c5)\nVALUES ('f','g','c4','d6','e7')\nUSING TTL 86400;\n</code></pre>\n<p>Likewise, TTLs can also be applied with the <code>UPDATE</code><br />\nstatement:</p>\n<pre><code>UPDATE query_test\nUSING TTL 86400\nSET c5='e7'\nWHERE pk1='f' AND pk2='g' AND ck3='c4' AND ck4='d6';\n</code></pre>\n<p>TTLs represent the number of seconds elapsed since write-time.</p>\n<h3>Note</h3>\n<p>One day is 86,400 seconds.</p>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506787_1075853117",
      "id": "paragraph_1591537684627_1966338088",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:107"
    },
    {
      "text": "BEGIN BATCH\r\n INSERT INTO security_logs_by_location (location_id,day,time_in,employee_id,mailstop)\r\n VALUES ('MPLS2',20180726,'2018-07-26 11:45:22.004','robp','M266');\r\n INSERT INTO security_logs_by_location_desc (location_id,day,time_in,employee_id,mailstop)\r\n VALUES ('MPLS2',20180726,'2018-07-26 11:45:22.004','robp','M266');\r\nAPPLY BATCH;",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506788_-2068062654",
      "id": "paragraph_1591538522446_-514169640",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:108"
    },
    {
      "text": "INSERT INTO query_test (pk1,pk2,ck3,ck4,c5)\r\nVALUES ('f','g','c4','d6','e7')\r\nUSING TTL 86400;",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506788_354113637",
      "id": "paragraph_1591538531025_-60287381",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:109"
    },
    {
      "text": "UPDATE query_test\r\nUSING TTL 86400\r\nSET c5='e7'\r\nWHERE pk1='f' AND pk2='g' AND ck3='c4' AND ck4='d6';",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506789_1212354291",
      "id": "paragraph_1591538528925_-764757916",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:110"
    },
    {
      "text": "",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506789_-1172382908",
      "id": "paragraph_1591537853129_272127009",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:111"
    },
    {
      "text": "%md\n\n\n### Altering a keyspace\n\nChanging a keyspace to use a different RF or strategy is a simple matter\nof using the `ALTER KEYSPACE` command. Let's assume that we\nhave created a keyspace called `fenago_test`:\n\n```\nCREATE KEYSPACE fenago_test WITH replication = {\n  'class': 'SimpleStrategy', 'replication_factor': '1'}\nAND durable_writes = true;\n```\n\nAs it is preferable to use `NetworkTopologyStrategy`, we can\nalter that easily:\n\n```\nALTER KEYSPACE fenago_test  WITH replication = { 'class':'NetworkTopologyStrategy',\n  'datacenter1': '1'};\n```\n\nIf, at some point, we want to add our second data center, that command\nwould look like this:\n\n```\nALTER KEYSPACE fenago_test  WITH replication = { 'class': 'NetworkTopologyStrategy',\n 'datacenter1': '1', 'datacenter2': '1'};\n```\n\nIf we added more nodes to both data centers, and needed to increase the\nRF in each, we can simply run this:\n\n```\nALTER KEYSPACE fenago_test  WITH replication = {'class': 'NetworkTopologyStrategy',\n 'datacenter1': '3', 'datacenter2': '3'};\n```\n\n### Note\n\nUpdating an RF on a keyspace does not automatically move data around.\nThe data will need to be streamed via repair, rebuild, or bootstrap.\n\n### Dropping a keyspace\n\nRemoving a keyspace is a simple matter of using the\n`DROP KEYSPACE` command:\n\n```\nDROP KEYSPACE fenago_test;\n```\n\n### Note\n\nDropping a keyspace does not actually remove the data from disk.\n\n",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<h3>Altering a keyspace</h3>\n<p>Changing a keyspace to use a different RF or strategy is a simple matter<br />\nof using the <code>ALTER KEYSPACE</code> command. Let&rsquo;s assume that we<br />\nhave created a keyspace called <code>fenago_test</code>:</p>\n<pre><code>CREATE KEYSPACE fenago_test WITH replication = {\n  'class': 'SimpleStrategy', 'replication_factor': '1'}\nAND durable_writes = true;\n</code></pre>\n<p>As it is preferable to use <code>NetworkTopologyStrategy</code>, we can<br />\nalter that easily:</p>\n<pre><code>ALTER KEYSPACE fenago_test  WITH replication = { 'class':'NetworkTopologyStrategy',\n  'datacenter1': '1'};\n</code></pre>\n<p>If, at some point, we want to add our second data center, that command<br />\nwould look like this:</p>\n<pre><code>ALTER KEYSPACE fenago_test  WITH replication = { 'class': 'NetworkTopologyStrategy',\n 'datacenter1': '1', 'datacenter2': '1'};\n</code></pre>\n<p>If we added more nodes to both data centers, and needed to increase the<br />\nRF in each, we can simply run this:</p>\n<pre><code>ALTER KEYSPACE fenago_test  WITH replication = {'class': 'NetworkTopologyStrategy',\n 'datacenter1': '3', 'datacenter2': '3'};\n</code></pre>\n<h3>Note</h3>\n<p>Updating an RF on a keyspace does not automatically move data around.<br />\nThe data will need to be streamed via repair, rebuild, or bootstrap.</p>\n<h3>Dropping a keyspace</h3>\n<p>Removing a keyspace is a simple matter of using the<br />\n<code>DROP KEYSPACE</code> command:</p>\n<pre><code>DROP KEYSPACE fenago_test;\n</code></pre>\n<h3>Note</h3>\n<p>Dropping a keyspace does not actually remove the data from disk.</p>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506789_252386089",
      "id": "paragraph_1591537684508_-1217992323",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:112"
    },
    {
      "text": "CREATE KEYSPACE fenago_test WITH replication = {\r\n  'class': 'SimpleStrategy', 'replication_factor': '1'}\r\nAND durable_writes = true;\r\n\r\n",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506790_2134221547",
      "id": "paragraph_1591538571615_1158508780",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:113"
    },
    {
      "text": "ALTER KEYSPACE fenago_test  WITH replication = { 'class':'NetworkTopologyStrategy',\r\n  'datacenter1': '1'};",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506790_-963435593",
      "id": "paragraph_1591538571410_1221203326",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:114"
    },
    {
      "text": "ALTER KEYSPACE fenago_test  WITH replication = { 'class': 'NetworkTopologyStrategy',\r\n 'datacenter1': '1', 'datacenter2': '1'};",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506790_-716640402",
      "id": "paragraph_1591538571405_911624965",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:115"
    },
    {
      "text": "ALTER KEYSPACE fenago_test WITH REPLICATION=\r\n {'class':'SimpleStrategy', 'replication_factor':1};",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506791_-2095035872",
      "id": "paragraph_1591538570906_1107173253",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:116"
    },
    {
      "text": "%md\r\n\r\n### Altering a table\r\n\r\nTables can be changed with the `ALTER` statement, using it to\r\nadd a column:\r\n\r\n```\r\nALTER TABLE query_test ADD c6 TEXT;\r\n```\r\n\r\nOr to remove a column:\r\n\r\n```\r\nALTER TABLE query_test DROP c5;\r\n```\r\n\r\n### Note\r\n\r\nPrimary key definitions cannot be changed on a table. To accomplish\r\nthis, the table must be recreated.\r\n\r\nTable options can also be set or changed with the `ALTER`\r\nstatement. For example, this statement updates the default TTL on a\r\ntable to one day (in seconds):\r\n\r\n```\r\nALTER TABLE query_test WITH default_time_to_live = 86400;\r\n```\r\n\r\n### Truncating a table\r\n\r\nTo remove all data from a table, you can use the\r\n`TRUNCATE TABLE` command:\r\n\r\n```\r\nTRUNCATE TABLE query_test;\r\n```\r\n\r\n \r\n\r\n### Dropping a table\r\n\r\nRemoving a table is a simple matter of using the `DROP TABLE`\r\ncommand:\r\n\r\n```\r\nDROP TABLE query_test;\r\n```\r\n\r\n### Note\r\n\r\nTry to avoid frequent drops or creates of a table with the same name.\r\nThis process has proven to be problematic with Apache Cassandra in the\r\npast. If you need to recreate a table, it’s always a good idea to\r\n`TRUNCATE` it before dropping it. It may be helpful to create\r\na table with a version number on the end of it\r\n(`query_test_v2`) to prevent this problem from occurring.\r\n\r\n#### Truncate versus drop\r\n\r\nIt's important to note that dropping a table is different from\r\ntruncating it. A drop will remove the table from the schema definition,\r\nbut the data will remain on-disk. With truncate, the data is removed,\r\nbut the schema remains. Truncate is also the only way to clear all data\r\nfrom a table in a single command, as a CQL delete requires key\r\nparameters.",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<h3>Altering a table</h3>\n<p>Tables can be changed with the <code>ALTER</code> statement, using it to<br />\nadd a column:</p>\n<pre><code>ALTER TABLE query_test ADD c6 TEXT;\n</code></pre>\n<p>Or to remove a column:</p>\n<pre><code>ALTER TABLE query_test DROP c5;\n</code></pre>\n<h3>Note</h3>\n<p>Primary key definitions cannot be changed on a table. To accomplish<br />\nthis, the table must be recreated.</p>\n<p>Table options can also be set or changed with the <code>ALTER</code><br />\nstatement. For example, this statement updates the default TTL on a<br />\ntable to one day (in seconds):</p>\n<pre><code>ALTER TABLE query_test WITH default_time_to_live = 86400;\n</code></pre>\n<h3>Truncating a table</h3>\n<p>To remove all data from a table, you can use the<br />\n<code>TRUNCATE TABLE</code> command:</p>\n<pre><code>TRUNCATE TABLE query_test;\n</code></pre>\n<h3>Dropping a table</h3>\n<p>Removing a table is a simple matter of using the <code>DROP TABLE</code><br />\ncommand:</p>\n<pre><code>DROP TABLE query_test;\n</code></pre>\n<h3>Note</h3>\n<p>Try to avoid frequent drops or creates of a table with the same name.<br />\nThis process has proven to be problematic with Apache Cassandra in the<br />\npast. If you need to recreate a table, it’s always a good idea to<br />\n<code>TRUNCATE</code> it before dropping it. It may be helpful to create<br />\na table with a version number on the end of it<br />\n(<code>query_test_v2</code>) to prevent this problem from occurring.</p>\n<h4>Truncate versus drop</h4>\n<p>It&rsquo;s important to note that dropping a table is different from<br />\ntruncating it. A drop will remove the table from the schema definition,<br />\nbut the data will remain on-disk. With truncate, the data is removed,<br />\nbut the schema remains. Truncate is also the only way to clear all data<br />\nfrom a table in a single command, as a CQL delete requires key<br />\nparameters.</p>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506793_-963261539",
      "id": "paragraph_1591537684305_-1616373307",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:117"
    },
    {
      "text": "ALTER TABLE query_test ADD c6 TEXT;\r\n",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506793_1770260015",
      "id": "paragraph_1591538636684_1450254750",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:118"
    },
    {
      "text": "\r\nALTER TABLE query_test DROP c5;\r\n\r\n",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506794_2135003571",
      "id": "paragraph_1591538633433_-933039709",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:119"
    },
    {
      "text": "\r\nALTER TABLE query_test WITH default_time_to_live = 86400;\r\n",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506794_-1005911586",
      "id": "paragraph_1591538633245_117360700",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:120"
    },
    {
      "text": "TRUNCATE TABLE query_test;\r\n",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506794_1808576046",
      "id": "paragraph_1591538632446_-1011050251",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:121"
    },
    {
      "text": "DROP TABLE query_test;",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506794_1046570848",
      "id": "paragraph_1591538631433_1721167041",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:122"
    },
    {
      "text": "",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506795_1757750704",
      "id": "paragraph_1591537683987_-1127474316",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:123"
    },
    {
      "text": "%md\n\n\n### Creating an index\n\nCassandra comes with the ability to apply distributed, secondary indexes\non arbitrary columns in a table. For an application of this, let's look\nat a different solution for our `order_status` table. For\nstarters, we'll add the date/time of the order as a clustering column.\nNext, we'll store the total as a `BIGINT` representing the\nnumber of cents (instead of `DECIMAL` for dollars), to ensure\nthat we maintain our precision accuracy. But the biggest difference is\nthat, in talking with our business resources, we will discover that\nbucketing by week will give us a partition of manageable size:\n\n```\nCREATE TABLE order_status_by_week (\n   week_bucket bigint,\n   order_datetime timestamp,\n   order_id uuid,\n   shipping_weight_kg decimal,\n   status text,\n   total bigint,\n   PRIMARY KEY (week_bucket, order_datetime, order_id)\n) WITH CLUSTERING ORDER BY (order_datetime DESC, order_id ASC)\n```\n\n \n\nNext, we will add similar rows into this table:\n\n```\nINSERT INTO order_status_by_week (status,order_id,total,week_bucket,order_datetime)\nVALUES ('PENDING',UUID(),11422,20180704,'2018-07-25 15:22:28');\nINSERT INTO order_status_by_week (status,order_id,total,week_bucket,order_datetime)\nVALUES ('PENDING',UUID(),3312,20180704,'2018-07-27 09:44:18');\nINSERT INTO order_status_by_week (status,order_id,total,week_bucket,order_datetime)\nVALUES ('PENDING',UUID(),8663,20180704,'2018-07-27 11:33:01');\nINSERT INTO order_status_by_week (status,order_id,total,shipping_weight_kg,week_bucket,order_datetime)\nVALUES ('PICKED',UUID(),30311,2,20180704,'2018-07-24 16:02:47');\nINSERT INTO order_status_by_week (status,order_id,total,shipping_weight_kg,week_bucket,order_datetime)\nVALUES ('SHIPPED',UUID(),21899,1.05,20180704,'2018-07-24 13:28:54');\nINSERT INTO order_status_by_week (status,order_id,total,shipping_weight_kg,week_bucket,order_datetime)\nVALUES ('SHIPPED',UUID(),17708,1.2,20180704,'2018-07-25 08:02:29');\n```\n\nNow I can query for orders placed during the fourth week of July, 2018:\n\n```\nSELECT * FROM order_status_by_week WHERE week_bucket=20180704;\n\nweek_bucket | order_datetime                  | order_id | shipping_weight_kg | status  | total\n-------------+---------------------------------+--------------------------------------+--------------------+---------+-------\n   20180704 | 2018-07-27 16:33:01.000000+0000 | 02d3af90-f315-41d9-ab59-4c69884925b9 |               null | PENDING | 8663\n   20180704 | 2018-07-27 14:44:18.000000+0000 | cb210378-752f-4a6b-bd2c-6d41afd4e614 |               null | PENDING | 3312\n   20180704 | 2018-07-25 20:22:28.000000+0000 | 59cf4afa-742c-4448-bd99-45c61660aa64 |               null | PENDING | 11422\n   20180704 | 2018-07-25 13:02:29.000000+0000 | c5d111b9-d048-4829-a998-1ca51c107a8e |                1.2 | SHIPPED | 17708\n   20180704 | 2018-07-24 21:02:47.000000+0000 | b111d1d3-9e54-481e-858e-b56e38a14b57 |                  2 | PICKED | 30311\n   20180704 | 2018-07-24 18:28:54.000000+0000 | c8b3101b-7804-444f-9c4f-65c17ff201f2 |               1.05 | SHIPPED | 21899\n\n(6 rows)\n```\n\nThis works, but without status as a part of the primary key definition,\nhow can we query for `PENDING` orders? Here is where we will\nadd a secondary index to handle this scenario:\n\n```\nCREATE INDEX [index_name] ON [keyspace_name.]<table_name>(<column_name>);\n```\n\n### Note\n\nYou can create an index without a name. Its name will then default to\n`[table_name]_[column_name]_idx`.\n\nIn the following code block, we will create an index, and then show how\nit is used:\n\n```\nCREATE INDEX order_status_idx ON order_status_by_week(status);\n\nSELECT week_bucket,order_datetime,order_id,status,total FROM order_status_by_week\n WHERE week_bucket=20180704 AND status='PENDING';\n\n week_bucket | order_datetime      | order_id                             | status  | total\n-------------+---------------------+--------------------------------------+-----------------\n    20180704 | 2018-07-27 16:33:01 | 02d3af90-f315-41d9-ab59-4c69884925b9 | PENDING |  8663\n    20180704 | 2018-07-27 14:44:18 | cb210378-752f-4a6b-bd2c-6d41afd4e614 | PENDING |  3312\n    20180704 | 2018-07-25 20:22:28 | 59cf4afa-742c-4448-bd99-45c61660aa64 | PENDING | 11422\n\n(3 rows)\n```\n\nIn this way, we can query on a column that has a more dynamic value. The\nstatus of the order can effectively be updated, without having to delete\nthe entire prior row.\n\n#### Caution with implementing secondary indexes\n\nWhile secondary indexes seem like a simple solution to add a dynamic\nquerying capability to a Cassandra model, caution needs to be given when\naddressing their use. Effective, high-performing, distributed\ndatabase-indexing is a computing problem that has yet to be solved.\nProper, well-defined queries based on primary key definitions are\nhigh-performing within Apache Cassandra, because they take the\nunderlying storage model into consideration. Secondary indexing actually\nworks against this principle.\n\nSecondary indexes in Apache Cassandra store data in a hidden table\n(behind the scenes) that only contains lookups for data contained on the\ncurrent node. Essentially, a secondary index query (which is not also\nfiltered by a partition key) will need to confer with every node in the\ncluster. This can be problematic with large clusters and potentially\nlead to query timeouts.\n\n \n\n### Note\n\nOur preceding example using a secondary index gets around this problem,\nbecause our query is also filtering by its partition key. This forces\nthe query to limit itself to a single node.\n\nCardinality is another problem to consider when building a secondary\nindex in Apache Cassandra. Let's say we created a secondary index on\n`order_id`, so that we can pull up an individual order if we\nhad to. In that scenario, the high cardinality of `order_id`\nwould essentially mean that we would query every node in the cluster,\njust to end up reading one partition from one node.\n\nAuthor (and DataStax Cassandra MVP) Richard Low accurately explains this\nin his article *The Sweet Spot for Cassandra Secondary Indexing*,\nwhen he describes creating an index on a high-cardinality column such as\nan email address:\n\n> **This means only one node (plus replicas) store data for a given\n> email address but all nodes are queried for each lookup. This is\n> wasteful—every node has potentially done a disk seek but we've only\n> got back one partition.**\n\nOn the flip-side of that coin, consider a secondary index on a\nlow-cardinality column, such as a Boolean. Now consider that the table\nin question has 20,000,000 rows. With an even distribution, both index\nentries will each point to 10,000,000 rows. That is far too many to be\nquerying at once.\n\nWe have established that querying with a secondary index in conjunction\nwith a partition key can perform well. But is there a time when querying\nonly by a secondary index could be efficient? Once again, Low's article\nconcludes the following:\n\n> *...the best use case for Cassandra's secondary indexes is when p is\n> approximately n; i.e. the number of partitions is about equal to the\n> number of nodes. Any fewer partitions and your n index lookups are\n> wasted; many more partitions and each node is doing many seeks. In\n> practice, this means indexing is most useful for returning tens, maybe\n> hundreds of results.*\n\nIn conclusion, secondary indexing can help with large solutions at scale\nunder certain conditions. But when used alone, the trade-off is usually\none of giving up performance in exchange for convenience. The number of\nnodes in the cluster, total partition keys, and cardinality of the\ncolumn in question must all be taken into consideration.\n\n### Dropping an index\n\nDropping a secondary index on a table is a simple task:\n\n```\nDROP INDEX [index_name]\n```\n\nIf you do not know the name of the index (or created it without a name),\nyou can describe the table to find it. Indexes on a table will appear at\nthe bottom of the definition. Then you can `DROP` it:\n\n```\nCREATE INDEX ON query_test(c5);\nDESC TABLE query_test ;\n\nCREATE TABLE fenago_ch3.query_test (\n   pk1 text,\n   pk2 text,\n   ck3 text,\n   ck4 text,\n   c5 text,\n   PRIMARY KEY ((pk1, pk2), ck3, ck4)\n) WITH CLUSTERING ORDER BY (ck3 DESC, ck4 ASC)\n...\n   AND speculative_retry = '99PERCENTILE';\nCREATE INDEX query_test_c5_idx ON fenago_ch3.query_test (c5);\n\nDROP INDEX query_test_c5_idx ;\n```\n\n",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<h3>Creating an index</h3>\n<p>Cassandra comes with the ability to apply distributed, secondary indexes<br />\non arbitrary columns in a table. For an application of this, let&rsquo;s look<br />\nat a different solution for our <code>order_status</code> table. For<br />\nstarters, we&rsquo;ll add the date/time of the order as a clustering column.<br />\nNext, we&rsquo;ll store the total as a <code>BIGINT</code> representing the<br />\nnumber of cents (instead of <code>DECIMAL</code> for dollars), to ensure<br />\nthat we maintain our precision accuracy. But the biggest difference is<br />\nthat, in talking with our business resources, we will discover that<br />\nbucketing by week will give us a partition of manageable size:</p>\n<pre><code>CREATE TABLE order_status_by_week (\n   week_bucket bigint,\n   order_datetime timestamp,\n   order_id uuid,\n   shipping_weight_kg decimal,\n   status text,\n   total bigint,\n   PRIMARY KEY (week_bucket, order_datetime, order_id)\n) WITH CLUSTERING ORDER BY (order_datetime DESC, order_id ASC)\n</code></pre>\n<p>Next, we will add similar rows into this table:</p>\n<pre><code>INSERT INTO order_status_by_week (status,order_id,total,week_bucket,order_datetime)\nVALUES ('PENDING',UUID(),11422,20180704,'2018-07-25 15:22:28');\nINSERT INTO order_status_by_week (status,order_id,total,week_bucket,order_datetime)\nVALUES ('PENDING',UUID(),3312,20180704,'2018-07-27 09:44:18');\nINSERT INTO order_status_by_week (status,order_id,total,week_bucket,order_datetime)\nVALUES ('PENDING',UUID(),8663,20180704,'2018-07-27 11:33:01');\nINSERT INTO order_status_by_week (status,order_id,total,shipping_weight_kg,week_bucket,order_datetime)\nVALUES ('PICKED',UUID(),30311,2,20180704,'2018-07-24 16:02:47');\nINSERT INTO order_status_by_week (status,order_id,total,shipping_weight_kg,week_bucket,order_datetime)\nVALUES ('SHIPPED',UUID(),21899,1.05,20180704,'2018-07-24 13:28:54');\nINSERT INTO order_status_by_week (status,order_id,total,shipping_weight_kg,week_bucket,order_datetime)\nVALUES ('SHIPPED',UUID(),17708,1.2,20180704,'2018-07-25 08:02:29');\n</code></pre>\n<p>Now I can query for orders placed during the fourth week of July, 2018:</p>\n<pre><code>SELECT * FROM order_status_by_week WHERE week_bucket=20180704;\n\nweek_bucket | order_datetime                  | order_id | shipping_weight_kg | status  | total\n-------------+---------------------------------+--------------------------------------+--------------------+---------+-------\n   20180704 | 2018-07-27 16:33:01.000000+0000 | 02d3af90-f315-41d9-ab59-4c69884925b9 |               null | PENDING | 8663\n   20180704 | 2018-07-27 14:44:18.000000+0000 | cb210378-752f-4a6b-bd2c-6d41afd4e614 |               null | PENDING | 3312\n   20180704 | 2018-07-25 20:22:28.000000+0000 | 59cf4afa-742c-4448-bd99-45c61660aa64 |               null | PENDING | 11422\n   20180704 | 2018-07-25 13:02:29.000000+0000 | c5d111b9-d048-4829-a998-1ca51c107a8e |                1.2 | SHIPPED | 17708\n   20180704 | 2018-07-24 21:02:47.000000+0000 | b111d1d3-9e54-481e-858e-b56e38a14b57 |                  2 | PICKED | 30311\n   20180704 | 2018-07-24 18:28:54.000000+0000 | c8b3101b-7804-444f-9c4f-65c17ff201f2 |               1.05 | SHIPPED | 21899\n\n(6 rows)\n</code></pre>\n<p>This works, but without status as a part of the primary key definition,<br />\nhow can we query for <code>PENDING</code> orders? Here is where we will<br />\nadd a secondary index to handle this scenario:</p>\n<pre><code>CREATE INDEX [index_name] ON [keyspace_name.]&lt;table_name&gt;(&lt;column_name&gt;);\n</code></pre>\n<h3>Note</h3>\n<p>You can create an index without a name. Its name will then default to<br />\n<code>[table_name]_[column_name]_idx</code>.</p>\n<p>In the following code block, we will create an index, and then show how<br />\nit is used:</p>\n<pre><code>CREATE INDEX order_status_idx ON order_status_by_week(status);\n\nSELECT week_bucket,order_datetime,order_id,status,total FROM order_status_by_week\n WHERE week_bucket=20180704 AND status='PENDING';\n\n week_bucket | order_datetime      | order_id                             | status  | total\n-------------+---------------------+--------------------------------------+-----------------\n    20180704 | 2018-07-27 16:33:01 | 02d3af90-f315-41d9-ab59-4c69884925b9 | PENDING |  8663\n    20180704 | 2018-07-27 14:44:18 | cb210378-752f-4a6b-bd2c-6d41afd4e614 | PENDING |  3312\n    20180704 | 2018-07-25 20:22:28 | 59cf4afa-742c-4448-bd99-45c61660aa64 | PENDING | 11422\n\n(3 rows)\n</code></pre>\n<p>In this way, we can query on a column that has a more dynamic value. The<br />\nstatus of the order can effectively be updated, without having to delete<br />\nthe entire prior row.</p>\n<h4>Caution with implementing secondary indexes</h4>\n<p>While secondary indexes seem like a simple solution to add a dynamic<br />\nquerying capability to a Cassandra model, caution needs to be given when<br />\naddressing their use. Effective, high-performing, distributed<br />\ndatabase-indexing is a computing problem that has yet to be solved.<br />\nProper, well-defined queries based on primary key definitions are<br />\nhigh-performing within Apache Cassandra, because they take the<br />\nunderlying storage model into consideration. Secondary indexing actually<br />\nworks against this principle.</p>\n<p>Secondary indexes in Apache Cassandra store data in a hidden table<br />\n(behind the scenes) that only contains lookups for data contained on the<br />\ncurrent node. Essentially, a secondary index query (which is not also<br />\nfiltered by a partition key) will need to confer with every node in the<br />\ncluster. This can be problematic with large clusters and potentially<br />\nlead to query timeouts.</p>\n<h3>Note</h3>\n<p>Our preceding example using a secondary index gets around this problem,<br />\nbecause our query is also filtering by its partition key. This forces<br />\nthe query to limit itself to a single node.</p>\n<p>Cardinality is another problem to consider when building a secondary<br />\nindex in Apache Cassandra. Let&rsquo;s say we created a secondary index on<br />\n<code>order_id</code>, so that we can pull up an individual order if we<br />\nhad to. In that scenario, the high cardinality of <code>order_id</code><br />\nwould essentially mean that we would query every node in the cluster,<br />\njust to end up reading one partition from one node.</p>\n<p>Author (and DataStax Cassandra MVP) Richard Low accurately explains this<br />\nin his article <em>The Sweet Spot for Cassandra Secondary Indexing</em>,<br />\nwhen he describes creating an index on a high-cardinality column such as<br />\nan email address:</p>\n<blockquote>\n<p><strong>This means only one node (plus replicas) store data for a given<br />\nemail address but all nodes are queried for each lookup. This is<br />\nwasteful—every node has potentially done a disk seek but we&rsquo;ve only<br />\ngot back one partition.</strong></p>\n</blockquote>\n<p>On the flip-side of that coin, consider a secondary index on a<br />\nlow-cardinality column, such as a Boolean. Now consider that the table<br />\nin question has 20,000,000 rows. With an even distribution, both index<br />\nentries will each point to 10,000,000 rows. That is far too many to be<br />\nquerying at once.</p>\n<p>We have established that querying with a secondary index in conjunction<br />\nwith a partition key can perform well. But is there a time when querying<br />\nonly by a secondary index could be efficient? Once again, Low&rsquo;s article<br />\nconcludes the following:</p>\n<blockquote>\n<p><em>&hellip;the best use case for Cassandra&rsquo;s secondary indexes is when p is<br />\napproximately n; i.e. the number of partitions is about equal to the<br />\nnumber of nodes. Any fewer partitions and your n index lookups are<br />\nwasted; many more partitions and each node is doing many seeks. In<br />\npractice, this means indexing is most useful for returning tens, maybe<br />\nhundreds of results.</em></p>\n</blockquote>\n<p>In conclusion, secondary indexing can help with large solutions at scale<br />\nunder certain conditions. But when used alone, the trade-off is usually<br />\none of giving up performance in exchange for convenience. The number of<br />\nnodes in the cluster, total partition keys, and cardinality of the<br />\ncolumn in question must all be taken into consideration.</p>\n<h3>Dropping an index</h3>\n<p>Dropping a secondary index on a table is a simple task:</p>\n<pre><code>DROP INDEX [index_name]\n</code></pre>\n<p>If you do not know the name of the index (or created it without a name),<br />\nyou can describe the table to find it. Indexes on a table will appear at<br />\nthe bottom of the definition. Then you can <code>DROP</code> it:</p>\n<pre><code>CREATE INDEX ON query_test(c5);\nDESC TABLE query_test ;\n\nCREATE TABLE fenago_ch3.query_test (\n   pk1 text,\n   pk2 text,\n   ck3 text,\n   ck4 text,\n   c5 text,\n   PRIMARY KEY ((pk1, pk2), ck3, ck4)\n) WITH CLUSTERING ORDER BY (ck3 DESC, ck4 ASC)\n...\n   AND speculative_retry = '99PERCENTILE';\nCREATE INDEX query_test_c5_idx ON fenago_ch3.query_test (c5);\n\nDROP INDEX query_test_c5_idx ;\n</code></pre>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506795_1160783648",
      "id": "paragraph_1591537683786_-840020111",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:124"
    },
    {
      "text": "CREATE TABLE order_status_by_week (\n   week_bucket bigint,\n   order_datetime timestamp,\n   order_id uuid,\n   shipping_weight_kg decimal,\n   status text,\n   total bigint,\n   PRIMARY KEY (week_bucket, order_datetime, order_id)\n) WITH CLUSTERING ORDER BY (order_datetime DESC, order_id ASC);\n",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506796_-1916060018",
      "id": "paragraph_1591538787886_1516926171",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:125"
    },
    {
      "text": "\nINSERT INTO order_status_by_week (status,order_id,total,week_bucket,order_datetime)\nVALUES ('PENDING',UUID(),11422,20180704,'2018-07-25 15:22:28');\nINSERT INTO order_status_by_week (status,order_id,total,week_bucket,order_datetime)\nVALUES ('PENDING',UUID(),3312,20180704,'2018-07-27 09:44:18');\nINSERT INTO order_status_by_week (status,order_id,total,week_bucket,order_datetime)\nVALUES ('PENDING',UUID(),8663,20180704,'2018-07-27 11:33:01');\nINSERT INTO order_status_by_week (status,order_id,total,shipping_weight_kg,week_bucket,order_datetime)\nVALUES ('PICKED',UUID(),30311,2,20180704,'2018-07-24 16:02:47');\nINSERT INTO order_status_by_week (status,order_id,total,shipping_weight_kg,week_bucket,order_datetime)\nVALUES ('SHIPPED',UUID(),21899,1.05,20180704,'2018-07-24 13:28:54');\nINSERT INTO order_status_by_week (status,order_id,total,shipping_weight_kg,week_bucket,order_datetime)\nVALUES ('SHIPPED',UUID(),17708,1.2,20180704,'2018-07-25 08:02:29');\n",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506797_-1473426533",
      "id": "paragraph_1591538916146_9339533",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:126"
    },
    {
      "text": "\nSELECT * FROM order_status_by_week WHERE week_bucket=20180704;",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506797_-663291866",
      "id": "paragraph_1591538915268_-1678874792",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:127"
    },
    {
      "text": "CREATE INDEX order_status_idx ON order_status_by_week(status);\r\n",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506797_-1048654794",
      "id": "paragraph_1591538787709_-1377670782",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:128"
    },
    {
      "text": "SELECT week_bucket,order_datetime,order_id,status,total FROM order_status_by_week\r\n WHERE week_bucket=20180704 AND status='PENDING';",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506798_1157818725",
      "id": "paragraph_1591970752890_1754052298",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:129"
    },
    {
      "text": "CREATE INDEX ON query_test(c5);\r\n\r\nCREATE TABLE fenago_ch3.query_test (\r\n   pk1 text,\r\n   pk2 text,\r\n   ck3 text,\r\n   ck4 text,\r\n   c5 text,\r\n   PRIMARY KEY ((pk1, pk2), ck3, ck4)\r\n) WITH CLUSTERING ORDER BY (ck3 DESC, ck4 ASC)\r\n...\r\n   AND speculative_retry = '99PERCENTILE';\r\nCREATE INDEX query_test_c5_idx ON fenago_ch3.query_test (c5);\r\n\r\nDROP INDEX query_test_c5_idx ;",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506798_-2120118157",
      "id": "paragraph_1591538787545_-1067955983",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:130"
    },
    {
      "text": "%md\n\n### Creating a custom data type\n\nApache Cassandra allows for the creation of custom **user-defined\ntypes** (**UDTs**). UDTs allow for further denormalization of data\nwithin a row. A good example of this is a mailing address for customers.\nAssume a simple table:\n\n```\nCREATE TABLE customer (\n last_name TEXT,\n first_name TEXT,\n company TEXT,\n PRIMARY KEY (last_name,first_name));\n```\n\n \n\nNow, our customers have mailing addresses. Corporate customers usually\nhave addresses for multiple things, including billing, shipping,\nheadquarters, distribution centers, store locations, and data centers.\nSo how do we track multiple addresses for a single customer? One way to\naccomplish this would be to create a collection of a UDT:\n\n```\nCREATE TYPE customer_address (\n type TEXT,\n street TEXT,\n city TEXT,\n state TEXT,\n postal_code TEXT,\n country TEXT);\n```\n\nNow, let's add the `customer_address` UDT to the table as a\nlist. This way, a customer can have multiple addresses:\n\n```\nALTER TABLE customer ADD addresses LIST<FROZEN <customer_address>>;\n```\n\n### Note\n\nThe `FROZEN` types are those that are immutable. They are\nwritten once and cannot be changed, short of rewriting all underlying\nproperties.\n\nWith that in place, let's add a few rows to the table:\n\n```\nINSERT INTO customer (last_name,first_name,company,addresses) VALUES ('Washburne','Hoban','Serenity',[{type:'SHIPPING',street:'9843 32nd Place',city:'Charlotte',state:'NC',postal_code:'05601',country:'USA'}]);\nINSERT INTO customer (last_name,first_name,company,addresses) VALUES ('Washburne','Zoey','Serenity',[{type:'SHIPPING',street:'9843 32nd Place',city:'Charlotte',state:'NC',postal_code:'05601',country:'USA'},{type:'BILL TO',street:'9800 32nd Place',city:'Charlotte',state:'NC',postal_code:'05601',country:'USA'}]);\nINSERT INTO customer (last_name,first_name,company,addresses) VALUES ('Tam','Simon','Persephone General Hospital',[{type:'BILL TO',street:'83595 25th Boulevard',city:'Lawrence',state:'KS',postal_code:'66044',country:'USA'}]);\n```\n\nQuerying it for Zoey Washburne shows that her company has two addresses:\n\n```\nSELECT last_name,first_name,company,addresses FROM customer\nWHERE last_name='Washburne' AND first_name='Zoey';\n\nlast_name | first_name |  company | addresses\n-----------+------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------\nWashburne |       Zoey | Serenity |[{type: 'SHIPPING', street: '9843 32nd Place', city: 'Charlotte', state: 'NC', postal_code: '05601', country: 'USA', street2: null}, {type: 'BILL TO', street: '9800 32nd Place', city: 'Charlotte', state: 'NC', postal_code: '05601', country: 'USA', street2: null}]\n\n(1 rows)\n```\n\n### Altering a custom type\n\nUDTs can have columns added to them. For instance, some addresses have\ntwo lines, so we can add an `address2` column:\n\n```\nALTER TYPE customer_address ADD address2 TEXT;\n```\n\nUDT columns can also be renamed with the `ALTER` command:\n\n```\nALTER TYPE customer_address RENAME address2 TO street2;\n```\n\n### Note\n\nColumns within a UDT cannot be removed or dropped, only added or\nrenamed.\n\n### Dropping a custom type\n\nUDTs can be dropped very easily, just by issuing the `DROP`\ncommand. If we create a simple UDT:\n\n```\nCREATE TYPE test_type (value TEXT);\n```\n\n \n\nIt can be dropped like this:\n\n```\nDROP TYPE test_type;\n```\n\n",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<h3>Creating a custom data type</h3>\n<p>Apache Cassandra allows for the creation of custom <strong>user-defined<br />\ntypes</strong> (<strong>UDTs</strong>). UDTs allow for further denormalization of data<br />\nwithin a row. A good example of this is a mailing address for customers.<br />\nAssume a simple table:</p>\n<pre><code>CREATE TABLE customer (\n last_name TEXT,\n first_name TEXT,\n company TEXT,\n PRIMARY KEY (last_name,first_name));\n</code></pre>\n<p>Now, our customers have mailing addresses. Corporate customers usually<br />\nhave addresses for multiple things, including billing, shipping,<br />\nheadquarters, distribution centers, store locations, and data centers.<br />\nSo how do we track multiple addresses for a single customer? One way to<br />\naccomplish this would be to create a collection of a UDT:</p>\n<pre><code>CREATE TYPE customer_address (\n type TEXT,\n street TEXT,\n city TEXT,\n state TEXT,\n postal_code TEXT,\n country TEXT);\n</code></pre>\n<p>Now, let&rsquo;s add the <code>customer_address</code> UDT to the table as a<br />\nlist. This way, a customer can have multiple addresses:</p>\n<pre><code>ALTER TABLE customer ADD addresses LIST&lt;FROZEN &lt;customer_address&gt;&gt;;\n</code></pre>\n<h3>Note</h3>\n<p>The <code>FROZEN</code> types are those that are immutable. They are<br />\nwritten once and cannot be changed, short of rewriting all underlying<br />\nproperties.</p>\n<p>With that in place, let&rsquo;s add a few rows to the table:</p>\n<pre><code>INSERT INTO customer (last_name,first_name,company,addresses) VALUES ('Washburne','Hoban','Serenity',[{type:'SHIPPING',street:'9843 32nd Place',city:'Charlotte',state:'NC',postal_code:'05601',country:'USA'}]);\nINSERT INTO customer (last_name,first_name,company,addresses) VALUES ('Washburne','Zoey','Serenity',[{type:'SHIPPING',street:'9843 32nd Place',city:'Charlotte',state:'NC',postal_code:'05601',country:'USA'},{type:'BILL TO',street:'9800 32nd Place',city:'Charlotte',state:'NC',postal_code:'05601',country:'USA'}]);\nINSERT INTO customer (last_name,first_name,company,addresses) VALUES ('Tam','Simon','Persephone General Hospital',[{type:'BILL TO',street:'83595 25th Boulevard',city:'Lawrence',state:'KS',postal_code:'66044',country:'USA'}]);\n</code></pre>\n<p>Querying it for Zoey Washburne shows that her company has two addresses:</p>\n<pre><code>SELECT last_name,first_name,company,addresses FROM customer\nWHERE last_name='Washburne' AND first_name='Zoey';\n\nlast_name | first_name |  company | addresses\n-----------+------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------\nWashburne |       Zoey | Serenity |[{type: 'SHIPPING', street: '9843 32nd Place', city: 'Charlotte', state: 'NC', postal_code: '05601', country: 'USA', street2: null}, {type: 'BILL TO', street: '9800 32nd Place', city: 'Charlotte', state: 'NC', postal_code: '05601', country: 'USA', street2: null}]\n\n(1 rows)\n</code></pre>\n<h3>Altering a custom type</h3>\n<p>UDTs can have columns added to them. For instance, some addresses have<br />\ntwo lines, so we can add an <code>address2</code> column:</p>\n<pre><code>ALTER TYPE customer_address ADD address2 TEXT;\n</code></pre>\n<p>UDT columns can also be renamed with the <code>ALTER</code> command:</p>\n<pre><code>ALTER TYPE customer_address RENAME address2 TO street2;\n</code></pre>\n<h3>Note</h3>\n<p>Columns within a UDT cannot be removed or dropped, only added or<br />\nrenamed.</p>\n<h3>Dropping a custom type</h3>\n<p>UDTs can be dropped very easily, just by issuing the <code>DROP</code><br />\ncommand. If we create a simple UDT:</p>\n<pre><code>CREATE TYPE test_type (value TEXT);\n</code></pre>\n<p>It can be dropped like this:</p>\n<pre><code>DROP TYPE test_type;\n</code></pre>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506798_-1771289465",
      "id": "paragraph_1591538787286_1948945744",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:131"
    },
    {
      "text": "CREATE TABLE customer (\r\n last_name TEXT,\r\n first_name TEXT,\r\n company TEXT,\r\n PRIMARY KEY (last_name,first_name));\r\n\r\n\r\n",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506799_-1943651605",
      "id": "paragraph_1591538786608_142944733",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:132"
    },
    {
      "text": "CREATE TYPE customer_address (\r\n type TEXT,\r\n street TEXT,\r\n city TEXT,\r\n state TEXT,\r\n postal_code TEXT,\r\n country TEXT);",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506799_-704878545",
      "id": "paragraph_1591539175234_1399864402",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:133"
    },
    {
      "text": "ALTER TABLE customer ADD addresses LIST<FROZEN <customer_address>>;\r\n",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506799_-893077971",
      "id": "paragraph_1591539176066_1019201917",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:134"
    },
    {
      "text": "INSERT INTO customer (last_name,first_name,company,addresses) VALUES ('Washburne','Hoban','Serenity',[{type:'SHIPPING',street:'9843 32nd Place',city:'Charlotte',state:'NC',postal_code:'05601',country:'USA'}]);\r\nINSERT INTO customer (last_name,first_name,company,addresses) VALUES ('Washburne','Zoey','Serenity',[{type:'SHIPPING',street:'9843 32nd Place',city:'Charlotte',state:'NC',postal_code:'05601',country:'USA'},{type:'BILL TO',street:'9800 32nd Place',city:'Charlotte',state:'NC',postal_code:'05601',country:'USA'}]);\r\nINSERT INTO customer (last_name,first_name,company,addresses) VALUES ('Tam','Simon','Persephone General Hospital',[{type:'BILL TO',street:'83595 25th Boulevard',city:'Lawrence',state:'KS',postal_code:'66044',country:'USA'}]);",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506800_246105537",
      "id": "paragraph_1591539176006_-2070019576",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:135"
    },
    {
      "text": "SELECT last_name,first_name,company,addresses FROM customer\r\nWHERE last_name='Washburne' AND first_name='Zoey';\r\n",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506800_-2012151431",
      "id": "paragraph_1591539174765_-429517680",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:136"
    },
    {
      "text": "ALTER TYPE customer_address ADD address2 TEXT;\r\n\r\n\r\n",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506800_1808257357",
      "id": "paragraph_1591539240546_1760656229",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:137"
    },
    {
      "text": "ALTER TYPE customer_address RENAME address2 TO street2;\r\n",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506801_-1363741894",
      "id": "paragraph_1591539239906_1966348402",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:138"
    },
    {
      "text": "\r\nCREATE TYPE test_type (value TEXT);",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506801_338979705",
      "id": "paragraph_1591539174570_1282023702",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:139"
    },
    {
      "text": "\r\nDROP TYPE test_type;",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506801_-653644574",
      "id": "paragraph_1591537345087_796921232",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:140"
    },
    {
      "text": "",
      "user": "anonymous",
      "dateUpdated": "2020-06-30T12:34:53+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506802_-101844575",
      "id": "paragraph_1591539282885_-927856867",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:141"
    },
    {
      "text": "",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506805_-1062490483",
      "id": "paragraph_1591537344487_-694661246",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:142"
    },
    {
      "text": "%md\r\n\r\n### Other CQL commands\r\n\r\nCQL has some additional commands and constructs that provide additional\r\nfunctionality. A few of them bear a resemblance to their similarly-named\r\nSQL counterparts, but may behave differently.\r\n\r\n \r\n\r\n \r\n\r\n#### COUNT\r\n\r\nCQL allows you to return a count of the number of rows in the result\r\nset. Its syntax is quite similar to that of the `COUNT`\r\naggregate function in SQL. This query will return the number of rows in\r\nthe customer table with the last name `Washburne`:\r\n\r\n```\r\nSELECT COUNT(*) FROM fenago_ch3.customer WHERE last_name='Washburne';\r\n\r\n count\r\n-------\r\n    2\r\n(1 rows)\r\n```\r\n\r\nThe most common usage of this function in SQL was to count the number of\r\nrows in a table with an unbound query. Apache Cassandra allows you to\r\nattempt this, but it does warn you:\r\n\r\n```\r\nSELECT COUNT(*) FROM fenago_ch3.customer;\r\n\r\n count\r\n-------\r\n    3\r\n(1 rows)\r\nWarnings :\r\nAggregation query used without partition key\r\n```\r\n\r\nThis warning is Cassandra's way of informing you that the query was not\r\nvery efficient. As described earlier, unbound queries (queries without\r\n`WHERE` clauses) must communicate with every node in the\r\ncluster. `COUNT` queries are no different, and so these\r\nqueries should be avoided.\r\n\r\n### Note\r\n\r\ncqlsh has a hard limit of 10,000 rows per query, so `COUNT`\r\nqueries run from cqlsh on large tables will max out at that number.\r\n\r\n \r\n\r\n \r\n\r\n#### DISTINCT\r\n\r\nCQL has a construct that intrinsically removes duplicate partition key\r\nentries from a result set, using the `DISTINCT` keyword. It\r\nworks in much the same way as its SQL counterpart:\r\n\r\n```\r\nSELECT DISTINCT last_name FROM customer;\r\n\r\n last_name\r\n-----------\r\n       Tam\r\n Washburne\r\n(2 rows)\r\n```\r\n\r\nThe main difference of `DISTINCT` in CQL is that it only\r\noperates on partition keys and static columns.\r\n\r\n### Note\r\n\r\nThe only time in which `DISTINCT` is useful is when running an\r\nunbound query. This can appear to run efficiently in small numbers\r\n(fewer than 100). Do remember that it still has to reach out to all the\r\nnodes in the cluster.\r\n\r\n#### LIMIT\r\n\r\nCQL allows the use of the `LIMIT` construct, which enforces a\r\nmaximum number of rows for the query to return. This is done by adding\r\nthe `LIMIT` keyword on the end of a query, followed by an\r\ninteger representing the number of rows to be returned:\r\n\r\n```\r\nSELECT * FROM security_logs_by_location LIMIT 1;\r\n\r\n location_id | day      | time_in | employee_id | mailstop\r\n-------------+----------+---------------------+-------------+----------\r\n       MPLS2 | 20180723 | 2018-07-23 11:49:11 |        samb | M266\r\n(1 rows)\r\n```\r\n\r\n#### STATIC\r\n\r\nStatic columns are data that is more dependent on the partition keys\r\nthan on the clustering keys. Specifying a column as\r\n`STATIC` ensures that its values are only stored once (with\r\nits partition keys) and not needlessly repeated in storage with the row\r\ndata.\r\n\r\nA new table can be created with a `STATIC` column like this:\r\n\r\n```\r\nCREATE TABLE fenago_ch3.fighter_jets (\r\n type TEXT PRIMARY KEY,\r\n nickname TEXT STATIC,\r\n serial_number BIGINT);\r\n```\r\n\r\nLikewise, an existing table can be altered to contain a\r\n`STATIC` column:\r\n\r\n```\r\nALTER TABLE fenago_ch3.users_by_dept ADD department_head TEXT STATIC;\r\n```\r\n\r\nNow, we can update data in that column:\r\n\r\n```\r\nINSERT INTO fenago_ch3.users_by_dept (department,department_head) VALUES\r\n('Engineering','Richard');\r\nINSERT INTO fenago_ch3.users_by_dept (department,department_head) VALUES ('Marketing','Erlich');\r\nINSERT INTO fenago_ch3.users_by_dept (department,department_head) VALUES ('Finance/HR','Jared');\r\n\r\nSELECT department,username,department_head,title FROM fenago_ch3.users_by_dept ;\r\n\r\n department  | username | department_head | title\r\n-------------+----------+-----------------+---------------\r\n Engineering |   Dinesh |         Richard |      Dev Lead\r\n Engineering | Gilfoyle |         Richard | Sys Admin/DBA\r\n Engineering |  Richard |         Richard |           CEO\r\n   Marketing |   Erlich |          Erlich |           CMO\r\n  Finance/HR |    Jared |           Jared |           COO\r\n(5 rows)\r\n```\r\n\r\nAs shown, `department_head` only changes as\r\nper `department`. This is because `department_head`\r\nis now stored with the partition key.\r\n\r\n\r\n\r\n\r\n",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<h3>Other CQL commands</h3>\n<p>CQL has some additional commands and constructs that provide additional<br />\nfunctionality. A few of them bear a resemblance to their similarly-named<br />\nSQL counterparts, but may behave differently.</p>\n<h4>COUNT</h4>\n<p>CQL allows you to return a count of the number of rows in the result<br />\nset. Its syntax is quite similar to that of the <code>COUNT</code><br />\naggregate function in SQL. This query will return the number of rows in<br />\nthe customer table with the last name <code>Washburne</code>:</p>\n<pre><code>SELECT COUNT(*) FROM fenago_ch3.customer WHERE last_name='Washburne';\n\n count\n-------\n    2\n(1 rows)\n</code></pre>\n<p>The most common usage of this function in SQL was to count the number of<br />\nrows in a table with an unbound query. Apache Cassandra allows you to<br />\nattempt this, but it does warn you:</p>\n<pre><code>SELECT COUNT(*) FROM fenago_ch3.customer;\n\n count\n-------\n    3\n(1 rows)\nWarnings :\nAggregation query used without partition key\n</code></pre>\n<p>This warning is Cassandra&rsquo;s way of informing you that the query was not<br />\nvery efficient. As described earlier, unbound queries (queries without<br />\n<code>WHERE</code> clauses) must communicate with every node in the<br />\ncluster. <code>COUNT</code> queries are no different, and so these<br />\nqueries should be avoided.</p>\n<h3>Note</h3>\n<p>cqlsh has a hard limit of 10,000 rows per query, so <code>COUNT</code><br />\nqueries run from cqlsh on large tables will max out at that number.</p>\n<h4>DISTINCT</h4>\n<p>CQL has a construct that intrinsically removes duplicate partition key<br />\nentries from a result set, using the <code>DISTINCT</code> keyword. It<br />\nworks in much the same way as its SQL counterpart:</p>\n<pre><code>SELECT DISTINCT last_name FROM customer;\n\n last_name\n-----------\n       Tam\n Washburne\n(2 rows)\n</code></pre>\n<p>The main difference of <code>DISTINCT</code> in CQL is that it only<br />\noperates on partition keys and static columns.</p>\n<h3>Note</h3>\n<p>The only time in which <code>DISTINCT</code> is useful is when running an<br />\nunbound query. This can appear to run efficiently in small numbers<br />\n(fewer than 100). Do remember that it still has to reach out to all the<br />\nnodes in the cluster.</p>\n<h4>LIMIT</h4>\n<p>CQL allows the use of the <code>LIMIT</code> construct, which enforces a<br />\nmaximum number of rows for the query to return. This is done by adding<br />\nthe <code>LIMIT</code> keyword on the end of a query, followed by an<br />\ninteger representing the number of rows to be returned:</p>\n<pre><code>SELECT * FROM security_logs_by_location LIMIT 1;\n\n location_id | day      | time_in | employee_id | mailstop\n-------------+----------+---------------------+-------------+----------\n       MPLS2 | 20180723 | 2018-07-23 11:49:11 |        samb | M266\n(1 rows)\n</code></pre>\n<h4>STATIC</h4>\n<p>Static columns are data that is more dependent on the partition keys<br />\nthan on the clustering keys. Specifying a column as<br />\n<code>STATIC</code> ensures that its values are only stored once (with<br />\nits partition keys) and not needlessly repeated in storage with the row<br />\ndata.</p>\n<p>A new table can be created with a <code>STATIC</code> column like this:</p>\n<pre><code>CREATE TABLE fenago_ch3.fighter_jets (\n type TEXT PRIMARY KEY,\n nickname TEXT STATIC,\n serial_number BIGINT);\n</code></pre>\n<p>Likewise, an existing table can be altered to contain a<br />\n<code>STATIC</code> column:</p>\n<pre><code>ALTER TABLE fenago_ch3.users_by_dept ADD department_head TEXT STATIC;\n</code></pre>\n<p>Now, we can update data in that column:</p>\n<pre><code>INSERT INTO fenago_ch3.users_by_dept (department,department_head) VALUES\n('Engineering','Richard');\nINSERT INTO fenago_ch3.users_by_dept (department,department_head) VALUES ('Marketing','Erlich');\nINSERT INTO fenago_ch3.users_by_dept (department,department_head) VALUES ('Finance/HR','Jared');\n\nSELECT department,username,department_head,title FROM fenago_ch3.users_by_dept ;\n\n department  | username | department_head | title\n-------------+----------+-----------------+---------------\n Engineering |   Dinesh |         Richard |      Dev Lead\n Engineering | Gilfoyle |         Richard | Sys Admin/DBA\n Engineering |  Richard |         Richard |           CEO\n   Marketing |   Erlich |          Erlich |           CMO\n  Finance/HR |    Jared |           Jared |           COO\n(5 rows)\n</code></pre>\n<p>As shown, <code>department_head</code> only changes as<br />\nper <code>department</code>. This is because <code>department_head</code><br />\nis now stored with the partition key.</p>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506805_-1544326412",
      "id": "paragraph_1591537344326_-135058611",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:143"
    },
    {
      "text": "SELECT COUNT(*) FROM fenago_ch3.customer WHERE last_name='Washburne';\r\n",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506806_1359713470",
      "id": "paragraph_1591539544165_79025764",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:144"
    },
    {
      "text": "SELECT COUNT(*) FROM fenago_ch3.customer;\r\n",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506807_-1354795306",
      "id": "paragraph_1591539544067_-494981223",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:145"
    },
    {
      "text": "SELECT DISTINCT last_name FROM customer;\r\n",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506807_-1690551871",
      "id": "paragraph_1591537344107_-145168777",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:146"
    },
    {
      "text": "SELECT * FROM security_logs_by_location LIMIT 1;\r\n",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506807_-1948426902",
      "id": "paragraph_1591539483245_2107375567",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:147"
    },
    {
      "text": "\r\nCREATE TABLE fenago_ch3.fighter_jets (\r\n type TEXT PRIMARY KEY,\r\n nickname TEXT STATIC,\r\n serial_number BIGINT);",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506807_350776502",
      "id": "paragraph_1591539479793_-269943592",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:148"
    },
    {
      "text": "ALTER TABLE fenago_ch3.users_by_dept ADD department_head TEXT STATIC;\r\n",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506807_-2005184714",
      "id": "paragraph_1591539482985_-673419850",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:149"
    },
    {
      "text": "\r\n\r\nINSERT INTO fenago_ch3.users_by_dept (department,department_head) VALUES\r\n('Engineering','Richard');\r\nINSERT INTO fenago_ch3.users_by_dept (department,department_head) VALUES ('Marketing','Erlich');\r\nINSERT INTO fenago_ch3.users_by_dept (department,department_head) VALUES ('Finance/HR','Jared');\r\n\r\nSELECT department,username,department_head,title FROM fenago_ch3.users_by_dept ;",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506808_1983664130",
      "id": "paragraph_1591539489847_960259038",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:150"
    },
    {
      "text": "",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506808_-131321211",
      "id": "paragraph_1591539605567_1995992596",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:151"
    },
    {
      "text": "%md\n\n#### User-defined functions\n\nAs of version 3.0, Apache Cassandra allows users to create\n**user-defined functions** (**UDFs**). As CQL does not supply much in\nthe way of extra tools and string utilities found in SQL, some of that\nfunction can be recreated with a UDF. Let's say that we want to query\nthe current year from a `date` column. The `date`\ncolumn will return the complete year, month, and day:\n\n```\nSELECT todate(now()) FROM system.local;\n\n system.todate(system.now())\n-----------------------------\n                  2018-08-03\n(1 rows)\n```\n\nTo just get the year back, we could handle that in the application code,\nor, after enabling user-defined functions in the\n`cassandra.yaml` file, we could write a small UDF using the\nJava language:\n\n```\nCREATE OR REPLACE FUNCTION year (input DATE)\n RETURNS NULL ON NULL INPUT RETURNS TEXT\n LANGUAGE java AS 'return input.toString().substring(0,4);';\n```\n\nNow, re-running the preceding query with `todate(now())`\nnested inside my new `year()` UDF returns this result:\n\n```\nSELECT fenago_ch3.year(todate(now())) FROM system.local;\n\n fenago_ch3.year(system.todate(system.now()))\n---------------------------------------------\n                                        2018\n(1 rows)\n```\n\n### Note\n\nTo prevent injection of malicious code, UDFs are disabled by default. To\nenable their use, set `enable_user_defined_functions: true` in\n`cassandra.yaml`. Remember that changes to that file require\nthe node to be restarted before they take effect.\n",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<h4>User-defined functions</h4>\n<p>As of version 3.0, Apache Cassandra allows users to create<br />\n<strong>user-defined functions</strong> (<strong>UDFs</strong>). As CQL does not supply much in<br />\nthe way of extra tools and string utilities found in SQL, some of that<br />\nfunction can be recreated with a UDF. Let&rsquo;s say that we want to query<br />\nthe current year from a <code>date</code> column. The <code>date</code><br />\ncolumn will return the complete year, month, and day:</p>\n<pre><code>SELECT todate(now()) FROM system.local;\n\n system.todate(system.now())\n-----------------------------\n                  2018-08-03\n(1 rows)\n</code></pre>\n<p>To just get the year back, we could handle that in the application code,<br />\nor, after enabling user-defined functions in the<br />\n<code>cassandra.yaml</code> file, we could write a small UDF using the<br />\nJava language:</p>\n<pre><code>CREATE OR REPLACE FUNCTION year (input DATE)\n RETURNS NULL ON NULL INPUT RETURNS TEXT\n LANGUAGE java AS 'return input.toString().substring(0,4);';\n</code></pre>\n<p>Now, re-running the preceding query with <code>todate(now())</code><br />\nnested inside my new <code>year()</code> UDF returns this result:</p>\n<pre><code>SELECT fenago_ch3.year(todate(now())) FROM system.local;\n\n fenago_ch3.year(system.todate(system.now()))\n---------------------------------------------\n                                        2018\n(1 rows)\n</code></pre>\n<h3>Note</h3>\n<p>To prevent injection of malicious code, UDFs are disabled by default. To<br />\nenable their use, set <code>enable_user_defined_functions: true</code> in<br />\n<code>cassandra.yaml</code>. Remember that changes to that file require<br />\nthe node to be restarted before they take effect.</p>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506808_9438864",
      "id": "paragraph_1591539605547_629236332",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:152"
    },
    {
      "text": "SELECT todate(now()) FROM system.local;\r\n\r\n",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506808_-357724036",
      "id": "paragraph_1591539605273_1835726329",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:153"
    },
    {
      "text": "\r\nCREATE OR REPLACE FUNCTION year (input DATE)\r\n RETURNS NULL ON NULL INPUT RETURNS TEXT\r\n LANGUAGE java AS 'return input.toString().substring(0,4);';",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506808_-1534797629",
      "id": "paragraph_1591539605084_680578915",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:154"
    },
    {
      "text": "SELECT fenago_ch3.year(todate(now())) FROM system.local;",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506809_-2055438194",
      "id": "paragraph_1591539604946_313245345",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:155"
    },
    {
      "text": "",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506809_595903410",
      "id": "paragraph_1591539489744_-1583466786",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:156"
    },
    {
      "text": "\r\n%md\r\n\r\n### cqlsh commands\r\n\r\nIt's important to note that the commands described in this section are\r\npart of cqlsh only. They are not part of CQL. Attempts to run these\r\ncommands from within the application code will not succeed.\r\n\r\n#### CONSISTENCY\r\n\r\nBy default, cqlsh is set to a consistency level of `ONE`. But\r\nit also allows you to specify a custom consistency level, depending on\r\nwhat you are trying to do. These different levels can be set with the\r\n`CONSISTENCY` command:\r\n\r\n```\r\nCONSISTENCY LOCAL_QUORUM;\r\n\r\nSELECT last_name,first_name FROM customer ;\r\n\r\n last_name | first_name\r\n-----------+------------\r\n       Tam |      Simon\r\n Washburne |      Hoban\r\n Washburne |       Zoey\r\n\r\n(3 rows)\r\n```\r\n\r\nOn a related note, queries at `CONSISTENCY ALL` force a read\r\nrepair to occur. If you find yourself troubleshooting a consistency\r\nissue on a small to mid-sized table (fewer than 20,000 rows), you can\r\nquickly repair it by setting the consistency level to `ALL`\r\nand querying the affected rows.\r\n\r\n### Note\r\n\r\nQuerying at consistency `ALL` and forcing a read repair comes\r\nin handy when facing replication errors on something such as the\r\n`system_auth` tables.\r\n\r\n```\r\nCONSISTENCY ALL;\r\nConsistency level set to ALL.\r\n\r\nSELECT COUNT(*) FROM system_auth.roles;\r\n\r\n count\r\n-------\r\n    4\r\n(1 rows)\r\n\r\nWarnings :\r\nAggregation query used without partition key\r\n```\r\n\r\n#### COPY\r\n\r\nThe `COPY` command delivered with cqlsh is a powerful tool\r\nthat allows you to quickly export and import data. Let's assume that I\r\nwanted to duplicate my `customer` table data into another\r\nquery table. I'll start by creating the new table:\r\n\r\n```\r\nCREATE TABLE customer_by_company ( last_name text,\r\n  first_name text,\r\n  addresses list<frozen<customer_address>>,\r\n  company text,\r\n  PRIMARY KEY (company,last_name,first_name));\r\n```\r\n\r\n \r\n\r\n\r\n \r\n",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<h3>cqlsh commands</h3>\n<p>It&rsquo;s important to note that the commands described in this section are<br />\npart of cqlsh only. They are not part of CQL. Attempts to run these<br />\ncommands from within the application code will not succeed.</p>\n<h4>CONSISTENCY</h4>\n<p>By default, cqlsh is set to a consistency level of <code>ONE</code>. But<br />\nit also allows you to specify a custom consistency level, depending on<br />\nwhat you are trying to do. These different levels can be set with the<br />\n<code>CONSISTENCY</code> command:</p>\n<pre><code>CONSISTENCY LOCAL_QUORUM;\n\nSELECT last_name,first_name FROM customer ;\n\n last_name | first_name\n-----------+------------\n       Tam |      Simon\n Washburne |      Hoban\n Washburne |       Zoey\n\n(3 rows)\n</code></pre>\n<p>On a related note, queries at <code>CONSISTENCY ALL</code> force a read<br />\nrepair to occur. If you find yourself troubleshooting a consistency<br />\nissue on a small to mid-sized table (fewer than 20,000 rows), you can<br />\nquickly repair it by setting the consistency level to <code>ALL</code><br />\nand querying the affected rows.</p>\n<h3>Note</h3>\n<p>Querying at consistency <code>ALL</code> and forcing a read repair comes<br />\nin handy when facing replication errors on something such as the<br />\n<code>system_auth</code> tables.</p>\n<pre><code>CONSISTENCY ALL;\nConsistency level set to ALL.\n\nSELECT COUNT(*) FROM system_auth.roles;\n\n count\n-------\n    4\n(1 rows)\n\nWarnings :\nAggregation query used without partition key\n</code></pre>\n<h4>COPY</h4>\n<p>The <code>COPY</code> command delivered with cqlsh is a powerful tool<br />\nthat allows you to quickly export and import data. Let&rsquo;s assume that I<br />\nwanted to duplicate my <code>customer</code> table data into another<br />\nquery table. I&rsquo;ll start by creating the new table:</p>\n<pre><code>CREATE TABLE customer_by_company ( last_name text,\n  first_name text,\n  addresses list&lt;frozen&lt;customer_address&gt;&gt;,\n  company text,\n  PRIMARY KEY (company,last_name,first_name));\n</code></pre>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506809_425403",
      "id": "paragraph_1591539489685_230790162",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:157"
    },
    {
      "text": "SELECT last_name,first_name FROM customer ;\r\n\r\n",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506809_-416798122",
      "id": "paragraph_1591539489525_331397097",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:158"
    },
    {
      "text": "SELECT COUNT(*) FROM system_auth.roles;",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506810_1363327851",
      "id": "paragraph_1591539482865_752620645",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:159"
    },
    {
      "text": "CREATE TABLE customer_by_company ( last_name text,\r\n  first_name text,\r\n  addresses list<frozen<customer_address>>,\r\n  company text,\r\n  PRIMARY KEY (company,last_name,first_name));\r\n\r\n",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506810_1178098744",
      "id": "paragraph_1591539479785_-825981626",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:160"
    },
    {
      "text": "",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506810_1328836477",
      "id": "paragraph_1591539823676_1811220609",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:161"
    },
    {
      "text": "%md\n\n\n\n#### DESCRIBE\n\n`DESCRIBE` is a command that can be used to show the\ndefinition(s) for a particular object. Its command structure looks like\nthis:\n\n```\nDESC[RIBE] (KEYSPACE|TABLE|TYPE|INDEX) <object_name>;\n```\n\nIn putting it to use, you can quickly see that it can be used to view\nthings such as full table options, keyspace replication, and index\ndefinitions.\n\n### Note\n\nThe `DESCRIBE` command can be shortened to `DESC`.\n\nHere, we will demonstrate using the `DESC` command on a table:\n\n```\nDESC TYPE customer_address;\n\nCREATE TYPE fenago_ch3.customer_address (\n type text,\n street text,\n city text,\n state text,\n postal_code text,\n country text,\n street2 text\n);\n```\n\nLikewise, the `DESC` command can be used to describe an\n`INDEX`:\n\n```\nDESC INDEX order_status_idx;\n\nCREATE INDEX order_status_idx ON fenago_ch3.order_status_by_week (status);\n```",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<h4>DESCRIBE</h4>\n<p><code>DESCRIBE</code> is a command that can be used to show the<br />\ndefinition(s) for a particular object. Its command structure looks like<br />\nthis:</p>\n<pre><code>DESC[RIBE] (KEYSPACE|TABLE|TYPE|INDEX) &lt;object_name&gt;;\n</code></pre>\n<p>In putting it to use, you can quickly see that it can be used to view<br />\nthings such as full table options, keyspace replication, and index<br />\ndefinitions.</p>\n<h3>Note</h3>\n<p>The <code>DESCRIBE</code> command can be shortened to <code>DESC</code>.</p>\n<p>Here, we will demonstrate using the <code>DESC</code> command on a table:</p>\n<pre><code>DESC TYPE customer_address;\n\nCREATE TYPE fenago_ch3.customer_address (\n type text,\n street text,\n city text,\n state text,\n postal_code text,\n country text,\n street2 text\n);\n</code></pre>\n<p>Likewise, the <code>DESC</code> command can be used to describe an<br />\n<code>INDEX</code>:</p>\n<pre><code>DESC INDEX order_status_idx;\n\nCREATE INDEX order_status_idx ON fenago_ch3.order_status_by_week (status);\n</code></pre>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506810_-1116139437",
      "id": "paragraph_1591539823354_713607199",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:162"
    },
    {
      "text": "DESC TYPE customer_address;\r\n\r\n\r\n",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506811_1257080129",
      "id": "paragraph_1591539823347_-1498398679",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:163"
    },
    {
      "text": "\r\nCREATE TYPE fenago_ch3.customer_address (\r\n type text,\r\n street text,\r\n city text,\r\n state text,\r\n postal_code text,\r\n country text,\r\n street2 text\r\n);",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506811_-237887030",
      "id": "paragraph_1591970886229_1378630972",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:164"
    },
    {
      "text": "%sh\r\ncat > script.cli <<EOL\r\nDESC INDEX order_status_idx;\r\nEOL\r\ncqlsh -f  script.cli --keyspace=fenago_ch3\r\n\r\n",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "sh",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/sh",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506811_-1291495045",
      "id": "paragraph_1591539823025_1441833275",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:165"
    },
    {
      "text": "\r\nCREATE INDEX order_status_idx ON fenago_ch3.order_status_by_week (status);",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506811_-2114044507",
      "id": "paragraph_1591537343847_-1457722379",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:166"
    },
    {
      "text": "%md\n\n\n#### TRACING\n\nThe `TRACING` command is a toggle that allows the tracing\nfunctionality to be turned on:\n\n```\nTRACING ON\nNow Tracing is enabled\n\nTRACING\nTracing is currently enabled. Use TRACING OFF to disable\n```\n \n\nTracing is useful in that it can show why particular queries may be\nrunning slowly. A tracing report allows you to view things about a\nquery, such as the following:\n\n-   Nodes contacted\n-   Number of SSTables read\n-   Number of tombstones encountered\n-   How long the query took to run\n",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "text",
          "editOnDblClick": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/text",
        "fontSize": 9,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<h4>TRACING</h4>\n<p>The <code>TRACING</code> command is a toggle that allows the tracing<br />\nfunctionality to be turned on:</p>\n<pre><code>TRACING ON\nNow Tracing is enabled\n\nTRACING\nTracing is currently enabled. Use TRACING OFF to disable\n</code></pre>\n<p>Tracing is useful in that it can show why particular queries may be<br />\nrunning slowly. A tracing report allows you to view things about a<br />\nquery, such as the following:</p>\n<ul>\n<li>Nodes contacted</li>\n<li>Number of SSTables read</li>\n<li>Number of tombstones encountered</li>\n<li>How long the query took to run</li>\n</ul>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506812_1744063799",
      "id": "paragraph_1591532886259_688892048",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:167"
    },
    {
      "text": "%sh\ncat > script.cli <<EOL\nTRACING ON\nEOL\ncqlsh -f  script.cli --keyspace=fenago_ch3\n",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "sh",
          "editOnDblClick": false,
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/sh",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506813_-1285990181",
      "id": "paragraph_1591537982694_-1212506468",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:168"
    },
    {
      "text": "%sh\ncat > script.cli <<EOL\nTRACING\nEOL\ncqlsh -f  script.cli --keyspace=fenago_ch3\n",
      "user": "anonymous",
      "dateUpdated": "2020-06-12T15:58:26+0000",
      "config": {
        "editorSetting": {
          "language": "sh",
          "editOnDblClick": false,
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/sh",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1591977506813_-118939320",
      "id": "paragraph_1591537997826_765385828",
      "dateCreated": "2020-06-12T15:58:26+0000",
      "status": "READY",
      "$$hashKey": "object:169"
    }
  ],
  "name": "lab_8",
  "id": "2FACXZ466",
  "defaultInterpreterGroup": "cassandra",
  "version": "0.9.0-preview1",
  "noteParams": {},
  "noteForms": {},
  "angularObjects": {},
  "config": {
    "isZeppelinNotebookCronEnable": false,
    "looknfeel": "default",
    "personalizedMode": "false"
  },
  "info": {},
  "path": "/Optional and Supplemental/lab_8"
}